"use client"

import { Navigation } from "@/components/navigation"
import { getLucideIcon } from "@/components/LucideIcon"
import { Home, ArrowUp } from "lucide-react"
import Link from "next/link"
import { useTheme } from "@/components/theme-provider"
import { useState, useEffect } from "react"

export default function PythonPage() {
  const { theme } = useTheme()
  const [activeSection, setActiveSection] = useState('intro')
  const [showBackToTop, setShowBackToTop] = useState(false)

  useEffect(() => {
    const handleScroll = () => {
      setShowBackToTop(window.scrollY > 400)
      
      const sections = [
        'intro', 'env-setup', 'python-basics', 'numpy', 'pandas', 
        'matplotlib-seaborn', 'data-cleaning', 'eda', 'sql-integration',
        'automation', 'best-practices', 'common-mistakes', 'templates',
        'advanced-libs', 'jupyter', 'data-io', 'pandas-advanced', 
        'string-processing', 'time-series-advanced', 'project-case', 
        'project-sales', 'project-churn', 'learning-path'
      ]
      
      for (const sectionId of sections) {
        const element = document.getElementById(sectionId)
        if (element) {
          const rect = element.getBoundingClientRect()
          if (rect.top <= 150 && rect.bottom >= 150) {
            setActiveSection(sectionId)
            break
          }
        }
      }
    }

    window.addEventListener('scroll', handleScroll)
    handleScroll()
    return () => window.removeEventListener('scroll', handleScroll)
  }, [])

  const scrollToTop = () => {
    window.scrollTo({ top: 0, behavior: 'smooth' })
  }

  const isDark = theme === 'dark'

  const navItems = [
    { id: 'intro', icon: 'üéØ', label: 'PythonÁü•ËØÜ‰ΩìÁ≥ª', color: 'purple' },
    { id: 'env-setup', icon: '‚öôÔ∏è', label: '01. ÁéØÂ¢ÉÊê≠Âª∫', color: 'blue' },
    { id: 'python-basics', icon: 'üìö', label: '02. PythonÂü∫Á°Ä', color: 'green' },
    { id: 'numpy', icon: 'üî¢', label: '03. NumPyÊï∞ÁªÑËÆ°ÁÆó', color: 'yellow' },
    { id: 'pandas', icon: 'üêº', label: '04. PandasÊï∞ÊçÆÂ§ÑÁêÜ', color: 'red' },
    { id: 'matplotlib-seaborn', icon: 'üìä', label: '05. ÂèØËßÜÂåñÂ∫ì', color: 'pink' },
    { id: 'data-cleaning', icon: 'üßπ', label: '06. Êï∞ÊçÆÊ∏ÖÊ¥ó', color: 'indigo' },
    { id: 'eda', icon: 'üîç', label: '07. Êé¢Á¥¢ÊÄßÂàÜÊûêEDA', color: 'orange' },
    { id: 'sql-integration', icon: 'üîó', label: '08. Python √ó SQL', color: 'teal' },
    { id: 'automation', icon: '‚ö°', label: '09. Ëá™Âä®ÂåñËÑöÊú¨', color: 'cyan' },
    { id: 'best-practices', icon: '‚ú®', label: '10. ÊúÄ‰Ω≥ÂÆûË∑µ', color: 'rose' },
    { id: 'common-mistakes', icon: '‚ö†Ô∏è', label: '11. Â∏∏ËßÅÈîôËØØÈÅøÂùë', color: 'amber' },
    { id: 'templates', icon: 'üì¶', label: '12. ‰ª£Á†ÅÊ®°ÊùøÂ∫ì', color: 'lime' },
    { id: 'advanced-libs', icon: 'üöÄ', label: '13. ËøõÈò∂Â∫ìÊé®Ëçê', color: 'emerald' },
    { id: 'jupyter', icon: 'üìì', label: '14. JupyterÂÆåÂÖ®ÊåáÂçó', color: 'sky' },
    { id: 'data-io', icon: 'üíæ', label: '15. Êï∞ÊçÆÂØºÂÖ•ÂØºÂá∫', color: 'indigo' },
    { id: 'pandas-advanced', icon: 'üêº', label: '16. PandasÈ´òÁ∫ßÊäÄÂ∑ß', color: 'orange' },
    { id: 'string-processing', icon: 'üìù', label: '17. Â≠óÁ¨¶‰∏≤Â§ÑÁêÜ', color: 'green' },
    { id: 'time-series-advanced', icon: 'üìÖ', label: '18. Êó∂Èó¥Â∫èÂàóÊ∑±Â∫¶', color: 'cyan' },
    { id: 'project-case', icon: 'üéØ', label: '19. ÁîµÂïÜÁî®Êà∑ÂàÜÊûê', color: 'purple' },
    { id: 'project-sales', icon: 'üìä', label: '20. ÈîÄÂîÆÈ¢ùÈ¢ÑÊµã', color: 'blue' },
    { id: 'project-churn', icon: '‚ö†Ô∏è', label: '21. Áî®Êà∑ÊµÅÂ§±È¢ÑË≠¶', color: 'red' },
    { id: 'learning-path', icon: 'üó∫Ô∏è', label: '22. Â≠¶‰π†Ë∑ØÂæÑ', color: 'violet' }
  ]

  const parts = [
    {
      id: 'env-setup',
      title: 'PART 01 ÁéØÂ¢ÉÊê≠Âª∫',
      subtitle: 'Â∑•Ê¨≤ÂñÑÂÖ∂‰∫ãÔºåÂøÖÂÖàÂà©ÂÖ∂Âô® ‚Äî‚Äî È´òÊïàÁéØÂ¢ÉÈÖçÁΩÆ',
      items: [
        {
          emoji: 'üêç',
          title: 'PythonÁâàÊú¨ÈÄâÊã© ‚òÜ',
          desc: 'Êé®ËçêPython 3.9+ÔºàÊï∞ÊçÆÂàÜÊûê3.9-3.11ÊúÄÁ®≥ÂÆöÔºå3.12ÈÉ®ÂàÜÂ∫ìÂèØËÉΩ‰∏çÂÖºÂÆπÔºâ',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöÊï∞ÊçÆÂàÜÊûêÈ°πÁõÆÂª∫ËÆÆ3.9-3.11ÔºåÂÖºÂÆπÊÄßÂ•Ω„ÄÅÂ∫ìÊîØÊåÅÂÖ®\\n**ÊòìË∏©ÂùëÁÇπ**Ôºö3.12+ÈÉ®ÂàÜÊï∞ÊçÆÂàÜÊûêÂ∫ìÔºàÂ¶ÇÊüê‰∫õÁâàÊú¨ÁöÑpandas„ÄÅnumpyÔºâÂèØËÉΩÊúâÂÖºÂÆπÊÄßÈóÆÈ¢ò\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöËôöÊãüÁéØÂ¢ÉÁÆ°ÁêÜÔºàvenv„ÄÅcondaÔºâ„ÄÅÁâàÊú¨ÈöîÁ¶ªÁ≠ñÁï•',
          code: `# Êü•ÁúãPythonÁâàÊú¨
python --version

# Êé®ËçêÔºö‰ΩøÁî®condaÂàõÂª∫ËôöÊãüÁéØÂ¢É
conda create -n data_analysis python=3.11
conda activate data_analysis

# Êàñ‰ΩøÁî®venv
python -m venv myenv
# WindowsÊøÄÊ¥ª
myenv\\Scripts\\activate
# Mac/LinuxÊøÄÊ¥ª
source myenv/bin/activate`
        },
        {
          emoji: 'üì¶',
          title: 'Ê†∏ÂøÉÂ∫ìÂÆâË£Ö ‚òÜ',
          desc: 'Êï∞ÊçÆÂàÜÊûêÂõõÂ§ß‰ª∂Ôºöpandas, numpy, matplotlib, seaborn',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**Ôºö‰∏ÄË°åÂëΩ‰ª§ÂÆâË£ÖÊâÄÊúâÊï∞ÊçÆÂàÜÊûêÊ†∏ÂøÉÂ∫ì\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöÁõ¥Êé•pip installÂèØËÉΩÈÅáÂà∞‰æùËµñÂÜ≤Á™ÅÔºåÊé®Ëçê‰ΩøÁî®requirements.txtÊàñconda\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**Ôºöpip vs condaÂå∫Âà´„ÄÅÈïúÂÉèÊ∫êÈÖçÁΩÆÔºàÊ∏ÖÂçé/ÈòøÈáåÔºâÂä†ÈÄü',
          code: `# ÊñπÂºè1ÔºöÂçïÁã¨ÂÆâË£Ö
pip install pandas numpy matplotlib seaborn

# ÊñπÂºè2ÔºöÊâπÈáèÂÆâË£ÖÔºàÊé®ËçêÔºâ
pip install pandas==2.1.0 numpy==1.24.3 matplotlib==3.7.2 seaborn==0.12.2

# ÊñπÂºè3Ôºö‰ΩøÁî®requirements.txt
# ÂàõÂª∫requirements.txtÊñá‰ª∂ÔºåÂÜÖÂÆπÂ¶Ç‰∏ãÔºö
pandas>=2.0.0
numpy>=1.24.0
matplotlib>=3.7.0
seaborn>=0.12.0
scikit-learn>=1.3.0
openpyxl>=3.1.0
xlrd>=2.0.0
pymysql>=1.1.0
sqlalchemy>=2.0.0

# ÁÑ∂ÂêéÊâßË°å
pip install -r requirements.txt

# ÈÖçÁΩÆÂõΩÂÜÖÈïúÂÉèÊ∫êÔºàÂä†ÈÄü‰∏ãËΩΩÔºâ
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pandas`
        },
        {
          emoji: 'üíª',
          title: 'IDEÈÄâÊã©',
          desc: 'Jupyter NotebookÈÄÇÂêàÊé¢Á¥¢ÂàÜÊûêÔºåVSCode/PyCharmÈÄÇÂêàÂ∑•Á®ãÂåñÂºÄÂèë',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöÊï∞ÊçÆÊé¢Á¥¢Áî®JupyterÔºåÁîü‰∫ßËÑöÊú¨Áî®VSCode/PyCharm\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöJupyter‰∏≠ÂèòÈáè‰ΩúÁî®ÂüüÊ∑∑‰π±ÔºåË∞ÉËØïÂõ∞Èöæ\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöJupyterLab„ÄÅGoogle Colab„ÄÅVS CodeÊèí‰ª∂Êé®Ëçê',
          code: `# ÂÆâË£ÖJupyter
pip install jupyter notebook jupyterlab

# ÂêØÂä®Jupyter Notebook
jupyter notebook

# ÂêØÂä®JupyterLabÔºàÊé®ËçêÔºåÂäüËÉΩÊõ¥Âº∫Ôºâ
jupyter lab

# VSCodeÊé®ËçêÊèí‰ª∂
# - Python (Microsoft)
# - Jupyter (Microsoft)
# - Pylance (ËØ≠Ê≥ïÊèêÁ§∫)
# - autoDocstring (ÊñáÊ°£ÁîüÊàê)`
        }
      ]
    },
    {
      id: 'python-basics',
      title: 'PART 02 PythonÂü∫Á°Ä',
      subtitle: 'Êï∞ÊçÆÂàÜÊûêÂøÖÂ§áÁöÑPythonÊ†∏ÂøÉËØ≠Ê≥ïÔºà80%Âú∫ÊôØÂè™ÈúÄ20%ËØ≠Ê≥ïÔºâ',
      items: [
        {
          emoji: 'üìù',
          title: 'Êï∞ÊçÆÁªìÊûÑÔºàÂøÖËÉåÔºâ‚òÜ',
          desc: 'list„ÄÅdict„ÄÅtuple„ÄÅset ‚Äî‚Äî Êï∞ÊçÆÂàÜÊûê90%Âú∫ÊôØÂè™Áî®Ëøô4‰∏™',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºölistÂ≠òÂÇ®Êï∞ÊçÆË°åÔºådictÂ≠òÂÇ®ÈîÆÂÄºÂØπÈÖçÁΩÆÔºåsetÂéªÈáç\\n**ÊòìË∏©ÂùëÁÇπ**ÔºölistÊòØÂèØÂèòÂØπË±°Ôºå‰Ωú‰∏∫ÂáΩÊï∞ÈªòËÆ§ÂèÇÊï∞‰ºöÂá∫bug\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöÂàóË°®Êé®ÂØºÂºè„ÄÅÂ≠óÂÖ∏Êé®ÂØºÂºè„ÄÅÁîüÊàêÂô®Ë°®ËææÂºè',
          code: `# ListÂàóË°®ÔºàÊúÄÂ∏∏Áî®Ôºâ
data = [1, 2, 3, 4, 5]
data.append(6)  # Ê∑ªÂä†ÂÖÉÁ¥†
data[0]  # Á¥¢Âºï
data[1:3]  # ÂàáÁâá

# DictÂ≠óÂÖ∏ÔºàÂ≠òÂÇ®ÈÖçÁΩÆ„ÄÅÊò†Â∞ÑÂÖ≥Á≥ªÔºâ
config = {
    'db_host': 'localhost',
    'db_port': 3306,
    'db_name': 'sales'
}
config['db_host']  # ÂèñÂÄº
config.get('db_user', 'default_user')  # ÂÆâÂÖ®ÂèñÂÄºÔºàÂ∏¶ÈªòËÆ§ÂÄºÔºâ

# TupleÂÖÉÁªÑÔºà‰∏çÂèØÂèòÔºåÂ∏∏Áî®‰∫éËøîÂõûÂ§ö‰∏™ÂÄºÔºâ
def get_stats(data):
    return len(data), sum(data), sum(data)/len(data)
count, total, avg = get_stats([1, 2, 3, 4, 5])

# SetÈõÜÂêàÔºàÂéªÈáç„ÄÅ‰∫§Âπ∂ÈõÜËøêÁÆóÔºâ
ids_set1 = {1, 2, 3, 4}
ids_set2 = {3, 4, 5, 6}
ids_set1 & ids_set2  # ‰∫§ÈõÜ {3, 4}
ids_set1 | ids_set2  # Âπ∂ÈõÜ {1, 2, 3, 4, 5, 6}
ids_set1 - ids_set2  # Â∑ÆÈõÜ {1, 2}

# ÂàóË°®Êé®ÂØºÂºèÔºàÈ´òÊïàÁîüÊàêÂàóË°®Ôºâ
squares = [x**2 for x in range(10)]
even_squares = [x**2 for x in range(10) if x % 2 == 0]`
        },
        {
          emoji: 'üîÑ',
          title: 'Âæ™ÁéØ‰∏éÊù°‰ª∂ ‚òÜ',
          desc: 'forÂæ™ÁéØÈÅçÂéÜÊï∞ÊçÆÔºåifÂà§Êñ≠Á≠õÈÄâÈÄªËæë',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöÈÅçÂéÜDataFrameË°å„ÄÅÊâπÈáèÂ§ÑÁêÜÊñá‰ª∂\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöËÉΩÁî®ÂêëÈáèÂåñËøêÁÆóÂ∞±Âà´Áî®forÂæ™ÁéØÔºàpandas‰∏≠forÊÖ¢100ÂÄçÔºâ\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**Ôºöenumerate()„ÄÅzip()„ÄÅitertoolsÊ®°Âùó',
          code: `# ForÂæ™ÁéØ
data = [1, 2, 3, 4, 5]
for item in data:
    print(item)

# enumerateÔºàÂêåÊó∂Ëé∑ÂèñÁ¥¢ÂºïÂíåÂÄºÔºâ
for idx, value in enumerate(data):
    print(f"Á¥¢Âºï{idx}: ÂÄº{value}")

# zipÔºàÂêåÊó∂ÈÅçÂéÜÂ§ö‰∏™ÂàóË°®Ôºâ
names = ['Alice', 'Bob', 'Charlie']
scores = [85, 92, 78]
for name, score in zip(names, scores):
    print(f"{name}: {score}ÂàÜ")

# Êù°‰ª∂Âà§Êñ≠
age = 25
if age >= 18:
    print("ÊàêÂπ¥‰∫∫")
elif age >= 13:
    print("ÈùíÂ∞ëÂπ¥")
else:
    print("ÂÑøÁ´•")

# ‰∏âÂÖÉË°®ËææÂºèÔºàÁÆÄÊ¥ÅÁöÑif-elseÔºâ
category = "È´ò" if score >= 90 else "‰∏≠" if score >= 60 else "‰Ωé"`
        },
        {
          emoji: '‚öôÔ∏è',
          title: 'ÂáΩÊï∞ÂÆö‰πâ',
          desc: 'Â∞ÅË£ÖÂèØÂ§çÁî®ÈÄªËæëÔºåÂáèÂ∞ëÈáçÂ§ç‰ª£Á†Å',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöÂ∞ÅË£ÖÊï∞ÊçÆÊ∏ÖÊ¥óÂáΩÊï∞„ÄÅÊåáÊ†áËÆ°ÁÆóÂáΩÊï∞\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöÂèØÂèòÂØπË±°‰Ωú‰∏∫ÈªòËÆ§ÂèÇÊï∞„ÄÅÂáΩÊï∞ÂÜÖ‰øÆÊîπÂÖ®Â±ÄÂèòÈáè\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöË£ÖÈ•∞Âô®„ÄÅlambdaË°®ËææÂºè„ÄÅ*argsÂíå**kwargs',
          code: `# Âü∫Á°ÄÂáΩÊï∞ÂÆö‰πâ
def calculate_gmv(price, quantity):
    """ËÆ°ÁÆóGMV"""
    return price * quantity

gmv = calculate_gmv(100, 50)  # 5000

# ÈªòËÆ§ÂèÇÊï∞
def calculate_discount(price, discount_rate=0.1):
    return price * (1 - discount_rate)

# ËøîÂõûÂ§ö‰∏™ÂÄº
def get_statistics(data):
    return min(data), max(data), sum(data)/len(data)

min_val, max_val, avg_val = get_statistics([1, 2, 3, 4, 5])

# LambdaË°®ËææÂºèÔºàÂåøÂêçÂáΩÊï∞Ôºâ
square = lambda x: x**2
square(5)  # 25

# Â∏∏Áî®‰∫éDataFrameÊìç‰Ωú
df['price_level'] = df['price'].apply(lambda x: 'È´ò' if x > 100 else '‰Ωé')

# *argsÂíå**kwargsÔºàÂèØÂèòÂèÇÊï∞Ôºâ
def calculate_total(*prices):
    return sum(prices)

calculate_total(10, 20, 30, 40)  # 100`
        },
        {
          emoji: 'üìÇ',
          title: 'Êñá‰ª∂Êìç‰Ωú',
          desc: 'ËØªÂÜôtxt„ÄÅcsv„ÄÅexcelÊñá‰ª∂',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöËØªÂèñÊó•ÂøóÊñá‰ª∂„ÄÅÂØºÂá∫Êï∞ÊçÆÊä•Ë°®\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöÊñá‰ª∂Êú™ÂÖ≥Èó≠ÂØºËá¥ËµÑÊ∫êÊ≥ÑÊºèÔºåÊé®Ëçê‰ΩøÁî®withËØ≠Âè•\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöpathlibÊ®°Âùó„ÄÅosÊ®°Âùó„ÄÅÊñá‰ª∂ÁºñÁ†ÅÈóÆÈ¢ò',
          code: `# ËØªÂèñÊñáÊú¨Êñá‰ª∂
with open('data.txt', 'r', encoding='utf-8') as f:
    content = f.read()

# ÂÜôÂÖ•ÊñáÊú¨Êñá‰ª∂
with open('output.txt', 'w', encoding='utf-8') as f:
    f.write("Hello World")

# ÈÄêË°åËØªÂèñÔºàÈÄÇÂêàÂ§ßÊñá‰ª∂Ôºâ
with open('big_data.txt', 'r', encoding='utf-8') as f:
    for line in f:
        process(line.strip())

# CSVÊñá‰ª∂Êìç‰ΩúÔºàÊé®ËçêÁî®pandasÔºâ
import pandas as pd
df = pd.read_csv('data.csv')
df.to_csv('output.csv', index=False)

# ExcelÊñá‰ª∂Êìç‰Ωú
df = pd.read_excel('data.xlsx', sheet_name='Sheet1')
df.to_excel('output.xlsx', index=False, sheet_name='Result')

# Ë∑ØÂæÑÊìç‰ΩúÔºàÊé®ËçêpathlibÔºâ
from pathlib import Path
file_path = Path('data/sales/2024/january.csv')
if file_path.exists():
    df = pd.read_csv(file_path)`
        }
      ]
    },
    {
      id: 'numpy',
      title: 'PART 03 NumPyÊï∞ÁªÑËÆ°ÁÆó',
      subtitle: 'È´òÊÄßËÉΩÊï∞ÂÄºËÆ°ÁÆóÁöÑÂü∫Áü≥ ‚Äî‚Äî ÊØîPythonÂéüÁîüÂø´100ÂÄç',
      items: [
        {
          emoji: 'üî¢',
          title: 'NumPyÊï∞ÁªÑÂàõÂª∫ ‚òÜ',
          desc: 'ndarrayÊòØNumPyÊ†∏ÂøÉÊï∞ÊçÆÁªìÊûÑÔºåÊîØÊåÅÂêëÈáèÂåñËøêÁÆó',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöÊâπÈáèÊï∞ÂÄºËÆ°ÁÆó„ÄÅÁü©ÈòµËøêÁÆó„ÄÅÁªüËÆ°ÂàÜÊûê\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöNumPyÊï∞ÁªÑÊòØÂõ∫ÂÆöÁ±ªÂûãÔºå‰∏çËÉΩÊ∑∑Áî®intÂíåstr\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöÊï∞ÁªÑÂπøÊí≠ÔºàbroadcastingÔºâ„ÄÅËä±ÂºèÁ¥¢Âºï',
          code: `import numpy as np

# ÂàõÂª∫Êï∞ÁªÑ
arr1 = np.array([1, 2, 3, 4, 5])
arr2 = np.array([[1, 2, 3], [4, 5, 6]])  # ‰∫åÁª¥Êï∞ÁªÑ

# Â∏∏Áî®ÂàõÂª∫ÂáΩÊï∞
np.zeros((3, 4))  # ÂÖ®0Êï∞ÁªÑ
np.ones((2, 3))   # ÂÖ®1Êï∞ÁªÑ
np.arange(0, 10, 2)  # [0, 2, 4, 6, 8]
np.linspace(0, 1, 5)  # [0, 0.25, 0.5, 0.75, 1.0]

# ÈöèÊú∫Êï∞ÁªÑÔºàÊï∞ÊçÆÂàÜÊûêÂ∏∏Áî®Ôºâ
np.random.rand(3, 4)  # 0-1‰πãÈó¥ÁöÑÂùáÂåÄÂàÜÂ∏É
np.random.randn(3, 4)  # Ê†áÂáÜÊ≠£ÊÄÅÂàÜÂ∏É
np.random.randint(0, 100, size=(3, 4))  # ÈöèÊú∫Êï¥Êï∞

# Êï∞ÁªÑÂ±ûÊÄß
arr = np.array([[1, 2, 3], [4, 5, 6]])
print(arr.shape)   # (2, 3) ÂΩ¢Áä∂
print(arr.dtype)   # int64 Êï∞ÊçÆÁ±ªÂûã
print(arr.ndim)    # 2 Áª¥Â∫¶
print(arr.size)    # 6 ÂÖÉÁ¥†ÊÄªÊï∞`
        },
        {
          emoji: '‚ö°',
          title: 'ÂêëÈáèÂåñËøêÁÆó ‚òÜ',
          desc: 'NumPyÊúÄÂ§ß‰ºòÂäøÔºöÊâπÈáèËøêÁÆóÔºåÊó†ÈúÄÂæ™ÁéØ',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöÊâπÈáè‰ª∑Ê†ºËÆ°ÁÆó„ÄÅÊäòÊâ£ËÆ°ÁÆó„ÄÅÊåáÊ†áÂΩí‰∏ÄÂåñ\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöËÉΩÁî®ÂêëÈáèÂåñÂ∞±Âà´Áî®forÂæ™ÁéØÔºåÊÄßËÉΩÂ∑ÆË∑ù100ÂÄç‰ª•‰∏ä\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöufuncÈÄöÁî®ÂáΩÊï∞„ÄÅÂπøÊí≠Êú∫Âà∂',
          code: `# ‚ùå ÈîôËØØÔºö‰ΩøÁî®PythonÂæ™ÁéØÔºàÊÖ¢Ôºâ
prices = [100, 200, 300, 400]
discounted = []
for price in prices:
    discounted.append(price * 0.8)

# ‚úÖ Ê≠£Á°ÆÔºöNumPyÂêëÈáèÂåñÔºàÂø´100ÂÄçÔºâ
prices = np.array([100, 200, 300, 400])
discounted = prices * 0.8  # [80, 160, 240, 320]

# ÊâπÈáèËøêÁÆó
arr = np.array([1, 2, 3, 4, 5])
arr + 10        # [11, 12, 13, 14, 15]
arr * 2         # [2, 4, 6, 8, 10]
arr ** 2        # [1, 4, 9, 16, 25]
arr > 3         # [False, False, False, True, True]

# Êï∞ÁªÑÈó¥ËøêÁÆó
arr1 = np.array([1, 2, 3])
arr2 = np.array([4, 5, 6])
arr1 + arr2     # [5, 7, 9]
arr1 * arr2     # [4, 10, 18]

# ÂπøÊí≠Êú∫Âà∂Ôºà‰∏çÂêåÂΩ¢Áä∂Êï∞ÁªÑËøêÁÆóÔºâ
matrix = np.array([[1, 2, 3], [4, 5, 6]])
vector = np.array([10, 20, 30])
matrix + vector  # [[11, 22, 33], [14, 25, 36]]`
        },
        {
          emoji: 'üìä',
          title: 'ÁªüËÆ°ÂáΩÊï∞',
          desc: 'Âø´ÈÄüËÆ°ÁÆóÂùáÂÄº„ÄÅÊñπÂ∑Æ„ÄÅÂàÜ‰ΩçÊï∞Á≠âÁªüËÆ°ÊåáÊ†á',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöÊï∞ÊçÆÊé¢Á¥¢„ÄÅÂºÇÂ∏∏ÂÄºÊ£ÄÊµã„ÄÅÊèèËø∞ÊÄßÁªüËÆ°\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöaxisÂèÇÊï∞ÂÆπÊòìÊ∑∑Ê∑ÜÔºà0ÊòØÂàóÔºå1ÊòØË°åÔºâ\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöÂä†ÊùÉÁªüËÆ°„ÄÅÁßªÂä®Á™óÂè£ÁªüËÆ°',
          code: `data = np.array([85, 92, 78, 95, 88, 76, 91, 89])

# Âü∫Á°ÄÁªüËÆ°
data.mean()     # Âπ≥ÂùáÂÄº 86.75
data.std()      # Ê†áÂáÜÂ∑Æ 6.12
data.var()      # ÊñπÂ∑Æ 37.44
data.min()      # ÊúÄÂ∞èÂÄº 76
data.max()      # ÊúÄÂ§ßÂÄº 95
data.sum()      # Ê±ÇÂíå 694

# ÂàÜ‰ΩçÊï∞
np.percentile(data, 25)  # 25%ÂàÜ‰ΩçÊï∞
np.percentile(data, 50)  # ‰∏≠‰ΩçÊï∞
np.percentile(data, 75)  # 75%ÂàÜ‰ΩçÊï∞

# ‰∫åÁª¥Êï∞ÁªÑÁªüËÆ°ÔºàÊ≥®ÊÑèaxisÂèÇÊï∞Ôºâ
matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
matrix.mean()           # ÂÖ®Â±ÄÂùáÂÄº 5.0
matrix.mean(axis=0)     # ÊØèÂàóÂùáÂÄº [4, 5, 6]
matrix.mean(axis=1)     # ÊØèË°åÂùáÂÄº [2, 5, 8]

# Êù°‰ª∂ÁªüËÆ°
data[data > 85].mean()  # Â§ß‰∫é85ÁöÑÊï∞ÊçÆÁöÑÂπ≥ÂùáÂÄº
np.where(data > 85, '‰ºòÁßÄ', 'ËâØÂ•Ω')  # Êù°‰ª∂ÊõøÊç¢`
        },
        {
          emoji: 'üîç',
          title: 'Êï∞ÁªÑÁ¥¢Âºï‰∏éÂàáÁâá',
          desc: 'ÁÅµÊ¥ªÊèêÂèñÊï∞ÊçÆÂ≠êÈõÜ',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöÊèêÂèñÁâπÂÆöË°åÂàó„ÄÅÁ≠õÈÄâÊï∞ÊçÆ„ÄÅÊï∞ÊçÆÈááÊ†∑\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöÂàáÁâáÊòØËßÜÂõæ‰∏çÊòØÂâØÊú¨Ôºå‰øÆÊîπ‰ºöÂΩ±ÂìçÂéüÊï∞ÁªÑ\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöÂ∏ÉÂ∞îÁ¥¢Âºï„ÄÅËä±ÂºèÁ¥¢Âºï„ÄÅix_ÁΩëÊ†ºÁ¥¢Âºï',
          code: `arr = np.array([10, 20, 30, 40, 50])

# Âü∫Á°ÄÁ¥¢Âºï
arr[0]      # 10
arr[-1]     # 50
arr[1:4]    # [20, 30, 40]

# ‰∫åÁª¥Êï∞ÁªÑÁ¥¢Âºï
matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
matrix[0, 1]     # 2 (Á¨¨0Ë°åÁ¨¨1Âàó)
matrix[1, :]     # [4, 5, 6] (Á¨¨1Ë°åÊâÄÊúâÂàó)
matrix[:, 2]     # [3, 6, 9] (ÊâÄÊúâË°åÁ¨¨2Âàó)
matrix[0:2, 1:3] # [[2, 3], [5, 6]]

# Â∏ÉÂ∞îÁ¥¢ÂºïÔºàÈáçË¶ÅÔºÅÔºâ
data = np.array([85, 92, 78, 95, 88, 76, 91, 89])
data[data > 85]          # [92, 95, 88, 91, 89]
data[(data > 80) & (data < 90)]  # [85, 88, 89]

# Ëä±ÂºèÁ¥¢Âºï
arr = np.array([10, 20, 30, 40, 50])
indices = [0, 2, 4]
arr[indices]  # [10, 30, 50]`
        }
      ]
    },
    {
      id: 'pandas',
      title: 'PART 04 PandasÊï∞ÊçÆÂ§ÑÁêÜ',
      subtitle: 'Êï∞ÊçÆÂàÜÊûêÁöÑÁëûÂ£´ÂÜõÂàÄ ‚Äî‚Äî 90%ÁöÑÊï∞ÊçÆÂ§ÑÁêÜÁî®PandasËß£ÂÜ≥',
      items: [
        {
          emoji: 'üêº',
          title: 'DataFrame‰∏éSeries ‚òÜ',
          desc: 'Pandas‰∏§Â§ßÊ†∏ÂøÉÊï∞ÊçÆÁªìÊûÑÔºöSeries(‰∏ÄÁª¥)ÂíåDataFrame(‰∫åÁª¥Ë°®)',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöËØªÂèñCSV/Excel„ÄÅÊï∞ÊçÆË°®Êìç‰Ωú„ÄÅ‰∏öÂä°ÊåáÊ†áËÆ°ÁÆó\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöDataFrameÂàóÂêçÈáçÂ§ç„ÄÅÁ¥¢ÂºïÈîô‰π±„ÄÅÈìæÂºèËµãÂÄºË≠¶Âëä\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöMultiIndexÂ§öÁ∫ßÁ¥¢Âºï„ÄÅÂàÜÁ±ªÊï∞ÊçÆÁ±ªÂûãCategorical',
          code: `import pandas as pd

# ÂàõÂª∫Series
s = pd.Series([1, 2, 3, 4, 5], index=['a', 'b', 'c', 'd', 'e'])

# ÂàõÂª∫DataFrame
data = {
    'user_id': [1001, 1002, 1003, 1004],
    'name': ['Alice', 'Bob', 'Charlie', 'David'],
    'age': [25, 30, 35, 28],
    'sales': [5000, 8000, 6000, 7000]
}
df = pd.DataFrame(data)

# ËØªÂèñÊñá‰ª∂ÔºàÊúÄÂ∏∏Áî®Ôºâ
df = pd.read_csv('sales_data.csv')
df = pd.read_excel('sales_data.xlsx', sheet_name='Sheet1')

# Êü•ÁúãÊï∞ÊçÆ
df.head()      # Ââç5Ë°å
df.tail(10)    # Âêé10Ë°å
df.info()      # Êï∞ÊçÆÁ±ªÂûãÂíåÁº∫Â§±ÂÄº‰ø°ÊÅØ
df.describe()  # Êï∞ÂÄºÂàóÁöÑÁªüËÆ°ÊëòË¶Å
df.shape       # (Ë°åÊï∞, ÂàóÊï∞)
df.columns     # ÂàóÂêç
df.dtypes      # ÊØèÂàóÊï∞ÊçÆÁ±ªÂûã

# ÈÄâÊã©Âàó
df['name']           # ÂçïÂàóÔºàËøîÂõûSeriesÔºâ
df[['name', 'age']]  # Â§öÂàóÔºàËøîÂõûDataFrameÔºâ`
        },
        {
          emoji: 'üîç',
          title: 'Êï∞ÊçÆÁ≠õÈÄâ‰∏éÁ¥¢Âºï ‚òÜ',
          desc: 'loc„ÄÅiloc„ÄÅÂ∏ÉÂ∞îÁ¥¢Âºï ‚Äî‚Äî Êï∞ÊçÆÂàÜÊûêÂ∏àÊØèÂ§©Áî®100Ê¨°',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöÁ≠õÈÄâÈ´ò‰ª∑ÂÄºÁî®Êà∑„ÄÅÊèêÂèñÁâπÂÆöÊó∂Èó¥ÊÆµÊï∞ÊçÆ„ÄÅÊù°‰ª∂Êü•ËØ¢\\n**ÊòìË∏©ÂùëÁÇπ**ÔºölocÁî®Ê†áÁ≠æÔºåilocÁî®‰ΩçÁΩÆÔºõÈìæÂºèÁ¥¢Âºï‰ºöÊä•SettingWithCopyWarning\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**Ôºöquery()ÊñπÊ≥ï„ÄÅeval()ÊñπÊ≥ï„ÄÅatÂíåiatÂø´ÈÄüËÆøÈóÆ',
          code: `# locÔºöÂü∫‰∫éÊ†áÁ≠æÁöÑÁ¥¢Âºï
df.loc[0]                    # Á¨¨0Ë°å
df.loc[0:5]                  # 0Âà∞5Ë°å
df.loc[:, 'name']            # nameÂàó
df.loc[0:5, ['name', 'age']] # 0-5Ë°åÁöÑnameÂíåageÂàó

# ilocÔºöÂü∫‰∫é‰ΩçÁΩÆÁöÑÁ¥¢Âºï
df.iloc[0]       # Á¨¨0Ë°å
df.iloc[0:5]     # 0-4Ë°åÔºà‰∏çÂåÖÊã¨5Ôºâ
df.iloc[:, 0]    # Á¨¨0Âàó
df.iloc[0:5, 0:3]  # Ââç5Ë°åÂâç3Âàó

# Â∏ÉÂ∞îÁ¥¢ÂºïÔºàÊúÄÈáçË¶ÅÔºÅÔºâ
df[df['age'] > 30]  # Âπ¥ÈæÑÂ§ß‰∫é30ÁöÑË°å
df[df['sales'] >= 7000]  # ÈîÄÂîÆÈ¢ùÂ§ß‰∫éÁ≠â‰∫é7000ÁöÑË°å
df[(df['age'] > 25) & (df['sales'] > 6000)]  # Â§öÊù°‰ª∂‰∏é
df[(df['age'] < 25) | (df['sales'] > 8000)]  # Â§öÊù°‰ª∂Êàñ

# Â≠óÁ¨¶‰∏≤Á≠õÈÄâ
df[df['name'].str.contains('A')]  # ÂêçÂ≠óÂåÖÂê´A
df[df['name'].str.startswith('B')]  # ÂêçÂ≠ó‰ª•BÂºÄÂ§¥
df[df['name'].isin(['Alice', 'Bob'])]  # ÂêçÂ≠óÂú®ÂàóË°®‰∏≠

# queryÊñπÊ≥ïÔºàÊõ¥ÁÆÄÊ¥ÅÔºâ
df.query('age > 30 and sales > 6000')
df.query('name == "Alice" or sales > 7500')`
        },
        {
          emoji: 'üîß',
          title: 'Êï∞ÊçÆÊ∏ÖÊ¥ó ‚òÜ',
          desc: 'Â§ÑÁêÜÁº∫Â§±ÂÄº„ÄÅÈáçÂ§çÂÄº„ÄÅÂºÇÂ∏∏ÂÄº ‚Äî‚Äî Êï∞ÊçÆÂàÜÊûêÁöÑÁ¨¨‰∏ÄÊ≠•',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöÊ∏ÖÊ¥óËÑèÊï∞ÊçÆ„ÄÅÂ°´ÂÖÖÁº∫Â§±ÂÄº„ÄÅÂéªÈáç\\n**ÊòìË∏©ÂùëÁÇπ**Ôºöinplace=True‰ºö‰øÆÊîπÂéüDataFrameÔºåË∞®ÊÖé‰ΩøÁî®\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöÊèíÂÄºÊñπÊ≥ïinterpolate()„ÄÅÂºÇÂ∏∏ÂÄºÊ£ÄÊµãIQRÊñπÊ≥ï',
          code: `# Áº∫Â§±ÂÄºÂ§ÑÁêÜ
df.isnull().sum()       # ÊØèÂàóÁº∫Â§±ÂÄºÊï∞Èáè
df.dropna()             # Âà†Èô§ÂåÖÂê´Áº∫Â§±ÂÄºÁöÑË°å
df.dropna(subset=['age'])  # Âà†Èô§ageÂàó‰∏∫Á©∫ÁöÑË°å
df.fillna(0)            # Áî®0Â°´ÂÖÖÁº∫Â§±ÂÄº
df['age'].fillna(df['age'].mean())  # Áî®ÂùáÂÄºÂ°´ÂÖÖ

# ÈáçÂ§çÂÄºÂ§ÑÁêÜ
df.duplicated().sum()   # ÈáçÂ§çË°åÊï∞Èáè
df.drop_duplicates()    # Âà†Èô§ÈáçÂ§çË°å
df.drop_duplicates(subset=['user_id'], keep='first')  # Âü∫‰∫éuser_idÂéªÈáç

# Êï∞ÊçÆÁ±ªÂûãËΩ¨Êç¢
df['age'] = df['age'].astype(int)
df['date'] = pd.to_datetime(df['date'])

# ÊõøÊç¢ÂÄº
df['gender'].replace({'M': 'Áî∑', 'F': 'Â•≥'})
df['sales'].replace(0, np.nan)  # 0ÊõøÊç¢‰∏∫NaN

# ÈáçÂëΩÂêçÂàó
df.rename(columns={'old_name': 'new_name'})

# Âà†Èô§Âàó
df.drop(columns=['col1', 'col2'])
df.drop(['col1', 'col2'], axis=1)  # Á≠â‰ª∑ÂÜôÊ≥ï`
        },
        {
          emoji: 'üìä',
          title: 'GroupByÂàÜÁªÑËÅöÂêà ‚òÜ',
          desc: 'SQLÁöÑGROUP BYÂú®Pandas‰∏≠ÁöÑÂÆûÁé∞ ‚Äî‚Äî ‰∏öÂä°ÂàÜÊûêÊ†∏ÂøÉ',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöÂàÜÂú∞Âå∫ÁªüËÆ°ÈîÄÂîÆÈ¢ù„ÄÅÊåâÊó∂Èó¥ËÅöÂêàÊï∞ÊçÆ„ÄÅÁî®Êà∑ÂàÜÁæ§ÂàÜÊûê\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöËÅöÂêàÂêéÁ¥¢Âºï‰ºöÂèòÔºåÈúÄË¶Åreset_index()\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**Ôºötransform()„ÄÅfilter()„ÄÅagg()Â§öÁßçËÅöÂêà',
          code: `# Âü∫Á°ÄÂàÜÁªÑËÅöÂêà
df.groupby('category')['sales'].sum()  # ÊåâÁ±ªÂà´Ê±ÇÈîÄÂîÆÈ¢ùÊÄªÂíå
df.groupby('region')['amount'].mean()  # ÊåâÂú∞Âå∫Ê±ÇÂπ≥ÂùáÈáëÈ¢ù

# Â§öÂàóÂàÜÁªÑ
df.groupby(['region', 'category'])['sales'].sum()

# Â§öÁßçËÅöÂêà
df.groupby('category').agg({
    'sales': 'sum',
    'quantity': 'sum',
    'price': 'mean'
})

# Ëá™ÂÆö‰πâËÅöÂêàÂáΩÊï∞
df.groupby('category')['sales'].agg(['sum', 'mean', 'count', 'max'])

# ÈáçÁΩÆÁ¥¢ÂºïÔºàÈáçË¶ÅÔºÅÔºâ
result = df.groupby('category')['sales'].sum().reset_index()

# transformÔºà‰øùÊåÅÂéüDataFrameÂΩ¢Áä∂Ôºâ
df['sales_pct'] = df.groupby('category')['sales'].transform(lambda x: x / x.sum())

# ÂÆûÊàòÊ°à‰æãÔºöËÆ°ÁÆóÊØè‰∏™Áî®Êà∑ÁöÑÊ∂àË¥πÈáëÈ¢ùÂç†ÊØî
df['user_sales_pct'] = df.groupby('user_id')['amount'].transform(lambda x: x / x.sum() * 100)`
        },
        {
          emoji: 'üîó',
          title: 'Êï∞ÊçÆÂêàÂπ∂Ôºàmerge/joinÔºâ‚òÜ',
          desc: 'SQLÁöÑJOINÂú®Pandas‰∏≠ÁöÑÂÆûÁé∞ ‚Äî‚Äî Â§öË°®ÂÖ≥ËÅîÂàÜÊûê',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöÁî®Êà∑Ë°®ÂÖ≥ËÅîËÆ¢ÂçïË°®„ÄÅ‰∫ßÂìÅË°®ÂÖ≥ËÅîÈîÄÂîÆË°®\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöÊ≥®ÊÑèleft/right/inner/outerÁöÑÂå∫Âà´ÔºåÊï∞ÊçÆËÜ®ËÉÄÈóÆÈ¢ò\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**Ôºöconcat()Á∫µÂêëÊãºÊé•„ÄÅjoin()ÊñπÊ≥ï',
          code: `# Inner JoinÔºàÂÜÖËøûÊé•Ôºå‰∏§Ë°®ÈÉΩÊúâÁöÑËÆ∞ÂΩïÔºâ
pd.merge(df_users, df_orders, on='user_id', how='inner')

# Left JoinÔºàÂ∑¶ËøûÊé•Ôºå‰øùÁïôÂ∑¶Ë°®ÊâÄÊúâËÆ∞ÂΩïÔºâ
pd.merge(df_users, df_orders, on='user_id', how='left')

# Â§öÈîÆÂÖ≥ËÅî
pd.merge(df1, df2, on=['key1', 'key2'])

# ÂàóÂêç‰∏çÂêåÊó∂ÂÖ≥ËÅî
pd.merge(df1, df2, left_on='user_id', right_on='uid')

# Á∫µÂêëÊãºÊé•ÔºàÂêàÂπ∂Â§ö‰∏™DataFrameÔºâ
pd.concat([df1, df2, df3], ignore_index=True)

# ÂÆûÊàòÊ°à‰æãÔºöÁî®Êà∑ËÆ¢ÂçïÂàÜÊûê
users = pd.DataFrame({
    'user_id': [1, 2, 3],
    'name': ['Alice', 'Bob', 'Charlie']
})

orders = pd.DataFrame({
    'order_id': [101, 102, 103],
    'user_id': [1, 1, 2],
    'amount': [100, 200, 150]
})

# ÂÖ≥ËÅîÂπ∂ÁªüËÆ°ÊØè‰∏™Áî®Êà∑ÁöÑËÆ¢ÂçïÊï∞ÂíåÊÄªÈáëÈ¢ù
result = pd.merge(users, orders, on='user_id', how='left')
user_stats = result.groupby(['user_id', 'name']).agg({
    'order_id': 'count',
    'amount': 'sum'
}).rename(columns={'order_id': 'order_count', 'amount': 'total_amount'})`
        },
        {
          emoji: 'üìÖ',
          title: 'Êó∂Èó¥Â∫èÂàóÂ§ÑÁêÜ',
          desc: 'Êó•ÊúüÊó∂Èó¥Êï∞ÊçÆÂ§ÑÁêÜ ‚Äî‚Äî ‰∏öÂä°ÂàÜÊûêÂøÖÂ§á',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöÊåâÊó•/Âë®/ÊúàËÅöÂêàÊï∞ÊçÆ„ÄÅËÆ°ÁÆóÂêåÊØîÁéØÊØî„ÄÅÊó∂Èó¥Á™óÂè£ÂàÜÊûê\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöÊó∂Âå∫ÈóÆÈ¢ò„ÄÅÊó•ÊúüÊ†ºÂºèËß£ÊûêÂ§±Ë¥•\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**Ôºöresample()ÈáçÈááÊ†∑„ÄÅrolling()ÁßªÂä®Á™óÂè£„ÄÅÊó∂Èó¥ÂÅèÁßª',
          code: `# Êó•ÊúüËΩ¨Êç¢
df['date'] = pd.to_datetime(df['date'])
df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')

# ÊèêÂèñÊó•ÊúüÁªÑ‰ª∂
df['year'] = df['date'].dt.year
df['month'] = df['date'].dt.month
df['day'] = df['date'].dt.day
df['weekday'] = df['date'].dt.dayofweek  # 0=Monday
df['week'] = df['date'].dt.isocalendar().week

# Êó•ÊúüÁ≠õÈÄâ
df[df['date'] >= '2024-01-01']
df[(df['date'] >= '2024-01-01') & (df['date'] <= '2024-01-31')]

# ÊåâÊó∂Èó¥ËÅöÂêà
df.set_index('date').resample('D').sum()   # ÊåâÊó•ËÅöÂêà
df.set_index('date').resample('W').mean()  # ÊåâÂë®ËÅöÂêà
df.set_index('date').resample('M').sum()   # ÊåâÊúàËÅöÂêà

# ÁßªÂä®Á™óÂè£ÔºàËÆ°ÁÆóÁßªÂä®Âπ≥ÂùáÔºâ
df['sales_ma7'] = df.set_index('date')['sales'].rolling(window=7).mean()

# ÂÆûÊàòÔºöËÆ°ÁÆóÂêåÊØîÂ¢ûÈïøÁéá
df_monthly = df.set_index('date').resample('M').sum()
df_monthly['yoy_growth'] = df_monthly['sales'].pct_change(periods=12) * 100`
        }
      ]
    },
    {
      id: 'matplotlib-seaborn',
      title: 'PART 05 Matplotlib & SeabornÂèØËßÜÂåñ',
      subtitle: '‰∏ÄÂõæËÉúÂçÉË®Ä ‚Äî‚Äî ËÆ©Êï∞ÊçÆËØ¥ËØù',
      items: [
        {
          emoji: 'üìä',
          title: 'MatplotlibÂü∫Á°Ä ‚òÜ',
          desc: 'PythonÊúÄÂü∫Á°ÄÁöÑÁªòÂõæÂ∫ìÔºåÈ´òÂ∫¶ÂèØÂÆöÂà∂',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöÁªòÂà∂ÊäòÁ∫øÂõæ„ÄÅÊü±Áä∂Âõæ„ÄÅÊï£ÁÇπÂõæ„ÄÅÈ•ºÂõæ\\n**ÊòìË∏©ÂùëÁÇπ**Ôºö‰∏≠ÊñáÊòæÁ§∫‰π±Á†Å„ÄÅÂõæ‰æã‰ΩçÁΩÆ„ÄÅÂùêÊ†áËΩ¥ÂàªÂ∫¶\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºösubplotsÂ≠êÂõæÂ∏ÉÂ±Ä„ÄÅËá™ÂÆö‰πâÊ†∑Âºè„ÄÅÂä®Áîª',
          code: `import matplotlib.pyplot as plt
import numpy as np

# Ëß£ÂÜ≥‰∏≠ÊñáÊòæÁ§∫ÈóÆÈ¢ò
plt.rcParams['font.sans-serif'] = ['SimHei']  # Èªë‰Ωì
plt.rcParams['axes.unicode_minus'] = False

# ÊäòÁ∫øÂõæ
x = np.arange(1, 13)
sales = [100, 120, 110, 130, 150, 140, 160, 180, 170, 190, 200, 210]
plt.figure(figsize=(10, 6))
plt.plot(x, sales, marker='o', linewidth=2, color='#19bcc8')
plt.title('2024Âπ¥ÊúàÂ∫¶ÈîÄÂîÆÈ¢ùË∂ãÂäø', fontsize=16, fontweight='bold')
plt.xlabel('Êúà‰ªΩ', fontsize=12)
plt.ylabel('ÈîÄÂîÆÈ¢ùÔºà‰∏áÂÖÉÔºâ', fontsize=12)
plt.grid(True, alpha=0.3)
plt.show()

# Êü±Áä∂Âõæ
categories = ['ÁîµÂ≠ê‰∫ßÂìÅ', 'ÊúçË£Ö', 'È£üÂìÅ', 'Âõæ‰π¶', 'ÂÆ∂Â±Ö']
values = [450, 320, 280, 150, 200]
plt.figure(figsize=(8, 6))
plt.bar(categories, values, color='#19bcc8', alpha=0.8)
plt.title('ÂêÑÂìÅÁ±ªÈîÄÂîÆÈ¢ùÂØπÊØî', fontsize=16)
plt.ylabel('ÈîÄÂîÆÈ¢ùÔºà‰∏áÂÖÉÔºâ', fontsize=12)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Êï£ÁÇπÂõæ
x = np.random.randn(100)
y = 2 * x + np.random.randn(100)
plt.figure(figsize=(8, 6))
plt.scatter(x, y, alpha=0.6, s=50, color='#19bcc8')
plt.title('Áî®Êà∑Ê¥ªË∑ÉÂ∫¶ vs Ê∂àË¥πÈáëÈ¢ù', fontsize=16)
plt.xlabel('Ê¥ªË∑ÉÂ∫¶', fontsize=12)
plt.ylabel('Ê∂àË¥πÈáëÈ¢ù', fontsize=12)
plt.show()

# È•ºÂõæ
labels = ['Áõ¥ÈîÄ', '‰ª£ÁêÜÂïÜ', 'ÁîµÂïÜ', 'ÂÖ∂‰ªñ']
sizes = [35, 25, 30, 10]
colors = ['#19bcc8', '#ff6b6b', '#ffd93d', '#6bcf7f']
plt.figure(figsize=(8, 6))
plt.pie(sizes, labels=labels, autopct='%1.1f%%', colors=colors, startangle=90)
plt.title('ÈîÄÂîÆÊ∏†ÈÅìÂç†ÊØî', fontsize=16)
plt.axis('equal')
plt.show()`
        },
        {
          emoji: 'üé®',
          title: 'SeabornÈ´òÁ∫ßÂèØËßÜÂåñ ‚òÜ',
          desc: 'Âü∫‰∫éMatplotlibÁöÑÈ´òÁ∫ßÂèØËßÜÂåñÂ∫ìÔºåÊ†∑ÂºèÊõ¥ÁæéËßÇ',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöÊï∞ÊçÆÂàÜÂ∏ÉÂàÜÊûê„ÄÅÁõ∏ÂÖ≥ÊÄßÂàÜÊûê„ÄÅÂàÜÁªÑÂØπÊØî\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöÈúÄË¶ÅDataFrameÊ†ºÂºèÊï∞ÊçÆ„ÄÅhueÂèÇÊï∞‰ΩøÁî®\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöFacetGridÂ§öÂ≠êÂõæ„ÄÅPairGridÈÖçÂØπÂõæ',
          code: `import seaborn as sns
import pandas as pd

# ËÆæÁΩÆÊ†∑Âºè
sns.set_style("whitegrid")
sns.set_palette("husl")

# Êï∞ÊçÆÂáÜÂ§á
df = pd.DataFrame({
    'category': ['A', 'B', 'C', 'D', 'E'] * 20,
    'value': np.random.randn(100) * 10 + 50,
    'region': np.random.choice(['ÂåóÂå∫', 'ÂçóÂå∫'], 100)
})

# ÁÆ±Á∫øÂõæÔºàÊü•ÁúãÂàÜÂ∏ÉÂíåÂºÇÂ∏∏ÂÄºÔºâ
plt.figure(figsize=(10, 6))
sns.boxplot(data=df, x='category', y='value', hue='region')
plt.title('ÂêÑÂìÅÁ±ªÈîÄÂîÆÈ¢ùÂàÜÂ∏ÉÔºàÂàÜÂú∞Âå∫Ôºâ', fontsize=16)
plt.show()

# Â∞èÊèêÁê¥ÂõæÔºàÊõ¥ËØ¶ÁªÜÁöÑÂàÜÂ∏ÉÔºâ
plt.figure(figsize=(10, 6))
sns.violinplot(data=df, x='category', y='value')
plt.title('ÂêÑÂìÅÁ±ªÈîÄÂîÆÈ¢ùÂàÜÂ∏É', fontsize=16)
plt.show()

# ÁÉ≠ÂäõÂõæÔºàÁõ∏ÂÖ≥ÊÄßÂàÜÊûêÔºâ
data = pd.DataFrame(np.random.randn(10, 5), 
                    columns=['ÈîÄÂîÆÈ¢ù', 'ËÆøÈóÆÈáè', 'ËΩ¨ÂåñÁéá', 'ÂÆ¢Âçï‰ª∑', 'Â§çË¥≠Áéá'])
plt.figure(figsize=(8, 6))
sns.heatmap(data.corr(), annot=True, cmap='coolwarm', center=0,
            linewidths=1, square=True)
plt.title('‰∏öÂä°ÊåáÊ†áÁõ∏ÂÖ≥ÊÄßÁü©Èòµ', fontsize=16)
plt.show()

# ÂàÜÁªÑÊü±Áä∂Âõæ
plt.figure(figsize=(10, 6))
sns.barplot(data=df, x='category', y='value', hue='region')
plt.title('ÂêÑÂìÅÁ±ªÈîÄÂîÆÈ¢ùÂØπÊØîÔºàÂàÜÂú∞Âå∫Ôºâ', fontsize=16)
plt.show()

# ÂõûÂΩíÂõæÔºàË∂ãÂäøÂàÜÊûêÔºâ
plt.figure(figsize=(8, 6))
sns.regplot(data=df, x='value', y=df['value'] * 1.5 + np.random.randn(100) * 5)
plt.title('ÈîÄÂîÆÈ¢ù vs Âà©Ê∂¶ ÂõûÂΩíÂàÜÊûê', fontsize=16)
plt.show()`
        },
        {
          emoji: 'üìà',
          title: 'Â∏∏Áî®ÂõæË°®ÈÄüÊü•',
          desc: 'Êï∞ÊçÆÂàÜÊûêÊúÄÂ∏∏Áî®ÁöÑ10ÁßçÂõæË°®ÂèäÂ∫îÁî®Âú∫ÊôØ',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöÊ†πÊçÆÊï∞ÊçÆÁ±ªÂûãÂíåÂàÜÊûêÁõÆÊ†áÈÄâÊã©ÂêàÈÄÇÁöÑÂõæË°®\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöÂõæË°®ÈÄâÊã©‰∏çÂΩìÂØºËá¥‰ø°ÊÅØ‰º†ËææÂ§±Áúü\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöPlotly‰∫§‰∫íÂºèÂõæË°®„ÄÅPyecharts',
          code: `# 1. ÊäòÁ∫øÂõæ - Ë∂ãÂäøÂàÜÊûê
df.plot(x='date', y='sales', kind='line', figsize=(10, 6))

# 2. Êü±Áä∂Âõæ - Á±ªÂà´ÂØπÊØî
df.plot(x='category', y='value', kind='bar', figsize=(8, 6))

# 3. Ê∞¥Âπ≥Êü±Áä∂Âõæ - ÊéíÂêçÂ±ïÁ§∫
df.plot(x='name', y='score', kind='barh', figsize=(8, 6))

# 4. Êï£ÁÇπÂõæ - Áõ∏ÂÖ≥ÊÄßÂàÜÊûê
df.plot(x='age', y='income', kind='scatter', figsize=(8, 6))

# 5. Áõ¥ÊñπÂõæ - Êï∞ÊçÆÂàÜÂ∏É
df['age'].plot(kind='hist', bins=20, figsize=(8, 6))

# 6. È•ºÂõæ - Âç†ÊØîÂàÜÊûê
df.groupby('category')['value'].sum().plot(kind='pie', figsize=(8, 8))

# 7. ÁÆ±Á∫øÂõæ - ÂºÇÂ∏∏ÂÄºÊ£ÄÊµã
df.boxplot(column='sales', by='region', figsize=(10, 6))

# 8. Èù¢ÁßØÂõæ - Á¥ØÁßØË∂ãÂäø
df.plot(x='date', y=['‰∫ßÂìÅA', '‰∫ßÂìÅB', '‰∫ßÂìÅC'], kind='area', 
        stacked=True, figsize=(10, 6))

# 9. Â§öÂ≠êÂõæÂØπÊØî
fig, axes = plt.subplots(2, 2, figsize=(12, 10))
df.plot(ax=axes[0, 0], x='date', y='sales', kind='line')
df.plot(ax=axes[0, 1], x='category', y='value', kind='bar')
df.plot(ax=axes[1, 0], x='age', y='income', kind='scatter')
df['age'].plot(ax=axes[1, 1], kind='hist', bins=20)
plt.tight_layout()
plt.show()

# 10. ‰øùÂ≠òÂõæË°®
plt.savefig('sales_analysis.png', dpi=300, bbox_inches='tight')`
        }
      ]
    },
    {
      id: 'data-cleaning',
      title: 'PART 06 Êï∞ÊçÆÊ∏ÖÊ¥óËøõÈò∂',
      subtitle: 'Êï∞ÊçÆË¥®ÈáèÂÜ≥ÂÆöÂàÜÊûêË¥®Èáè ‚Äî‚Äî 80%Êó∂Èó¥Ëä±Âú®Êï∞ÊçÆÊ∏ÖÊ¥ó',
      items: [
        {
          emoji: 'üßπ',
          title: 'Áº∫Â§±ÂÄºÂ§ÑÁêÜÁ≠ñÁï• ‚òÜ',
          desc: '‰∏çÂêåÂú∫ÊôØ‰∏ãÁöÑÁº∫Â§±ÂÄºÂ§ÑÁêÜÊñπÊ≥ï',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöÁî®Êà∑‰ø°ÊÅØÁº∫Â§±„ÄÅËÆ¢ÂçïÈáëÈ¢ùÁº∫Â§±„ÄÅÊó∂Èó¥Â∫èÂàóÊñ≠ÁÇπ\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöÁõ≤ÁõÆÂà†Èô§Áº∫Â§±ÂÄºÂØºËá¥Ê†∑Êú¨Èáè‰∏çË∂≥„ÄÅÂ°´ÂÖÖÊñπÊ≥ï‰∏çÂΩì\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöMICEÂ§öÈáçÊèíË°•„ÄÅKNNÊèíË°•',
          code: `import pandas as pd
import numpy as np

# Êü•ÁúãÁº∫Â§±ÂÄºÊÉÖÂÜµ
df.isnull().sum()
df.isnull().sum() / len(df) * 100  # Áº∫Â§±Áéá

# ÂèØËßÜÂåñÁº∫Â§±ÂÄºÊ®°Âºè
import missingno as msno
msno.matrix(df)  # Áº∫Â§±ÂÄºÁü©ÈòµÂõæ
msno.heatmap(df)  # Áº∫Â§±ÂÄºÁõ∏ÂÖ≥ÊÄßÁÉ≠ÂäõÂõæ

# 1. Âà†Èô§Á≠ñÁï•ÔºàÁº∫Â§±Áéá<5%Ôºâ
df.dropna(subset=['user_id'])  # Âà†Èô§ÂÖ≥ÈîÆÂ≠óÊÆµÁº∫Â§±ÁöÑË°å
df.dropna(thresh=10)  # ‰øùÁïôËá≥Â∞ë10‰∏™ÈùûÁ©∫ÂÄºÁöÑË°å

# 2. Â°´ÂÖÖÁ≠ñÁï• - Êï∞ÂÄºÂûã
df['age'].fillna(df['age'].mean())    # ÂùáÂÄºÂ°´ÂÖÖ
df['income'].fillna(df['income'].median())  # ‰∏≠‰ΩçÊï∞Â°´ÂÖÖÔºàÊúâÂºÇÂ∏∏ÂÄºÊó∂Ôºâ
df['sales'].fillna(df['sales'].mode()[0])  # ‰ºóÊï∞Â°´ÂÖÖ

# 3. Â°´ÂÖÖÁ≠ñÁï• - ÂàÜÁªÑÂ°´ÂÖÖÔºàÊõ¥ÂêàÁêÜÔºâ
df['age'] = df.groupby('city')['age'].transform(
    lambda x: x.fillna(x.mean())
)

# 4. Â°´ÂÖÖÁ≠ñÁï• - Á±ªÂà´Âûã
df['category'].fillna('Êú™Áü•')
df['region'].fillna(df['region'].mode()[0])

# 5. ÂâçÂêë/ÂêéÂêëÂ°´ÂÖÖÔºàÊó∂Èó¥Â∫èÂàóÔºâ
df['sales'].fillna(method='ffill')  # Áî®Ââç‰∏Ä‰∏™ÂÄºÂ°´ÂÖÖ
df['sales'].fillna(method='bfill')  # Áî®Âêé‰∏Ä‰∏™ÂÄºÂ°´ÂÖÖ

# 6. ÊèíÂÄºÂ°´ÂÖÖÔºàÊó∂Èó¥Â∫èÂàóÔºâ
df['sales'].interpolate(method='linear')  # Á∫øÊÄßÊèíÂÄº
df['sales'].interpolate(method='polynomial', order=2)  # Â§öÈ°πÂºèÊèíÂÄº

# 7. Ê†áËÆ∞Áº∫Â§±ÂÄºÔºà‰øùÁïô‰ø°ÊÅØÔºâ
df['age_missing'] = df['age'].isnull().astype(int)
df['age'].fillna(df['age'].median())`
        },
        {
          emoji: 'üîç',
          title: 'ÂºÇÂ∏∏ÂÄºÊ£ÄÊµã‰∏éÂ§ÑÁêÜ ‚òÜ',
          desc: 'IQR„ÄÅZ-score„ÄÅ‰∏öÂä°ËßÑÂàô‰∏âÂ§ßÊñπÊ≥ï',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöËÆ¢ÂçïÈáëÈ¢ùÂºÇÂ∏∏„ÄÅÁî®Êà∑Âπ¥ÈæÑÂºÇÂ∏∏„ÄÅÈîÄÈáèÁ™ÅÂ¢û\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöËØØÂà†Ê≠£Â∏∏ÊûÅÂÄº„ÄÅÈòàÂÄºËÆæÁΩÆ‰∏çÂêàÁêÜ\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöÂ≠§Á´ãÊ£ÆÊûó„ÄÅDBSCANËÅöÁ±ªÊ£ÄÊµã',
          code: `# 1. IQRÊñπÊ≥ïÔºàÂõõÂàÜ‰ΩçË∑ùÔºâ- ÊúÄÂ∏∏Áî®
Q1 = df['sales'].quantile(0.25)
Q3 = df['sales'].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Ê†áËÆ∞ÂºÇÂ∏∏ÂÄº
df['is_outlier'] = (df['sales'] < lower_bound) | (df['sales'] > upper_bound)

# Âà†Èô§ÂºÇÂ∏∏ÂÄº
df_clean = df[(df['sales'] >= lower_bound) & (df['sales'] <= upper_bound)]

# 2. Z-scoreÊñπÊ≥ïÔºàÊ†áÂáÜÂ∑ÆÔºâ
from scipy import stats
df['z_score'] = np.abs(stats.zscore(df['sales']))
df_clean = df[df['z_score'] < 3]  # ‰øùÁïô3‰∏™Ê†áÂáÜÂ∑ÆÂÜÖÁöÑÊï∞ÊçÆ

# 3. ‰∏öÂä°ËßÑÂàô
df_clean = df[
    (df['age'] >= 0) & (df['age'] <= 120) &  # Âπ¥ÈæÑÂêàÁêÜËåÉÂõ¥
    (df['price'] > 0) &  # ‰ª∑Ê†ºÂøÖÈ°ª‰∏∫Ê≠£
    (df['quantity'] > 0) & (df['quantity'] <= 1000)  # Êï∞ÈáèÂêàÁêÜËåÉÂõ¥
]

# 4. ÁôæÂàÜ‰ΩçÊï∞Êà™Êñ≠ÔºàWinsorizationÔºâ
lower = df['sales'].quantile(0.01)
upper = df['sales'].quantile(0.99)
df['sales_clean'] = df['sales'].clip(lower, upper)

# 5. ÂèØËßÜÂåñÊ£ÄÊµã
import seaborn as sns
plt.figure(figsize=(12, 4))
plt.subplot(1, 3, 1)
sns.boxplot(y=df['sales'])
plt.title('ÁÆ±Á∫øÂõæÊ£ÄÊµãÂºÇÂ∏∏ÂÄº')

plt.subplot(1, 3, 2)
df['sales'].hist(bins=50)
plt.title('Áõ¥ÊñπÂõæÊ£ÄÊµãÂºÇÂ∏∏ÂÄº')

plt.subplot(1, 3, 3)
stats.probplot(df['sales'], dist="norm", plot=plt)
plt.title('Q-QÂõæÊ£ÄÊµãÂºÇÂ∏∏ÂÄº')
plt.tight_layout()
plt.show()`
        },
        {
          emoji: 'üîÑ',
          title: 'Êï∞ÊçÆÁ±ªÂûãËΩ¨Êç¢',
          desc: 'Ê≠£Á°ÆÁöÑÊï∞ÊçÆÁ±ªÂûãÊòØÂàÜÊûêÁöÑÂü∫Á°Ä',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöÊó•ÊúüÂ≠óÁ¨¶‰∏≤ËΩ¨Êó•Êúü„ÄÅÊï∞ÂÄºÂ≠óÁ¨¶‰∏≤ËΩ¨Êï∞Â≠ó„ÄÅÁ±ªÂà´ÁºñÁ†Å\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöÁ±ªÂûãËΩ¨Êç¢Â§±Ë¥•„ÄÅÁ≤æÂ∫¶‰∏¢Â§±„ÄÅÊó∂Âå∫ÈóÆÈ¢ò\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöCategoricalÊï∞ÊçÆÁ±ªÂûãËäÇÁúÅÂÜÖÂ≠ò',
          code: `# 1. Êï∞ÂÄºÁ±ªÂûãËΩ¨Êç¢
df['price'] = pd.to_numeric(df['price'], errors='coerce')  # ËΩ¨Êç¢Â§±Ë¥•ÂèòNaN
df['quantity'] = df['quantity'].astype(int)

# 2. Êó•ÊúüÁ±ªÂûãËΩ¨Êç¢
df['date'] = pd.to_datetime(df['date'])
df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')
df['date'] = pd.to_datetime(df['date'], errors='coerce')

# 3. Â≠óÁ¨¶‰∏≤Á±ªÂûã
df['user_id'] = df['user_id'].astype(str)

# 4. Á±ªÂà´Á±ªÂûãÔºàËäÇÁúÅÂÜÖÂ≠òÔºâ
df['category'] = df['category'].astype('category')

# 5. Â∏ÉÂ∞îÁ±ªÂûã
df['is_vip'] = df['is_vip'].astype(bool)

# 6. ÊâπÈáèËΩ¨Êç¢
df = df.astype({
    'user_id': str,
    'age': int,
    'sales': float,
    'category': 'category',
    'is_active': bool
})

# 7. Â§ÑÁêÜÂçÉÂàÜ‰Ωç„ÄÅÁôæÂàÜÂè∑
df['amount'] = df['amount'].str.replace(',', '').astype(float)
df['rate'] = df['rate'].str.rstrip('%').astype(float) / 100

# 8. ‰ºòÂåñÂÜÖÂ≠òÂç†Áî®
def reduce_mem_usage(df):
    for col in df.columns:
        col_type = df[col].dtype
        if col_type != object:
            c_min = df[col].min()
            c_max = df[col].max()
            if str(col_type)[:3] == 'int':
                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                    df[col] = df[col].astype(np.int8)
                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                    df[col] = df[col].astype(np.int16)
    return df`
        }
      ]
    },
    {
      id: 'eda',
      title: 'PART 07 Êé¢Á¥¢ÊÄßÊï∞ÊçÆÂàÜÊûêÔºàEDAÔºâ',
      subtitle: '‰∫ÜËß£‰Ω†ÁöÑÊï∞ÊçÆ ‚Äî‚Äî ÂàÜÊûêÁöÑÁ¨¨‰∏ÄÊ≠•',
      items: [
        {
          emoji: 'üîç',
          title: 'EDAÊ†∏ÂøÉÊ≠•È™§ ‚òÜ',
          desc: 'Êï∞ÊçÆÊ¶ÇËßà ‚Üí ÂçïÂèòÈáèÂàÜÊûê ‚Üí ÂèåÂèòÈáèÂàÜÊûê ‚Üí Â§öÂèòÈáèÂàÜÊûê',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöÊñ∞Êï∞ÊçÆÈõÜÂàùÊ≠•Êé¢Á¥¢„ÄÅÂºÇÂ∏∏Ê£ÄÊµã„ÄÅÁâπÂæÅÈÄâÊã©\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöË∑≥ËøáEDAÁõ¥Êé•Âª∫Ê®°„ÄÅÂøΩÁï•Êï∞ÊçÆÂàÜÂ∏É\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**Ôºöpandas-profilingËá™Âä®ÂåñEDA',
          code: `import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# 1. Êï∞ÊçÆÊ¶ÇËßà
print("Êï∞ÊçÆÁª¥Â∫¶:", df.shape)
print("\\nÊï∞ÊçÆÁ±ªÂûã:\\n", df.dtypes)
print("\\nÂâç5Ë°å:\\n", df.head())
print("\\nÊèèËø∞ÁªüËÆ°:\\n", df.describe())
print("\\nÁº∫Â§±ÂÄº:\\n", df.isnull().sum())

# 2. ÂçïÂèòÈáèÂàÜÊûê - Êï∞ÂÄºÂûã
# Áõ¥ÊñπÂõæ
df['age'].hist(bins=30, figsize=(8, 6))
plt.title('Âπ¥ÈæÑÂàÜÂ∏É')
plt.show()

# ÁÆ±Á∫øÂõæ
df.boxplot(column='sales', figsize=(6, 8))
plt.title('ÈîÄÂîÆÈ¢ùÁÆ±Á∫øÂõæ')
plt.show()

# ÁªüËÆ°ÊëòË¶Å
print("ÂùáÂÄº:", df['sales'].mean())
print("‰∏≠‰ΩçÊï∞:", df['sales'].median())
print("Ê†áÂáÜÂ∑Æ:", df['sales'].std())
print("ÂÅèÂ∫¶:", df['sales'].skew())
print("Â≥∞Â∫¶:", df['sales'].kurt())

# 3. ÂçïÂèòÈáèÂàÜÊûê - Á±ªÂà´Âûã
df['category'].value_counts()
df['category'].value_counts().plot(kind='bar', figsize=(8, 6))
plt.title('ÂêÑÁ±ªÂà´Êï∞ÈáèÂàÜÂ∏É')
plt.show()

# 4. ÂèåÂèòÈáèÂàÜÊûê - Êï∞ÂÄº vs Êï∞ÂÄº
df.plot(x='age', y='income', kind='scatter', figsize=(8, 6))
plt.title('Âπ¥ÈæÑ vs Êî∂ÂÖ•')
plt.show()

# Áõ∏ÂÖ≥Á≥ªÊï∞
df[['age', 'income', 'sales']].corr()

# 5. ÂèåÂèòÈáèÂàÜÊûê - Á±ªÂà´ vs Êï∞ÂÄº
df.groupby('category')['sales'].mean().plot(kind='bar', figsize=(8, 6))
plt.title('ÂêÑÁ±ªÂà´Âπ≥ÂùáÈîÄÂîÆÈ¢ù')
plt.show()

sns.boxplot(data=df, x='category', y='sales', figsize=(10, 6))
plt.title('ÂêÑÁ±ªÂà´ÈîÄÂîÆÈ¢ùÂàÜÂ∏É')
plt.show()

# 6. Â§öÂèòÈáèÂàÜÊûê - Áõ∏ÂÖ≥ÊÄßÁü©Èòµ
plt.figure(figsize=(10, 8))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm', center=0)
plt.title('ÁâπÂæÅÁõ∏ÂÖ≥ÊÄßÁü©Èòµ')
plt.show()

# 7. Ëá™Âä®ÂåñEDAÔºàÊé®ËçêÔºÅÔºâ
# pip install pandas-profiling
from pandas_profiling import ProfileReport
profile = ProfileReport(df, title="Êï∞ÊçÆÂàÜÊûêÊä•Âëä")
profile.to_file("eda_report.html")`
        },
        {
          emoji: 'üìä',
          title: 'Êï∞ÊçÆÂàÜÂ∏ÉÊ£ÄÈ™å',
          desc: 'Ê≠£ÊÄÅÊÄßÊ£ÄÈ™å„ÄÅÂÅèÂ∫¶Â≥∞Â∫¶ÂàÜÊûê',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöÈÄâÊã©ÁªüËÆ°Ê£ÄÈ™åÊñπÊ≥ï„ÄÅÁâπÂæÅÂ∑•Á®ãÂâçÁöÑÂàÜÂ∏ÉÂàÜÊûê\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöÂÅáËÆæÊï∞ÊçÆÁ¨¶ÂêàÊ≠£ÊÄÅÂàÜÂ∏É„ÄÅÂøΩÁï•ÈïøÂ∞æÂàÜÂ∏É\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöBox-CoxÂèòÊç¢„ÄÅYeo-JohnsonÂèòÊç¢',
          code: `from scipy import stats
import matplotlib.pyplot as plt

# 1. Ê≠£ÊÄÅÊÄßÊ£ÄÈ™å
# Shapiro-WilkÊ£ÄÈ™å
statistic, p_value = stats.shapiro(df['sales'])
print(f"Shapiro-WilkÊ£ÄÈ™å: p-value={p_value:.4f}")
if p_value > 0.05:
    print("Êï∞ÊçÆÁ¨¶ÂêàÊ≠£ÊÄÅÂàÜÂ∏É")
else:
    print("Êï∞ÊçÆ‰∏çÁ¨¶ÂêàÊ≠£ÊÄÅÂàÜÂ∏É")

# 2. Q-QÂõæÔºàÂèØËßÜÂåñÊ≠£ÊÄÅÊÄßÔºâ
plt.figure(figsize=(8, 6))
stats.probplot(df['sales'], dist="norm", plot=plt)
plt.title('Q-QÂõæÊ£ÄÈ™åÊ≠£ÊÄÅÊÄß')
plt.show()

# 3. ÂÅèÂ∫¶ÂíåÂ≥∞Â∫¶
skewness = df['sales'].skew()
kurtosis = df['sales'].kurt()
print(f"ÂÅèÂ∫¶: {skewness:.2f}")  # >0Âè≥ÂÅèÔºå<0Â∑¶ÂÅè
print(f"Â≥∞Â∫¶: {kurtosis:.2f}")  # >0Â∞ñÂ≥∞Ôºå<0Âπ≥Â≥∞

# 4. Êï∞ÊçÆÂèòÊç¢ÔºàÂ§ÑÁêÜÂÅèÊÄÅÂàÜÂ∏ÉÔºâ
# ÂØπÊï∞ÂèòÊç¢
df['sales_log'] = np.log1p(df['sales'])

# Âπ≥ÊñπÊ†πÂèòÊç¢
df['sales_sqrt'] = np.sqrt(df['sales'])

# Box-CoxÂèòÊç¢
df['sales_boxcox'], lambda_param = stats.boxcox(df['sales'] + 1)

# ÂØπÊØîÂèòÊç¢ÂâçÂêé
fig, axes = plt.subplots(2, 2, figsize=(12, 10))
df['sales'].hist(bins=50, ax=axes[0, 0])
axes[0, 0].set_title('ÂéüÂßãÊï∞ÊçÆ')
df['sales_log'].hist(bins=50, ax=axes[0, 1])
axes[0, 1].set_title('ÂØπÊï∞ÂèòÊç¢')
df['sales_sqrt'].hist(bins=50, ax=axes[1, 0])
axes[1, 0].set_title('Âπ≥ÊñπÊ†πÂèòÊç¢')
df['sales_boxcox'].hist(bins=50, ax=axes[1, 1])
axes[1, 1].set_title('Box-CoxÂèòÊç¢')
plt.tight_layout()
plt.show()`
        }
      ]
    },
    {
      id: 'sql-integration',
      title: 'PART 08 Python √ó SQLÈõÜÊàê',
      subtitle: 'PythonËøûÊé•Êï∞ÊçÆÂ∫ì ‚Äî‚Äî Êï∞ÊçÆÂàÜÊûêÁöÑÊï∞ÊçÆÊù•Ê∫ê',
      items: [
        {
          emoji: 'üîó',
          title: 'PyMySQLËøûÊé•MySQL ‚òÜ',
          desc: 'PythonËøûÊé•MySQLÊï∞ÊçÆÂ∫ìÔºåÊâßË°åSQLÊü•ËØ¢',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**Ôºö‰ªéÊï∞ÊçÆÂ∫ìËØªÂèñÊï∞ÊçÆ„ÄÅÂÜôÂÖ•ÂàÜÊûêÁªìÊûú\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöSQLÊ≥®ÂÖ•È£éÈô©„ÄÅËøûÊé•Êú™ÂÖ≥Èó≠„ÄÅÁºñÁ†ÅÈóÆÈ¢ò\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöËøûÊé•Ê±†„ÄÅ‰∫ãÂä°ÁÆ°ÁêÜ„ÄÅORMÊ°ÜÊû∂ÔºàSQLAlchemyÔºâ',
          code: `import pymysql
import pandas as pd

# 1. Âª∫Á´ãËøûÊé•
conn = pymysql.connect(
    host='localhost',
    user='root',
    password='your_password',
    database='sales_db',
    charset='utf8mb4'
)

# 2. ÊâßË°åÊü•ËØ¢ÔºàËøîÂõûDataFrameÔºâ
sql = "SELECT * FROM orders WHERE order_date >= '2024-01-01'"
df = pd.read_sql(sql, conn)

# 3. ÂèÇÊï∞ÂåñÊü•ËØ¢ÔºàÈò≤Ê≠¢SQLÊ≥®ÂÖ•Ôºâ
sql = "SELECT * FROM users WHERE user_id = %s"
df = pd.read_sql(sql, conn, params=(1001,))

# 4. ÂÜôÂÖ•Êï∞ÊçÆÂ∫ì
df.to_sql('analysis_result', conn, if_exists='replace', index=False)

# 5. ‰ΩøÁî®withËØ≠Âè•ÔºàËá™Âä®ÂÖ≥Èó≠ËøûÊé•Ôºâ
with pymysql.connect(**db_config) as conn:
    df = pd.read_sql("SELECT * FROM orders", conn)

# 6. SQLAlchemyÊñπÂºèÔºàÊé®ËçêÔºâ
from sqlalchemy import create_engine
engine = create_engine('mysql+pymysql://user:pass@localhost/db_name')
df = pd.read_sql("SELECT * FROM orders", engine)
df.to_sql('result', engine, if_exists='append', index=False)

# 7. ÊâπÈáèÊèíÂÖ•ÔºàÈ´òÊïàÔºâ
from sqlalchemy import create_engine
engine = create_engine('mysql+pymysql://user:pass@localhost/db')
df.to_sql('table_name', engine, if_exists='append', index=False, 
          method='multi', chunksize=1000)`
        }
      ]
    },
    {
      id: 'automation',
      title: 'PART 09 Ëá™Âä®ÂåñËÑöÊú¨',
      subtitle: 'ËÆ©Python‰∏∫‰Ω†Â∑•‰Ωú ‚Äî‚Äî Ëß£ÊîæÂèåÊâã',
      items: [
        {
          emoji: '‚ö°',
          title: 'Ëá™Âä®ÂåñÊï∞ÊçÆÊä•Ë°®ÁîüÊàê ‚òÜ',
          desc: 'ÂÆöÊó∂‰ªéÊï∞ÊçÆÂ∫ìÊèêÂèñÊï∞ÊçÆÔºåÁîüÊàêExcelÊä•Ë°®Âπ∂ÂèëÈÄÅÈÇÆ‰ª∂',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöÊØèÊó•ÈîÄÂîÆÊä•Ë°®„ÄÅÂë®Êä•„ÄÅÊúàÊä•Ëá™Âä®Âåñ\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöÊó∂Âå∫ÈóÆÈ¢ò„ÄÅÊñá‰ª∂Ë∑ØÂæÑ„ÄÅÈÇÆ‰ª∂ÂèëÈÄÅÂ§±Ë¥•\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöAPSchedulerÂÆöÊó∂‰ªªÂä°„ÄÅÊó•ÂøóËÆ∞ÂΩï',
          code: `import pandas as pd
import pymysql
from datetime import datetime, timedelta
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.base import MIMEBase
from email import encoders

# 1. ‰ªéÊï∞ÊçÆÂ∫ìËé∑ÂèñÊï∞ÊçÆ
def get_sales_data(start_date, end_date):
    conn = pymysql.connect(host='localhost', user='root', 
                          password='pass', database='sales_db')
    sql = f"""
    SELECT date, category, SUM(amount) as sales
    FROM orders
    WHERE date BETWEEN '{start_date}' AND '{end_date}'
    GROUP BY date, category
    """
    df = pd.read_sql(sql, conn)
    conn.close()
    return df

# 2. Êï∞ÊçÆÂàÜÊûê
def analyze_data(df):
    summary = df.groupby('category')['sales'].agg(['sum', 'mean', 'count'])
    summary = summary.sort_values('sum', ascending=False)
    return summary

# 3. ÁîüÊàêExcelÊä•Ë°®
def generate_report(df, summary, filename):
    with pd.ExcelWriter(filename, engine='openpyxl') as writer:
        df.to_excel(writer, sheet_name='ÊòéÁªÜÊï∞ÊçÆ', index=False)
        summary.to_excel(writer, sheet_name='Ê±áÊÄªÂàÜÊûê')
    return filename

# 4. ÂèëÈÄÅÈÇÆ‰ª∂
def send_email(to_email, subject, body, attachment_path):
    from_email = 'your_email@gmail.com'
    password = 'your_app_password'
    
    msg = MIMEMultipart()
    msg['From'] = from_email
    msg['To'] = to_email
    msg['Subject'] = subject
    msg.attach(MIMEText(body, 'plain', 'utf-8'))
    
    # ÈôÑ‰ª∂
    with open(attachment_path, 'rb') as f:
        part = MIMEBase('application', 'octet-stream')
        part.set_payload(f.read())
        encoders.encode_base64(part)
        part.add_header('Content-Disposition', 
                       f'attachment; filename={attachment_path}')
        msg.attach(part)
    
    # ÂèëÈÄÅ
    server = smtplib.SMTP('smtp.gmail.com', 587)
    server.starttls()
    server.login(from_email, password)
    server.send_message(msg)
    server.quit()

# 5. ‰∏ªÊµÅÁ®ã
def main():
    today = datetime.now()
    yesterday = today - timedelta(days=1)
    
    # Ëé∑ÂèñÊï∞ÊçÆ
    df = get_sales_data(yesterday, today)
    summary = analyze_data(df)
    
    # ÁîüÊàêÊä•Ë°®
    filename = f'ÈîÄÂîÆÊó•Êä•_{yesterday.strftime("%Y%m%d")}.xlsx'
    generate_report(df, summary, filename)
    
    # ÂèëÈÄÅÈÇÆ‰ª∂
    send_email('boss@company.com', 
              f'ÈîÄÂîÆÊó•Êä• {yesterday.strftime("%Y-%m-%d")}',
              'ÈôÑ‰ª∂ÊòØ‰ªäÊó•ÈîÄÂîÆÊï∞ÊçÆÂàÜÊûêÊä•ÂëäÔºåËØ∑Êü•Êî∂„ÄÇ',
              filename)
    
    print(f"Êä•Ë°®ÁîüÊàêÂπ∂ÂèëÈÄÅÊàêÂäü: {filename}")

if __name__ == '__main__':
    main()`
        }
      ]
    },
    {
      id: 'best-practices',
      title: 'PART 10 ÊúÄ‰Ω≥ÂÆûË∑µ',
      subtitle: 'ÂÜôÂá∫‰ºòÈõÖÈ´òÊïàÁöÑPython‰ª£Á†Å',
      items: [
        {
          emoji: '‚ú®',
          title: 'PandasÊÄßËÉΩ‰ºòÂåñ ‚òÜ',
          desc: 'ÂêëÈáèÂåñ„ÄÅÂàÜÂùóÂ§ÑÁêÜ„ÄÅÊï∞ÊçÆÁ±ªÂûã‰ºòÂåñ',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöÂ§ÑÁêÜÂ§ßÊï∞ÊçÆÈõÜÔºà>1GBÔºâ„ÄÅÊèêÂçá‰ª£Á†ÅËøêË°åÈÄüÂ∫¶\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöÂæ™ÁéØÈÅçÂéÜDataFrame„ÄÅÈ¢ëÁπÅÂ§çÂà∂Êï∞ÊçÆ\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöDask„ÄÅVaexÂ§ßÊï∞ÊçÆÂ§ÑÁêÜ',
          code: `# ‚ùå ÊÖ¢ÔºöÂæ™ÁéØÈÅçÂéÜDataFrame
for idx, row in df.iterrows():
    df.loc[idx, 'new_col'] = row['a'] + row['b']

# ‚úÖ Âø´ÔºöÂêëÈáèÂåñËøêÁÆóÔºàÂø´100ÂÄçÔºâ
df['new_col'] = df['a'] + df['b']

# ‚ùå ÊÖ¢ÔºöÈÄêË°åappend
result = pd.DataFrame()
for chunk in data_chunks:
    result = result.append(chunk)

# ‚úÖ Âø´Ôºö‰∏ÄÊ¨°ÊÄßconcat
result = pd.concat(data_chunks, ignore_index=True)

# ‰ºòÂåñÊï∞ÊçÆÁ±ªÂûãËäÇÁúÅÂÜÖÂ≠ò
df['category'] = df['category'].astype('category')
df['int_col'] = df['int_col'].astype('int32')  # int64‚Üíint32

# ÂàÜÂùóËØªÂèñÂ§ßÊñá‰ª∂
chunks = []
for chunk in pd.read_csv('big_file.csv', chunksize=10000):
    processed = process(chunk)
    chunks.append(processed)
df = pd.concat(chunks)

# ‰ΩøÁî®queryÊñπÊ≥ïÔºàÊõ¥Âø´Ôºâ
df.query('age > 30 and sales > 5000')  # ÊØîÂ∏ÉÂ∞îÁ¥¢ÂºïÂø´`
        },
        {
          emoji: 'üîí',
          title: '‰ª£Á†ÅËßÑËåÉ‰∏éÂèØÁª¥Êä§ÊÄß',
          desc: 'ÂëΩÂêçËßÑËåÉ„ÄÅÊ≥®Èáä„ÄÅÂºÇÂ∏∏Â§ÑÁêÜ',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöÂõ¢ÈòüÂçè‰Ωú„ÄÅ‰ª£Á†ÅÂÆ°Êü•„ÄÅÈïøÊúüÁª¥Êä§\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöÂèòÈáèÂêç‰∏çÊ∏ÖÊô∞„ÄÅÁº∫Â∞ëÂºÇÂ∏∏Â§ÑÁêÜ„ÄÅÁ°¨ÁºñÁ†Å\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöPEP 8ËßÑËåÉ„ÄÅÁ±ªÂûãÊ≥®Ëß£„ÄÅÂçïÂÖÉÊµãËØï',
          code: `# 1. ÂëΩÂêçËßÑËåÉ
# ‚ùå ‰∏çÂ•Ω
df1 = pd.read_csv('data.csv')
x = df1['sales'].sum()

# ‚úÖ Â•Ω
sales_data = pd.read_csv('sales_data.csv')
total_sales = sales_data['sales'].sum()

# 2. ÂºÇÂ∏∏Â§ÑÁêÜ
try:
    df = pd.read_csv('data.csv')
except FileNotFoundError:
    print("Êñá‰ª∂‰∏çÂ≠òÂú®")
    df = pd.DataFrame()
except Exception as e:
    print(f"ËØªÂèñÂ§±Ë¥•: {e}")
    df = pd.DataFrame()

# 3. ÈÖçÁΩÆÂ§ñÁΩÆ
# config.py
DB_CONFIG = {
    'host': 'localhost',
    'user': 'root',
    'password': 'pass',
    'database': 'sales_db'
}

# 4. ÂáΩÊï∞ÊñáÊ°£
def calculate_growth_rate(current, previous):
    """
    ËÆ°ÁÆóÂ¢ûÈïøÁéá
    
    Parameters:
    -----------
    current : float
        ÂΩìÂâçÂÄº
    previous : float
        ‰∏äÊúüÂÄº
    
    Returns:
    --------
    float : Â¢ûÈïøÁéáÔºà%Ôºâ
    """
    if previous == 0:
        return 0
    return (current - previous) / previous * 100

# 5. Êó•ÂøóËÆ∞ÂΩï
import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

logger.info("ÂºÄÂßãÂ§ÑÁêÜÊï∞ÊçÆ")
logger.warning("ÂèëÁé∞ÂºÇÂ∏∏ÂÄº")
logger.error("Â§ÑÁêÜÂ§±Ë¥•")`
        }
      ]
    },
    {
      id: 'common-mistakes',
      title: 'PART 11 Â∏∏ËßÅÈîôËØØÈÅøÂùë',
      subtitle: 'Ââç‰∫∫Ë∏©ËøáÁöÑÂùëÔºå‰Ω†‰∏çÁî®ÂÜçË∏©',
      items: [
        {
          emoji: '‚ö†Ô∏è',
          title: 'PandasÂ∏∏ËßÅÈîôËØØ ‚òÜ',
          desc: 'SettingWithCopyWarning„ÄÅÈìæÂºèÁ¥¢Âºï„ÄÅinplaceÈô∑Èò±',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöÊï∞ÊçÆ‰øÆÊîπ„ÄÅÁ≠õÈÄâÂêéËµãÂÄº\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöË≠¶Âëä‰∏çÂ§ÑÁêÜÂØºËá¥Êï∞ÊçÆÊú™Êõ¥Êñ∞\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöPandasÂ∫ïÂ±ÇÊú∫Âà∂„ÄÅËßÜÂõævsÂâØÊú¨',
          code: `# 1. SettingWithCopyWarning
# ‚ùå ÈîôËØØÔºöÈìæÂºèÁ¥¢Âºï
df[df['age'] > 30]['sales'] = 0  # Ë≠¶ÂëäÔºÅÂèØËÉΩ‰∏çÁîüÊïà

# ‚úÖ Ê≠£Á°ÆÔºö‰ΩøÁî®loc
df.loc[df['age'] > 30, 'sales'] = 0

# 2. inplaceÈô∑Èò±
# ‚ùå ÈîôËØØÔºö‰ª•‰∏∫inplace‰ºöËøîÂõûÁªìÊûú
result = df.dropna(inplace=True)  # resultÊòØNoneÔºÅ

# ‚úÖ Ê≠£Á°ÆÔºö‰∏ç‰ΩøÁî®inplace
result = df.dropna()

# 3. ÂâØÊú¨vsËßÜÂõæ
df_subset = df[df['age'] > 30]  # ËøôÊòØÂâØÊú¨ËøòÊòØËßÜÂõæÔºü‰∏çÁ°ÆÂÆöÔºÅ
df_subset['new_col'] = 1  # ÂèØËÉΩËß¶ÂèëË≠¶Âëä

# ‚úÖ Ê≠£Á°ÆÔºöÊòæÂºèÂ§çÂà∂
df_subset = df[df['age'] > 30].copy()
df_subset['new_col'] = 1

# 4. Êï∞ÊçÆÁ±ªÂûãÊ∑∑Ê∑Ü
df['age'] = df['age'] + 'Â≤Å'  # ‚ùå ‰ºöÂèòÊàêobjectÁ±ªÂûã
df['age_label'] = df['age'].astype(str) + 'Â≤Å'  # ‚úÖ

# 5. groupbyÂêéÂøòËÆ∞reset_index
grouped = df.groupby('category')['sales'].sum()
# ‚ùå groupedÊòØSeriesÔºåcategoryÂèòÊàê‰∫ÜÁ¥¢Âºï
# ‚úÖ ËΩ¨ÂõûDataFrame
grouped = df.groupby('category')['sales'].sum().reset_index()`
        }
      ]
    },
    {
      id: 'templates',
      title: 'PART 12 ‰ª£Á†ÅÊ®°ÊùøÂ∫ì',
      subtitle: 'ÊãøÊù•Âç≥Áî®ÁöÑ‰ª£Á†ÅÊ®°Êùø ‚Äî‚Äî Âø´ÈÄüÂºÄÂèë',
      items: [
        {
          emoji: 'üì¶',
          title: 'Êï∞ÊçÆÂàÜÊûêÂÖ®ÊµÅÁ®ãÊ®°Êùø',
          desc: '‰ªéÊï∞ÊçÆËØªÂèñÂà∞ÁªìÊûúËæìÂá∫ÁöÑÂÆåÊï¥ÊµÅÁ®ã',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöÊñ∞È°πÁõÆÂø´ÈÄüÂêØÂä®„ÄÅÊ†áÂáÜÂåñÂàÜÊûêÊµÅÁ®ã\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöÂøòËÆ∞ÈîôËØØÂ§ÑÁêÜ„ÄÅÁº∫Â∞ëÊï∞ÊçÆÈ™åËØÅ\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöCookiecutterÈ°πÁõÆÊ®°Êùø',
          code: `import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

# ================== 1. ÈÖçÁΩÆ ==================
plt.rcParams['font.sans-serif'] = ['SimHei']
sns.set_style("whitegrid")

# ================== 2. Êï∞ÊçÆËØªÂèñ ==================
def load_data(file_path):
    try:
        df = pd.read_csv(file_path)
        print(f"‚úÖ Êï∞ÊçÆÂä†ËΩΩÊàêÂäü: {df.shape[0]}Ë°å √ó {df.shape[1]}Âàó")
        return df
    except Exception as e:
        print(f"‚ùå Êï∞ÊçÆÂä†ËΩΩÂ§±Ë¥•: {e}")
        return None

# ================== 3. Êï∞ÊçÆÊ∏ÖÊ¥ó ==================
def clean_data(df):
    df_clean = df.copy()
    
    # Âà†Èô§ÈáçÂ§çÂÄº
    df_clean = df_clean.drop_duplicates()
    
    # Â§ÑÁêÜÁº∫Â§±ÂÄº
    df_clean['age'].fillna(df_clean['age'].median(), inplace=True)
    df_clean.dropna(subset=['user_id'], inplace=True)
    
    # ÂºÇÂ∏∏ÂÄºÂ§ÑÁêÜ
    Q1 = df_clean['sales'].quantile(0.25)
    Q3 = df_clean['sales'].quantile(0.75)
    IQR = Q3 - Q1
    df_clean = df_clean[
        (df_clean['sales'] >= Q1 - 1.5*IQR) & 
        (df_clean['sales'] <= Q3 + 1.5*IQR)
    ]
    
    print(f"‚úÖ Êï∞ÊçÆÊ∏ÖÊ¥óÂÆåÊàê: {df_clean.shape[0]}Ë°å‰øùÁïô")
    return df_clean

# ================== 4. Êé¢Á¥¢ÊÄßÂàÜÊûê ==================
def explore_data(df):
    print("\\n" + "="*50)
    print("Êï∞ÊçÆÊ¶ÇËßà")
    print("="*50)
    print(df.info())
    print("\\nÊèèËø∞ÁªüËÆ°:\\n", df.describe())
    
    # ÂèØËßÜÂåñ
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    df['age'].hist(bins=30, ax=axes[0,0])
    axes[0,0].set_title('Âπ¥ÈæÑÂàÜÂ∏É')
    df['sales'].hist(bins=30, ax=axes[0,1])
    axes[0,1].set_title('ÈîÄÂîÆÈ¢ùÂàÜÂ∏É')
    df.groupby('category')['sales'].sum().plot(kind='bar', ax=axes[1,0])
    axes[1,0].set_title('ÂêÑÁ±ªÂà´ÈîÄÂîÆÈ¢ù')
    df.plot(x='age', y='sales', kind='scatter', ax=axes[1,1])
    axes[1,1].set_title('Âπ¥ÈæÑ vs ÈîÄÂîÆÈ¢ù')
    plt.tight_layout()
    plt.savefig('eda_report.png', dpi=300)
    print("\\n‚úÖ EDAÊä•ÂëäÂ∑≤‰øùÂ≠ò: eda_report.png")

# ================== 5. Êï∞ÊçÆÂàÜÊûê ==================
def analyze_data(df):
    # ÂàÜÁªÑÁªüËÆ°
    summary = df.groupby('category').agg({
        'sales': ['sum', 'mean', 'count'],
        'quantity': 'sum'
    }).round(2)
    
    # Êó∂Èó¥Â∫èÂàóÂàÜÊûê
    df['date'] = pd.to_datetime(df['date'])
    daily_sales = df.groupby('date')['sales'].sum()
    
    return summary, daily_sales

# ================== 6. ÁªìÊûúËæìÂá∫ ==================
def export_results(summary, daily_sales, output_file):
    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
        summary.to_excel(writer, sheet_name='ÂàÜÁ±ªÊ±áÊÄª')
        daily_sales.to_excel(writer, sheet_name='Êó•ÈîÄÂîÆÈ¢ù')
    print(f"\\n‚úÖ ÂàÜÊûêÁªìÊûúÂ∑≤ÂØºÂá∫: {output_file}")

# ================== 7. ‰∏ªÊµÅÁ®ã ==================
if __name__ == '__main__':
    # Âä†ËΩΩÊï∞ÊçÆ
    df = load_data('sales_data.csv')
    
    if df is not None:
        # Ê∏ÖÊ¥óÊï∞ÊçÆ
        df_clean = clean_data(df)
        
        # Êé¢Á¥¢ÂàÜÊûê
        explore_data(df_clean)
        
        # Êï∞ÊçÆÂàÜÊûê
        summary, daily_sales = analyze_data(df_clean)
        
        # ÂØºÂá∫ÁªìÊûú
        export_results(summary, daily_sales, 
                      f'ÂàÜÊûêÊä•Âëä_{datetime.now().strftime("%Y%m%d")}.xlsx')
        
        print("\\nüéâ ÂàÜÊûêÂÆåÊàêÔºÅ")`
        }
      ]
    },
    {
      id: 'advanced-libs',
      title: 'PART 13 ËøõÈò∂Â∫ìÊé®Ëçê',
      subtitle: 'Êõ¥Âº∫Â§ßÁöÑÊï∞ÊçÆÂàÜÊûêÂ∑•ÂÖ∑',
      items: [
        {
          emoji: 'üöÄ',
          title: 'ËøõÈò∂Â∫ìÈÄüËßà',
          desc: 'Plotly„ÄÅStatsmodels„ÄÅScikit-learnÁ≠â',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**Ôºö‰∫§‰∫íÂºèÂèØËßÜÂåñ„ÄÅÁªüËÆ°Âª∫Ê®°„ÄÅÊú∫Âô®Â≠¶‰π†\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöÂ∫ì‰πãÈó¥ÁâàÊú¨ÂÜ≤Á™Å\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöÂêÑÂ∫ìÂÆòÊñπÊñáÊ°£',
          code: `# 1. Plotly - ‰∫§‰∫íÂºèÂèØËßÜÂåñ
import plotly.express as px
fig = px.line(df, x='date', y='sales', title='ÈîÄÂîÆË∂ãÂäø')
fig.show()

# 2. Statsmodels - ÁªüËÆ°ÂàÜÊûê
from statsmodels.formula.api import ols
model = ols('sales ~ age + income', data=df).fit()
print(model.summary())

# 3. Scikit-learn - Êú∫Âô®Â≠¶‰π†ÔºàËØ¶ËßÅÊú∫Âô®Â≠¶‰π†Ê®°ÂùóÔºâ
from sklearn.ensemble import RandomForestRegressor
model = RandomForestRegressor()
model.fit(X_train, y_train)

# 4. Openpyxl - ExcelÈ´òÁ∫ßÊìç‰Ωú
from openpyxl import load_workbook
wb = load_workbook('data.xlsx')
ws = wb.active
ws['A1'] = 'Hello'

# 5. Requests - APIÊï∞ÊçÆËé∑Âèñ
import requests
response = requests.get('https://api.example.com/data')
data = response.json()

# 6. Beautiful Soup - ÁΩëÈ°µÊï∞ÊçÆÊäìÂèñ
from bs4 import BeautifulSoup
soup = BeautifulSoup(html, 'html.parser')
titles = soup.find_all('h2')`
        }
      ]
    },
    {
      id: 'jupyter',
      title: 'PART 14 Jupyter Notebook ÂÆåÂÖ®ÊåáÂçó',
      subtitle: 'Êï∞ÊçÆÂàÜÊûêÂ∏àÁöÑ‰∏ªÊàòÂú∫ ‚Äî‚Äî 90%ÁöÑÊé¢Á¥¢ÊÄßÂ∑•‰ΩúÂú®ËøôÈáåÂÆåÊàê',
      items: [
        {
          emoji: '‚å®Ô∏è',
          title: 'JupyterÂø´Êç∑ÈîÆÂ§ßÂÖ® ‚òÜ',
          desc: 'ÊéåÊè°Âø´Êç∑ÈîÆÔºåÊïàÁéáÊèêÂçá10ÂÄç',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöÂø´ÈÄüÁºñÂÜôÂíåËøêË°å‰ª£Á†Å„ÄÅË∞ÉËØï„ÄÅÊºîÁ§∫\\n**ÊòìË∏©ÂùëÁÇπ**Ôºö‰∏çÁü•ÈÅìÂø´Êç∑ÈîÆÔºåÈº†Ê†áÊìç‰ΩúÊïàÁéá‰Ωé\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöËá™ÂÆö‰πâÂø´Êç∑ÈîÆ„ÄÅVimÊ®°Âºè',
          code: `# ========== ÂëΩ‰ª§Ê®°ÂºèÔºàÊåâ Esc ËøõÂÖ•Ôºâ==========
# A - Âú®‰∏äÊñπÊèíÂÖ•Êñ∞ÂçïÂÖÉÊ†º
# B - Âú®‰∏ãÊñπÊèíÂÖ•Êñ∞ÂçïÂÖÉÊ†º
# D,D - Âà†Èô§ÂΩìÂâçÂçïÂÖÉÊ†ºÔºàËøûÊåâ‰∏§Ê¨°DÔºâ
# M - ËΩ¨Êç¢‰∏∫MarkdownÂçïÂÖÉÊ†º
# Y - ËΩ¨Êç¢‰∏∫‰ª£Á†ÅÂçïÂÖÉÊ†º
# Shift+M - ÂêàÂπ∂ÈÄâ‰∏≠ÁöÑÂçïÂÖÉÊ†º
# Ctrl+Shift+- - ÂàÜÂâ≤ÂçïÂÖÉÊ†º

# ========== ÁºñËæëÊ®°ÂºèÔºàÊåâ Enter ËøõÂÖ•Ôºâ==========
# Ctrl+Enter - ËøêË°åÂΩìÂâçÂçïÂÖÉÊ†º
# Shift+Enter - ËøêË°åÂΩìÂâçÂçïÂÖÉÊ†ºÂπ∂ÈÄâÊã©‰∏ã‰∏Ä‰∏™
# Alt+Enter - ËøêË°åÂΩìÂâçÂçïÂÖÉÊ†ºÂπ∂Âú®‰∏ãÊñπÊèíÂÖ•Êñ∞ÂçïÂÖÉÊ†º
# Ctrl+/ - Ê≥®Èáä/ÂèñÊ∂àÊ≥®Èáä
# Tab - ‰ª£Á†ÅË°•ÂÖ®
# Shift+Tab - Êü•ÁúãÂáΩÊï∞ÊñáÊ°£

# ========== ÈÄöÁî®Âø´Êç∑ÈîÆ ==========
# Ctrl+S - ‰øùÂ≠ò
# Ctrl+Shift+P - ÊâìÂºÄÂëΩ‰ª§Èù¢Êùø
# H - ÊòæÁ§∫Âø´Êç∑ÈîÆÂ∏ÆÂä©
# Shift+L - ÊòæÁ§∫/ÈöêËóèË°åÂè∑`
        },
        {
          emoji: '‚ú®',
          title: 'MagicÂëΩ‰ª§ ‚òÜ',
          desc: 'JupyterÁöÑË∂ÖËÉΩÂäõ ‚Äî‚Äî %Âíå%%È≠îÊ≥ïÂëΩ‰ª§',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**Ôºö‰ª£Á†ÅÊÄßËÉΩÂàÜÊûê„ÄÅË∞ÉËØï„ÄÅÁ≥ªÁªüÂëΩ‰ª§ÊâßË°å\\n**ÊòìË∏©ÂùëÁÇπ**Ôºö‰∏çÁü•ÈÅìÊúâËøô‰∫õÂº∫Â§ßÂäüËÉΩÂ≠òÂú®\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöËá™ÂÆö‰πâmagicÂëΩ‰ª§',
          code: `# 1. ÊÄßËÉΩÂàÜÊûê
%timeit sum(range(100))  # ÊµãËØïÂçïË°å‰ª£Á†ÅÊâßË°åÊó∂Èó¥
%%timeit  # ÊµãËØïÊï¥‰∏™ÂçïÂÖÉÊ†ºÊâßË°åÊó∂Èó¥
total = 0
for i in range(100):
    total += i

# 2. ÊòæÁ§∫matplotlibÂõæË°®
%matplotlib inline  # ÂõæË°®ÂµåÂÖ•notebook
%matplotlib notebook  # ‰∫§‰∫íÂºèÂõæË°®

# 3. Ëá™Âä®ÈáçËΩΩÊ®°Âùó
%load_ext autoreload
%autoreload 2  # Ëá™Âä®ÈáçËΩΩÊâÄÊúâÊ®°Âùó

# 4. Êü•ÁúãÂèòÈáè
%whos  # ÊòæÁ§∫ÊâÄÊúâÂèòÈáè
%who_ls  # ËøîÂõûÂèòÈáèÂàóË°®

# 5. ËøêË°åÂ§ñÈÉ®PythonÊñá‰ª∂
%run script.py

# 6. Ë∞ÉËØï
%debug  # ËøõÂÖ•Ë∞ÉËØïÊ®°Âºè
%pdb on  # Ëá™Âä®ËøõÂÖ•Ë∞ÉËØïÂô®

# 7. Á≥ªÁªüÂëΩ‰ª§
!pip install pandas  # ÊâßË°åÁ≥ªÁªüÂëΩ‰ª§
!ls  # Linux/Mac
!dir  # Windows

# 8. ÁéØÂ¢ÉÂèòÈáè
%env  # Êü•ÁúãÁéØÂ¢ÉÂèòÈáè
%env MY_VAR=value  # ËÆæÁΩÆÁéØÂ¢ÉÂèòÈáè

# 9. ‰ª£Á†ÅÊÄßËÉΩÂàÜÊûê
%prun my_function()  # ÊÄßËÉΩÂàÜÊûê
%lprun -f my_function my_function()  # ÈÄêË°åÊÄßËÉΩÂàÜÊûê

# 10. ‰øùÂ≠òÂçïÂÖÉÊ†ºÂÜÖÂÆπ
%%writefile script.py
def hello():
    print("Hello World")`
        },
        {
          emoji: 'üîß',
          title: 'JupyterÈ´òÁ∫ßÊäÄÂ∑ß',
          desc: 'ËÆ©JupyterÊõ¥Âº∫Â§ßÁöÑÂÆûÁî®ÊäÄÂ∑ß',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöÂ±ïÁ§∫Êï∞ÊçÆ„ÄÅË∞ÉËØï‰ª£Á†Å„ÄÅÁîüÊàêÊä•Âëä\\n**ÊòìË∏©ÂùëÁÇπ**Ôºö‰∏çÁü•ÈÅìËøô‰∫õÂäüËÉΩÔºåÊâãÂ∑•Êìç‰ΩúÊµ™Ë¥πÊó∂Èó¥\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöJupyterÊâ©Â±ïÂºÄÂèë',
          code: `# 1. ÊòæÁ§∫Â§ö‰∏™ËæìÂá∫
from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"
df.head()
df.describe()
df.info()  # ‰∏â‰∏™ÈÉΩ‰ºöÊòæÁ§∫

# 2. ÈöêËóèË≠¶Âëä
import warnings
warnings.filterwarnings('ignore')

# 3. ËÆæÁΩÆÊòæÁ§∫ÈÄâÈ°π
import pandas as pd
pd.set_option('display.max_rows', 100)
pd.set_option('display.max_columns', 50)
pd.set_option('display.width', 1000)
pd.set_option('display.float_format', '{:.2f}'.format)

# 4. ËøõÂ∫¶Êù°
from tqdm import tqdm
for i in tqdm(range(100)):
    # Â§ÑÁêÜÊï∞ÊçÆ
    pass

# 5. ‰∫§‰∫íÂºèÂ∞èÈÉ®‰ª∂
from ipywidgets import interact
@interact(x=(0, 10))
def plot_data(x):
    return x ** 2

# 6. ÊòæÁ§∫DataFrameÊ†∑Âºè
df.style.background_gradient(cmap='coolwarm')\\
    .highlight_max(axis=0)\\
    .format("{:.2f}")

# 7. ÂØºÂá∫‰∏∫HTML/PDF
# ÂëΩ‰ª§Ë°åÊâßË°å
# jupyter nbconvert --to html notebook.ipynb
# jupyter nbconvert --to pdf notebook.ipynb

# 8. ÂèòÈáèÊü•ÁúãÂô®ÔºàÈúÄÂÆâË£ÖÊâ©Â±ïÔºâ
%load_ext jupyter_contrib_nbextensions
# ÂêØÁî®Variable InspectorÊâ©Â±ï`
        },
        {
          emoji: 'üöÄ',
          title: 'JupyterLabÊâ©Â±ïÊé®Ëçê',
          desc: 'ÂøÖË£ÖÊâ©Â±ïÔºåÂ§ßÂπÖÊèêÂçáÊïàÁéá',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**Ôºö‰ª£Á†ÅÊ†ºÂºèÂåñ„ÄÅGitÈõÜÊàê„ÄÅË°®Ê†ºÊü•Áúã\\n**ÊòìË∏©ÂùëÁÇπ**Ôºö‰∏çÁü•ÈÅìÊúâËøô‰∫õÊâ©Â±ïÔºåÂéüÁîüÂäüËÉΩÂèóÈôê\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöËá™ÂÆö‰πâÊâ©Â±ïÂºÄÂèë',
          code: `# ÂÆâË£ÖJupyterLabÔºàÊé®Ëçê‰ΩøÁî®LabËÄå‰∏çÊòØNotebookÔºâ
pip install jupyterlab

# 1. ‰ª£Á†ÅÊ†ºÂºèÂåñ - Black
pip install jupyterlab-code-formatter black
# ‰ΩøÁî®ÔºöCtrl+Shift+I Ê†ºÂºèÂåñ‰ª£Á†Å

# 2. ÂèòÈáèÊü•ÁúãÂô®
pip install lckr-jupyterlab-variableinspector

# 3. GitÈõÜÊàê
pip install jupyterlab-git

# 4. Ë°®Ê†ºÊü•ÁúãÂô®ÔºàÊõ¥Â•ΩÁöÑDataFrameÊòæÁ§∫Ôºâ
pip install jupyterlab-spreadsheet-editor

# 5. PlotlyÊîØÊåÅ
pip install jupyterlab-plotly

# 6. ÁõÆÂΩïÁîüÊàêÂô®
pip install jupyterlab-toc

# 7. ‰ª£Á†ÅË°•ÂÖ®Â¢ûÂº∫
pip install jupyter-lsp
pip install python-lsp-server

# 8. DebuggerÂèØËßÜÂåñË∞ÉËØï
# JupyterLab 3.0+ ÂÜÖÁΩÆÔºåÁÇπÂáªbugÂõæÊ†áÂêØÁî®

# ÂêØÂä®JupyterLab
jupyter lab

# Â∏∏Áî®ÈÖçÁΩÆ
# ÁîüÊàêÈÖçÁΩÆÊñá‰ª∂
jupyter lab --generate-config

# ËÆæÁΩÆÈªòËÆ§ÊµèËßàÂô®„ÄÅÁ´ØÂè£Á≠â
# ÁºñËæë ~/.jupyter/jupyter_lab_config.py`
        }
      ]
    },
    {
      id: 'data-io',
      title: 'PART 15 Êï∞ÊçÆÂØºÂÖ•ÂØºÂá∫Â§ßÂÖ®',
      subtitle: 'Êï∞ÊçÆÂàÜÊûêÁöÑÁ¨¨‰∏ÄÊ≠• ‚Äî‚Äî ÂêÑÁßçÊï∞ÊçÆÊ∫êÁöÑËØªÂèñ‰∏éÂÜôÂÖ•',
      items: [
        {
          emoji: 'üìä',
          title: 'ExcelÊñá‰ª∂Êìç‰Ωú ‚òÜ',
          desc: 'ËØªÂèñÂ§ösheet„ÄÅÊ†∑Âºè‰øùÁïô„ÄÅÂ§ßÊñá‰ª∂Â§ÑÁêÜ',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**Ôºö‰∏öÂä°ÈÉ®Èó®Â∏∏Áî®Excel‰∫§‰ªòÊï∞ÊçÆ\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöÁºñÁ†ÅÈóÆÈ¢ò„ÄÅÊó•ÊúüÊ†ºÂºè„ÄÅÂêàÂπ∂ÂçïÂÖÉÊ†º\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöopenpyxlÈ´òÁ∫ßÊìç‰Ωú„ÄÅxlwings‰∏éExcel‰∫§‰∫í',
          code: `import pandas as pd

# 1. Âü∫Á°ÄËØªÂèñ
df = pd.read_excel('data.xlsx')

# 2. ËØªÂèñÊåáÂÆösheet
df = pd.read_excel('data.xlsx', sheet_name='Sheet1')

# 3. ËØªÂèñÂ§ö‰∏™sheet
dfs = pd.read_excel('data.xlsx', sheet_name=['Sheet1', 'Sheet2'])
dfs = pd.read_excel('data.xlsx', sheet_name=None)  # ËØªÂèñÊâÄÊúâsheet

# 4. ÊåáÂÆöËØªÂèñË°åÂàó
df = pd.read_excel('data.xlsx', 
                   usecols='A:E',  # Âè™ËØªA-EÂàó
                   skiprows=2,  # Ë∑≥ËøáÂâç2Ë°å
                   nrows=1000)  # Âè™ËØª1000Ë°å

# 5. Â§ÑÁêÜÊó•Êúü
df = pd.read_excel('data.xlsx', parse_dates=['Êó•ÊúüÂàó'])

# 6. ÂÜôÂÖ•ExcelÔºàÂçïsheetÔºâ
df.to_excel('output.xlsx', index=False, sheet_name='ÁªìÊûú')

# 7. ÂÜôÂÖ•Â§ö‰∏™sheet
with pd.ExcelWriter('output.xlsx', engine='openpyxl') as writer:
    df1.to_excel(writer, sheet_name='ÈîÄÂîÆÊï∞ÊçÆ', index=False)
    df2.to_excel(writer, sheet_name='Áî®Êà∑Êï∞ÊçÆ', index=False)
    df3.to_excel(writer, sheet_name='Ê±áÊÄªÂàÜÊûê', index=False)

# 8. ‰øùÁïôExcelÊ†∑ÂºèÔºàËøΩÂä†Êï∞ÊçÆÔºâ
from openpyxl import load_workbook
with pd.ExcelWriter('existing.xlsx', engine='openpyxl', mode='a') as writer:
    df.to_excel(writer, sheet_name='Êñ∞Sheet', index=False)

# 9. Â§ÑÁêÜÂ§ßÊñá‰ª∂ÔºàÂàÜÂùóËØªÂèñÔºâ
chunks = pd.read_excel('big_file.xlsx', chunksize=10000)
for chunk in chunks:
    process(chunk)`
        },
        {
          emoji: 'üìÑ',
          title: 'CSVÊñá‰ª∂Êìç‰Ωú ‚òÜ',
          desc: 'ÁºñÁ†ÅÂ§ÑÁêÜ„ÄÅÂàÜÈöîÁ¨¶„ÄÅÂ§ßÊñá‰ª∂ÂàÜÂùó',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöÊúÄÂ∏∏ËßÅÁöÑÊï∞ÊçÆ‰∫§Êç¢Ê†ºÂºè\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöÁºñÁ†ÅÈóÆÈ¢òÔºàUTF-8 vs GBKÔºâ„ÄÅÂàÜÈöîÁ¨¶ÈîôËØØ\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöCSVÂéãÁº©„ÄÅÊµÅÂºèÂ§ÑÁêÜ',
          code: `# 1. Âü∫Á°ÄËØªÂèñ
df = pd.read_csv('data.csv')

# 2. ÁºñÁ†ÅÂ§ÑÁêÜÔºàÈáçË¶ÅÔºÅÔºâ
df = pd.read_csv('data.csv', encoding='utf-8')
df = pd.read_csv('data.csv', encoding='gbk')  # ‰∏≠ÊñáWindowsÂ∏∏Áî®
df = pd.read_csv('data.csv', encoding='latin-1')  # Â§áÈÄâÊñπÊ°à

# 3. ÊåáÂÆöÂàÜÈöîÁ¨¶
df = pd.read_csv('data.txt', sep='\\t')  # TabÂàÜÈöî
df = pd.read_csv('data.txt', sep='|')  # Á´ñÁ∫øÂàÜÈöî

# 4. Â§ÑÁêÜÁº∫Â§±ÂÄº
df = pd.read_csv('data.csv', na_values=['NA', 'null', ''])

# 5. ÊåáÂÆöÊï∞ÊçÆÁ±ªÂûãÔºàÊèêÂçáÊÄßËÉΩÔºâ
dtypes = {'user_id': str, 'age': int, 'amount': float}
df = pd.read_csv('data.csv', dtype=dtypes)

# 6. Êó•ÊúüËß£Êûê
df = pd.read_csv('data.csv', parse_dates=['date_column'])

# 7. Â§ßÊñá‰ª∂ÂàÜÂùóËØªÂèñÔºàÊé®ËçêÔºÅÔºâ
chunks = []
for chunk in pd.read_csv('big_file.csv', chunksize=100000):
    # Â§ÑÁêÜÊØè‰∏™chunk
    processed = process(chunk)
    chunks.append(processed)
df = pd.concat(chunks, ignore_index=True)

# 8. ÂÜôÂÖ•CSV
df.to_csv('output.csv', index=False, encoding='utf-8-sig')  # ExcelÂèãÂ•Ω

# 9. ÂéãÁº©ÂÜôÂÖ•
df.to_csv('output.csv.gz', index=False, compression='gzip')

# 10. Âè™ËØªÂèñÈÉ®ÂàÜÂàó
df = pd.read_csv('data.csv', usecols=['user_id', 'amount', 'date'])`
        },
        {
          emoji: 'üóÑÔ∏è',
          title: 'Êï∞ÊçÆÂ∫ìËØªÂÜô ‚òÜ',
          desc: 'MySQL„ÄÅPostgreSQL„ÄÅSQLiteÁ≠âÊï∞ÊçÆÂ∫ìÊìç‰Ωú',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**Ôºö‰ªéÁîü‰∫ßÊï∞ÊçÆÂ∫ìËØªÂèñÊï∞ÊçÆ„ÄÅÂõûÂÜôÂàÜÊûêÁªìÊûú\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöËøûÊé•Ê±†„ÄÅÂ§ßÊï∞ÊçÆÈáèOOM„ÄÅSQLÊ≥®ÂÖ•\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöËøûÊé•Ê±†ÁÆ°ÁêÜ„ÄÅORMÊ°ÜÊû∂',
          code: `import pandas as pd
from sqlalchemy import create_engine
import pymysql

# 1. SQLiteÔºàÊó†ÈúÄÂÆâË£ÖÔºâ
import sqlite3
conn = sqlite3.connect('database.db')
df = pd.read_sql('SELECT * FROM orders', conn)
conn.close()

# 2. MySQL/MariaDB
engine = create_engine('mysql+pymysql://user:pass@host:3306/dbname')
df = pd.read_sql('SELECT * FROM orders WHERE date > "2024-01-01"', engine)

# 3. PostgreSQL
engine = create_engine('postgresql://user:pass@host:5432/dbname')
df = pd.read_sql_query('SELECT * FROM sales', engine)

# 4. ÂèÇÊï∞ÂåñÊü•ËØ¢ÔºàÈò≤SQLÊ≥®ÂÖ•Ôºâ
query = "SELECT * FROM users WHERE user_id = %(id)s"
df = pd.read_sql(query, engine, params={'id': 1001})

# 5. ÊâπÈáèËØªÂèñÔºàÂàÜÂùóÔºâ
query = "SELECT * FROM large_table"
for chunk in pd.read_sql(query, engine, chunksize=10000):
    process(chunk)

# 6. ÂÜôÂÖ•Êï∞ÊçÆÂ∫ì
df.to_sql('table_name', engine, if_exists='replace', index=False)
# if_exists: 'fail', 'replace', 'append'

# 7. ÊâπÈáèÊèíÂÖ•ÔºàÈ´òÊïàÔºâ
df.to_sql('table_name', engine, if_exists='append', index=False,
          method='multi', chunksize=1000)

# 8. ‰ΩøÁî®withËØ≠Âè•ÔºàËá™Âä®ÂÖ≥Èó≠ËøûÊé•Ôºâ
with engine.connect() as conn:
    df = pd.read_sql('SELECT * FROM orders', conn)

# 9. ËØªÂèñË°®ÁªìÊûÑ
query = "SHOW CREATE TABLE table_name"
structure = pd.read_sql(query, engine)

# 10. ÊâßË°åÂ§öÊù°SQL
with engine.begin() as conn:
    conn.execute("DELETE FROM temp_table")
    df.to_sql('temp_table', conn, if_exists='append', index=False)`
        },
        {
          emoji: 'üåê',
          title: 'JSON/APIÊï∞ÊçÆ',
          desc: 'JSONÊñá‰ª∂„ÄÅRESTful APIÊï∞ÊçÆËé∑Âèñ',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöË∞ÉÁî®Á¨¨‰∏âÊñπAPI„ÄÅÂ§ÑÁêÜÂµåÂ•óJSON\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöÂµåÂ•óÁªìÊûÑÂ±ïÂºÄ„ÄÅAPIÈôêÊµÅ\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöÂºÇÊ≠•ËØ∑Ê±Ç„ÄÅGraphQL',
          code: `import pandas as pd
import json
import requests

# 1. ËØªÂèñJSONÊñá‰ª∂
df = pd.read_json('data.json')

# 2. Â§ÑÁêÜÂµåÂ•óJSON
with open('nested.json', 'r', encoding='utf-8') as f:
    data = json.load(f)
df = pd.json_normalize(data, record_path=['items'])

# 3. ‰ªéAPIËé∑ÂèñÊï∞ÊçÆ
response = requests.get('https://api.example.com/data')
data = response.json()
df = pd.DataFrame(data)

# 4. Â∏¶ÂèÇÊï∞ÁöÑAPIËØ∑Ê±Ç
params = {'start_date': '2024-01-01', 'end_date': '2024-12-31'}
response = requests.get('https://api.example.com/sales', params=params)
df = pd.DataFrame(response.json())

# 5. POSTËØ∑Ê±Ç
payload = {'user_id': 123, 'action': 'query'}
response = requests.post('https://api.example.com/data', json=payload)
df = pd.DataFrame(response.json())

# 6. Â∏¶ËÆ§ËØÅÁöÑËØ∑Ê±Ç
headers = {'Authorization': 'Bearer YOUR_TOKEN'}
response = requests.get('https://api.example.com/data', headers=headers)
df = pd.DataFrame(response.json())

# 7. Â§ÑÁêÜÂàÜÈ°µAPI
all_data = []
page = 1
while True:
    response = requests.get(f'https://api.example.com/data?page={page}')
    data = response.json()
    if not data:
        break
    all_data.extend(data)
    page += 1
df = pd.DataFrame(all_data)

# 8. ÂÜôÂÖ•JSON
df.to_json('output.json', orient='records', force_ascii=False, indent=2)

# 9. Â±ïÂºÄÂµåÂ•óÂàó
df = pd.json_normalize(data, 
                       record_path=['orders'], 
                       meta=['user_id', 'user_name'])

# 10. ÈîôËØØÂ§ÑÁêÜ
try:
    response = requests.get('https://api.example.com/data', timeout=10)
    response.raise_for_status()
    df = pd.DataFrame(response.json())
except requests.exceptions.RequestException as e:
    print(f"ËØ∑Ê±ÇÂ§±Ë¥•: {e}")`
        },
        {
          emoji: '‚ö°',
          title: 'È´òÊïàÊ†ºÂºèÊé®Ëçê',
          desc: 'Parquet„ÄÅFeather ‚Äî‚Äî ÊØîCSVÂø´10ÂÄç',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöÂ≠òÂÇ®Â§ßÊï∞ÊçÆÈõÜ„ÄÅÊï∞ÊçÆ‰∏≠Èó¥ÁªìÊûúÁºìÂ≠ò\\n**ÊòìË∏©ÂùëÁÇπ**Ôºö‰∏çÁü•ÈÅìËøô‰∫õÊ†ºÂºèÂ≠òÂú®Ôºå‰∏ÄÁõ¥Áî®CSV\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöApache Arrow„ÄÅÊï∞ÊçÆÊπñ',
          code: `# 1. ParquetÔºàÊé®ËçêÔºÅÔºâ
# ÂÆâË£Ö: pip install pyarrow
df.to_parquet('data.parquet', index=False)
df = pd.read_parquet('data.parquet')

# ‰ºòÁÇπÔºö
# - ÂéãÁº©ÁéáÈ´òÔºàÊØîCSVÂ∞è5-10ÂÄçÔºâ
# - ËØªÂèñÈÄüÂ∫¶Âø´ÔºàÊØîCSVÂø´10-50ÂÄçÔºâ
# - ‰øùÁïôÊï∞ÊçÆÁ±ªÂûã
# - ÊîØÊåÅÂàóÂºèÂ≠òÂÇ®

# 2. FeatherÔºàË∂ÖÂø´ÔºÅÔºâ
# ÂÆâË£Ö: pip install pyarrow
df.to_feather('data.feather')
df = pd.read_feather('data.feather')

# ‰ºòÁÇπÔºö
# - ËØªÂÜôÈÄüÂ∫¶ÊûÅÂø´
# - ÂÆåÁæé‰øùÁïôPandasÊï∞ÊçÆÁ±ªÂûã
# - ÈÄÇÂêà‰∏¥Êó∂ÁºìÂ≠ò

# 3. HDF5ÔºàÁßëÂ≠¶ËÆ°ÁÆóÂ∏∏Áî®Ôºâ
# ÂÆâË£Ö: pip install tables
df.to_hdf('data.h5', key='df', mode='w')
df = pd.read_hdf('data.h5', 'df')

# 4. PickleÔºàPython‰∏ìÁî®Ôºâ
df.to_pickle('data.pkl')
df = pd.read_pickle('data.pkl')

# ÊÄßËÉΩÂØπÊØîÔºà10GBÊï∞ÊçÆÔºâ
# CSV:      ÂÜôÂÖ•60s  ËØªÂèñ120s  Êñá‰ª∂Â§ßÂ∞è10GB
# Parquet:  ÂÜôÂÖ•20s  ËØªÂèñ10s   Êñá‰ª∂Â§ßÂ∞è2GB
# Feather:  ÂÜôÂÖ•8s   ËØªÂèñ5s    Êñá‰ª∂Â§ßÂ∞è4GB

# 5. ÂÆûÈôÖÂ∫îÁî®Âª∫ËÆÆ
# - Êï∞ÊçÆ‰∫§Êç¢ÔºöÁî®CSVÔºàÈÄöÁî®ÊÄßÂ•ΩÔºâ
# - Êï∞ÊçÆÂ≠òÂÇ®ÔºöÁî®ParquetÔºàÂéãÁº©ÁéáÈ´òÔºâ
# - ‰∏¥Êó∂ÁºìÂ≠òÔºöÁî®FeatherÔºàÈÄüÂ∫¶ÊúÄÂø´Ôºâ
# - PythonÂÜÖÈÉ®ÔºöÁî®PickleÔºàÂÆåÊï¥‰øùÂ≠òÂØπË±°Ôºâ`
        }
      ]
    },
    {
      id: 'pandas-advanced',
      title: 'PART 16 Pandas È´òÁ∫ßÊäÄÂ∑ß',
      subtitle: 'ËøõÈò∂Êìç‰Ωú ‚Äî‚Äî ÊèêÂçáÊï∞ÊçÆÂ§ÑÁêÜÊïàÁéá10ÂÄç',
      items: [
        {
          emoji: 'üöÄ',
          title: 'apply vs map vs applymap ÊÄßËÉΩÂØπÊØî ‚òÜ',
          desc: 'ÈÄâÊã©Ê≠£Á°ÆÁöÑÊñπÊ≥ïÔºåÊÄßËÉΩÊèêÂçá10-100ÂÄç',
          detail: '**Ê†∏ÂøÉ**ÔºöÂêëÈáèÂåñÊìç‰Ωú > apply > Âæ™ÁéØ\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöËØØÁî®applyÂØºËá¥ÊÄßËÉΩ‰Ωé‰∏ã\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöCython„ÄÅNumbaÂä†ÈÄü',
          code: `import pandas as pd
import numpy as np
import time

# ÂàõÂª∫ÊµãËØïÊï∞ÊçÆ
df = pd.DataFrame({
    'A': np.random.randint(0, 100, 1000000),
    'B': np.random.randint(0, 100, 1000000)
})

# ========== ÊñπÊ≥ï1ÔºöÂæ™ÁéØÔºàÊúÄÊÖ¢Ôºå‰∏çÊé®ËçêÔºâ==========
start = time.time()
result = []
for val in df['A']:
    result.append(val * 2)
df['C'] = result
print(f"Âæ™ÁéØËÄóÊó∂: {time.time() - start:.3f}s")

# ========== ÊñπÊ≥ï2ÔºöapplyÔºà‰∏≠Á≠âÈÄüÂ∫¶Ôºâ==========
start = time.time()
df['C'] = df['A'].apply(lambda x: x * 2)
print(f"applyËÄóÊó∂: {time.time() - start:.3f}s")

# ========== ÊñπÊ≥ï3ÔºöÂêëÈáèÂåñÔºàÊúÄÂø´ÔºåÊé®ËçêÔºÅÔºâ==========
start = time.time()
df['C'] = df['A'] * 2
print(f"ÂêëÈáèÂåñËÄóÊó∂: {time.time() - start:.3f}s")

# ========== map vs apply ==========
# map: Áî®‰∫éSeriesÔºåÊò†Â∞ÑÂ≠óÂÖ∏ÊàñÂáΩÊï∞
df['category'] = df['A'].map({0: 'low', 50: 'medium', 100: 'high'})
df['category'] = df['A'].map(lambda x: 'high' if x > 50 else 'low')

# apply: Áî®‰∫éSeriesÊàñDataFrame
df['C'] = df['A'].apply(lambda x: x * 2)  # Series
df['sum'] = df.apply(lambda row: row['A'] + row['B'], axis=1)  # DataFrame

# ========== applymap (Â∑≤Â∫üÂºÉÔºåÁî®mapÊõø‰ª£) ==========
# ÂØπDataFrameÁöÑÊâÄÊúâÂÖÉÁ¥†Â∫îÁî®ÂáΩÊï∞
df_numeric = df[['A', 'B']].map(lambda x: x * 2)  # Pandas 2.1+

# ========== ÊÄßËÉΩ‰ºòÂåñÂª∫ËÆÆ ==========
# 1. ‰ºòÂÖà‰ΩøÁî®ÂêëÈáèÂåñÊìç‰Ωú
# 2. ÈúÄË¶ÅÊù°‰ª∂Âà§Êñ≠Êó∂Áî® np.where„ÄÅnp.select
# 3. Â§çÊùÇÈÄªËæëÊâçÁî® apply
# 4. ÈÅøÂÖçÂæ™ÁéØ

# Á§∫‰æãÔºöÊù°‰ª∂ËµãÂÄºÔºàÊé®ËçêÊñπÊ≥ïÔºâ
df['level'] = np.where(df['A'] > 80, 'high',
                np.where(df['A'] > 50, 'medium', 'low'))

# Â§öÊù°‰ª∂‰ΩøÁî® np.select
conditions = [df['A'] > 80, df['A'] > 50, df['A'] > 20]
choices = ['high', 'medium', 'low']
df['level'] = np.select(conditions, choices, default='very_low')`
        },
        {
          emoji: 'üîÑ',
          title: 'pivot_table ÈÄèËßÜË°®È´òÁ∫ßÁî®Ê≥ï ‚òÜ',
          desc: 'ExcelÈÄèËßÜË°®ÁöÑPythonÂÆûÁé∞ÔºåÊï∞ÊçÆÂàÜÊûêÂà©Âô®',
          detail: '**‰∏öÂä°Âú∫ÊôØ**ÔºöÂ§öÁª¥Â∫¶Êï∞ÊçÆÊ±áÊÄª„ÄÅ‰∫§ÂèâÂàÜÊûê\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöaggfuncÂèÇÊï∞„ÄÅfill_value\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**Ôºöcrosstab„ÄÅgroupbyÈ´òÁ∫ßÁî®Ê≥ï',
          code: `import pandas as pd
import numpy as np

# ÂàõÂª∫ÈîÄÂîÆÊï∞ÊçÆ
df = pd.DataFrame({
    'date': pd.date_range('2024-01-01', periods=100),
    'region': np.random.choice(['ÂåóÂå∫', 'ÂçóÂå∫', '‰∏úÂå∫', 'Ë•øÂå∫'], 100),
    'product': np.random.choice(['‰∫ßÂìÅA', '‰∫ßÂìÅB', '‰∫ßÂìÅC'], 100),
    'sales': np.random.randint(100, 1000, 100),
    'quantity': np.random.randint(1, 20, 100)
})

# ========== Âü∫Á°ÄÈÄèËßÜË°® ==========
# ÊåâÂú∞Âå∫Âíå‰∫ßÂìÅÊ±áÊÄªÈîÄÂîÆÈ¢ù
pivot1 = pd.pivot_table(
    df,
    values='sales',
    index='region',
    columns='product',
    aggfunc='sum',
    fill_value=0
)
print("Âü∫Á°ÄÈÄèËßÜË°®:")
print(pivot1)

# ========== Â§öÂàóËÅöÂêà ==========
pivot2 = pd.pivot_table(
    df,
    values=['sales', 'quantity'],
    index='region',
    columns='product',
    aggfunc={'sales': 'sum', 'quantity': 'mean'},
    fill_value=0
)
print("\\nÂ§öÂàóËÅöÂêà:")
print(pivot2)

# ========== Â§öÈáçÁ¥¢Âºï ==========
df['month'] = df['date'].dt.month
pivot3 = pd.pivot_table(
    df,
    values='sales',
    index=['region', 'month'],
    columns='product',
    aggfunc='sum',
    fill_value=0,
    margins=True,  # Ê∑ªÂä†ÊÄªËÆ°Ë°å
    margins_name='ÊÄªËÆ°'
)
print("\\nÂ§öÈáçÁ¥¢Âºï+ÊÄªËÆ°:")
print(pivot3)

# ========== Â§öÁßçËÅöÂêàÂáΩÊï∞ ==========
pivot4 = pd.pivot_table(
    df,
    values='sales',
    index='region',
    columns='product',
    aggfunc=['sum', 'mean', 'count'],
    fill_value=0
)
print("\\nÂ§öÁßçËÅöÂêàÂáΩÊï∞:")
print(pivot4)

# ========== Ëá™ÂÆö‰πâËÅöÂêàÂáΩÊï∞ ==========
def custom_agg(x):
    return x.max() - x.min()

pivot5 = pd.pivot_table(
    df,
    values='sales',
    index='region',
    aggfunc={'sales': [('ÊúÄÂ§ßÂÄº', 'max'), ('ÊúÄÂ∞èÂÄº', 'min'), ('ÊûÅÂ∑Æ', custom_agg)]}
)
print("\\nËá™ÂÆö‰πâËÅöÂêàÂáΩÊï∞:")
print(pivot5)

# ========== ÈÄèËßÜË°®ËΩ¨ÂõûÈïøÊ†ºÂºè ==========
pivot_reset = pivot1.reset_index()
long_format = pivot1.melt(ignore_index=False, var_name='product', value_name='sales')
print("\\nËΩ¨ÂõûÈïøÊ†ºÂºè:")
print(long_format.head())`
        },
        {
          emoji: 'üîÄ',
          title: 'melt Êï∞ÊçÆÈáçÂ°ëÔºàÂÆΩËΩ¨ÈïøÔºâ',
          desc: 'Â∞ÜÂÆΩË°®ËΩ¨Êç¢‰∏∫ÈïøË°®ÔºåÊñπ‰æøÂàÜÊûêÂíåÂèØËßÜÂåñ',
          detail: '**‰∏öÂä°Âú∫ÊôØ**ÔºöÂ§öÂàóËΩ¨ÂçïÂàó„ÄÅÊó∂Èó¥Â∫èÂàóÂàÜÊûê\\n**ÂèçÂêëÊìç‰Ωú**ÔºöpivotÔºàÈïøËΩ¨ÂÆΩÔºâ\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**Ôºöstack/unstack',
          code: `import pandas as pd

# ========== ÂÆΩË°®Á§∫‰æã ==========
wide_df = pd.DataFrame({
    'name': ['Âº†‰∏â', 'ÊùéÂõõ', 'Áéã‰∫î'],
    'ËØ≠Êñá': [85, 90, 88],
    'Êï∞Â≠¶': [92, 88, 95],
    'Ëã±ËØ≠': [78, 85, 90]
})
print("ÂÆΩË°®:")
print(wide_df)

# ========== Âü∫Á°Ä melt ==========
long_df = pd.melt(
    wide_df,
    id_vars=['name'],  # ‰øùÊåÅ‰∏çÂèòÁöÑÂàó
    value_vars=['ËØ≠Êñá', 'Êï∞Â≠¶', 'Ëã±ËØ≠'],  # Ë¶ÅËΩ¨Êç¢ÁöÑÂàó
    var_name='ÁßëÁõÆ',  # Êñ∞ÂàóÂêçÔºàÂéüÂàóÂêçÔºâ
    value_name='ÊàêÁª©'  # Êñ∞ÂàóÂêçÔºàÂÄºÔºâ
)
print("\\nÈïøË°®:")
print(long_df)

# ========== ‰∏çÊåáÂÆö value_varsÔºàËΩ¨Êç¢ÊâÄÊúâÂÖ∂‰ªñÂàóÔºâ==========
long_df2 = pd.melt(wide_df, id_vars=['name'], var_name='ÁßëÁõÆ', value_name='ÊàêÁª©')

# ========== Â§ö‰∏™ id_vars ==========
wide_df2 = pd.DataFrame({
    'name': ['Âº†‰∏â', 'ÊùéÂõõ'],
    'class': ['1Áè≠', '2Áè≠'],
    'Q1_sales': [100, 150],
    'Q2_sales': [120, 160],
    'Q3_sales': [110, 155],
    'Q4_sales': [130, 170]
})

long_df3 = pd.melt(
    wide_df2,
    id_vars=['name', 'class'],
    value_vars=['Q1_sales', 'Q2_sales', 'Q3_sales', 'Q4_sales'],
    var_name='quarter',
    value_name='sales'
)
print("\\nÂ§ö‰∏™id_vars:")
print(long_df3)

# ========== ÂèçÂêëÊìç‰ΩúÔºöpivotÔºàÈïøËΩ¨ÂÆΩÔºâ==========
wide_again = long_df.pivot(
    index='name',
    columns='ÁßëÁõÆ',
    values='ÊàêÁª©'
).reset_index()
print("\\nÈïøË°®ËΩ¨ÂõûÂÆΩË°®:")
print(wide_again)

# ========== stack/unstackÔºàÂ§öÂ±ÇÁ¥¢ÂºïËΩ¨Êç¢Ôºâ==========
# stack: ÂàóËΩ¨Ë°åÔºàÂÆΩËΩ¨ÈïøÔºâ
stacked = wide_df.set_index('name').stack()
print("\\nstackÁªìÊûú:")
print(stacked)

# unstack: Ë°åËΩ¨ÂàóÔºàÈïøËΩ¨ÂÆΩÔºâ
unstacked = stacked.unstack()
print("\\nunstackÁªìÊûú:")
print(unstacked)`
        },
        {
          emoji: 'üìä',
          title: 'crosstab ‰∫§ÂèâË°®ÂàÜÊûê',
          desc: 'ÁªüËÆ°‰∏§‰∏™ÊàñÂ§ö‰∏™ÂèòÈáèÁöÑÈ¢ëÊ¨°ÂàÜÂ∏É',
          detail: '**‰∏öÂä°Âú∫ÊôØ**ÔºöÁî®Êà∑ÁîªÂÉè„ÄÅABÊµãËØïÂàÜÊûê\\n**‰∏épivot_tableÂå∫Âà´**ÔºöcrosstabÁî®‰∫éÈ¢ëÊ¨°ÁªüËÆ°\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöÂç°ÊñπÊ£ÄÈ™å',
          code: `import pandas as pd
import numpy as np

# ÂàõÂª∫Áî®Êà∑Êï∞ÊçÆ
df = pd.DataFrame({
    'user_id': range(1, 1001),
    'gender': np.random.choice(['Áî∑', 'Â•≥'], 1000),
    'age_group': np.random.choice(['18-25', '26-35', '36-45', '46+'], 1000),
    'product': np.random.choice(['‰∫ßÂìÅA', '‰∫ßÂìÅB', '‰∫ßÂìÅC'], 1000),
    'purchased': np.random.choice([0, 1], 1000, p=[0.7, 0.3])
})

# ========== Âü∫Á°Ä‰∫§ÂèâË°®ÔºàÈ¢ëÊ¨°ÁªüËÆ°Ôºâ==========
cross1 = pd.crosstab(df['gender'], df['age_group'])
print("ÊÄßÂà´√óÂπ¥ÈæÑÁªÑ ‰∫§ÂèâË°®:")
print(cross1)

# ========== Ê∑ªÂä†ÊÄªËÆ° ==========
cross2 = pd.crosstab(
    df['gender'], 
    df['age_group'],
    margins=True,
    margins_name='ÊÄªËÆ°'
)
print("\\nÊ∑ªÂä†ÊÄªËÆ°:")
print(cross2)

# ========== ËÆ°ÁÆóÊØî‰æãÔºànormalizeÔºâ==========
# normalize='all': Âç†ÊÄª‰ΩìÁöÑÊØî‰æã
cross3 = pd.crosstab(df['gender'], df['age_group'], normalize='all')
print("\\nÂç†ÊÄª‰ΩìÊØî‰æã:")
print(cross3)

# normalize='index': Ë°åÊØî‰æã
cross4 = pd.crosstab(df['gender'], df['age_group'], normalize='index')
print("\\nË°åÊØî‰æã:")
print(cross4)

# normalize='columns': ÂàóÊØî‰æã
cross5 = pd.crosstab(df['gender'], df['age_group'], normalize='columns')
print("\\nÂàóÊØî‰æã:")
print(cross5)

# ========== Â§öÁª¥‰∫§ÂèâË°® ==========
cross6 = pd.crosstab(
    [df['gender'], df['age_group']],  # Â§öË°åÁ¥¢Âºï
    df['product']
)
print("\\nÂ§öÁª¥‰∫§ÂèâË°®:")
print(cross6)

# ========== Â∏¶ËÅöÂêàÁöÑ‰∫§ÂèâË°® ==========
# ÁªüËÆ°‰∏çÂêåÊÄßÂà´ÂíåÂπ¥ÈæÑÁªÑÁöÑË¥≠‰π∞Áéá
cross7 = pd.crosstab(
    df['gender'],
    df['age_group'],
    values=df['purchased'],
    aggfunc='mean'
)
print("\\nË¥≠‰π∞Áéá‰∫§ÂèâË°®:")
print(cross7)

# ========== ‰∏öÂä°Â∫îÁî®ÔºöABÊµãËØïÂàÜÊûê ==========
ab_test = pd.DataFrame({
    'user_id': range(1, 10001),
    'group': np.random.choice(['A', 'B'], 10000),
    'converted': np.random.choice([0, 1], 10000, p=[0.85, 0.15])
})

# ËÆ°ÁÆóËΩ¨ÂåñÁéá
conversion = pd.crosstab(
    ab_test['group'],
    ab_test['converted'],
    normalize='index'
) * 100
print("\\nABÊµãËØïËΩ¨ÂåñÁéá(%):")
print(conversion)`
        },
        {
          emoji: 'üîó',
          title: 'pipe ÈìæÂºèÊìç‰Ωú',
          desc: 'ËÆ©‰ª£Á†ÅÊõ¥‰ºòÈõÖ„ÄÅÂèØËØªÊÄßÊõ¥Âº∫',
          detail: '**‰ºòÁÇπ**ÔºöÈÅøÂÖç‰∏≠Èó¥ÂèòÈáè„ÄÅ‰ª£Á†ÅÊõ¥Ê∏ÖÊô∞\\n**ÈÄÇÁî®**ÔºöÂ§öÊ≠•Êï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöËá™ÂÆö‰πâpipeÂáΩÊï∞',
          code: `import pandas as pd
import numpy as np

# ÂàõÂª∫Êï∞ÊçÆ
df = pd.DataFrame({
    'name': ['Âº†‰∏â', 'ÊùéÂõõ', 'Áéã‰∫î', 'ËµµÂÖ≠', 'Èí±‰∏É'],
    'age': [25, 30, 35, 28, 32],
    'salary': [8000, 12000, 15000, 9000, 11000],
    'department': ['ÈîÄÂîÆ', 'ÊäÄÊúØ', 'ÊäÄÊúØ', 'ÈîÄÂîÆ', 'Â∏ÇÂú∫']
})

# ========== ‰º†ÁªüÊñπÊ≥ïÔºà‰∫ßÁîü‰∏≠Èó¥ÂèòÈáèÔºâ==========
df_filtered = df[df['age'] > 25]
df_sorted = df_filtered.sort_values('salary', ascending=False)
df_final = df_sorted.reset_index(drop=True)
print("‰º†ÁªüÊñπÊ≥ïÁªìÊûú:")
print(df_final)

# ========== pipeÊñπÊ≥ïÔºàÈìæÂºèÊìç‰ΩúÔºâ==========
result = (df
    .pipe(lambda x: x[x['age'] > 25])
    .pipe(lambda x: x.sort_values('salary', ascending=False))
    .pipe(lambda x: x.reset_index(drop=True))
)
print("\\npipeÊñπÊ≥ïÁªìÊûú:")
print(result)

# ========== Ëá™ÂÆö‰πâpipeÂáΩÊï∞ ==========
def filter_age(df, min_age):
    return df[df['age'] > min_age]

def add_bonus(df, bonus_rate=0.1):
    df = df.copy()
    df['bonus'] = df['salary'] * bonus_rate
    return df

def format_currency(df, cols):
    df = df.copy()
    for col in cols:
        df[col] = df[col].apply(lambda x: f'¬•{x:,.0f}')
    return df

# ‰ΩøÁî®Ëá™ÂÆö‰πâÂáΩÊï∞
result2 = (df
    .pipe(filter_age, min_age=25)
    .pipe(add_bonus, bonus_rate=0.15)
    .pipe(format_currency, cols=['salary', 'bonus'])
)
print("\\nËá™ÂÆö‰πâpipeÂáΩÊï∞:")
print(result2)

# ========== Â§çÊùÇÊï∞ÊçÆÂ§ÑÁêÜÊµÅÁ®ã ==========
sales_df = pd.DataFrame({
    'date': pd.date_range('2024-01-01', periods=100),
    'product': np.random.choice(['A', 'B', 'C'], 100),
    'sales': np.random.randint(100, 1000, 100),
    'quantity': np.random.randint(1, 20, 100)
})

def add_time_features(df):
    df = df.copy()
    df['year'] = df['date'].dt.year
    df['month'] = df['date'].dt.month
    df['weekday'] = df['date'].dt.dayofweek
    return df

def calculate_metrics(df):
    df = df.copy()
    df['unit_price'] = df['sales'] / df['quantity']
    return df

def aggregate_by_product(df):
    return df.groupby('product').agg({
        'sales': 'sum',
        'quantity': 'sum',
        'unit_price': 'mean'
    }).round(2)

# ÂÆåÊï¥Â§ÑÁêÜÊµÅÁ®ã
analysis = (sales_df
    .pipe(add_time_features)
    .pipe(calculate_metrics)
    .pipe(aggregate_by_product)
)
print("\\nÂÆåÊï¥ÂàÜÊûêÊµÅÁ®ã:")
print(analysis)`
        },
        {
          emoji: '‚ö°',
          title: 'eval Âíå query ÊÄßËÉΩ‰ºòÂåñ',
          desc: 'Â§ßÊï∞ÊçÆÈõÜ‰∏ãÁöÑÈ´òÊïàÊü•ËØ¢ÂíåËÆ°ÁÆó',
          detail: '**ÊÄßËÉΩÊèêÂçá**ÔºöÊØî‰º†ÁªüÊñπÊ≥ïÂø´2-10ÂÄç\\n**ÈÄÇÁî®**ÔºöÂ§ßÊï∞ÊçÆÈõÜÔºà>10‰∏áË°åÔºâ\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöËØ≠Ê≥ïÈôêÂà∂„ÄÅÂàóÂêçÈôêÂà∂',
          code: `import pandas as pd
import numpy as np
import time

# ÂàõÂª∫Â§ßÊï∞ÊçÆÈõÜ
np.random.seed(42)
df = pd.DataFrame({
    'A': np.random.randn(1000000),
    'B': np.random.randn(1000000),
    'C': np.random.randn(1000000),
    'category': np.random.choice(['X', 'Y', 'Z'], 1000000)
})

# ========== evalÔºöË°®ËææÂºèËÆ°ÁÆó ==========
# ‰º†ÁªüÊñπÊ≥ï
start = time.time()
df['D1'] = df['A'] + df['B'] * df['C']
t1 = time.time() - start

# evalÊñπÊ≥ïÔºàÊõ¥Âø´Ôºâ
start = time.time()
df['D2'] = df.eval('A + B * C')
t2 = time.time() - start

print(f"‰º†ÁªüÊñπÊ≥ïËÄóÊó∂: {t1:.3f}s")
print(f"evalÊñπÊ≥ïËÄóÊó∂: {t2:.3f}s")
print(f"ÊÄßËÉΩÊèêÂçá: {t1/t2:.2f}ÂÄç")

# ========== queryÔºöÊù°‰ª∂ËøáÊª§ ==========
# ‰º†ÁªüÊñπÊ≥ï
start = time.time()
result1 = df[(df['A'] > 0) & (df['B'] < 0) & (df['category'] == 'X')]
t1 = time.time() - start

# queryÊñπÊ≥ïÔºàÊõ¥Âø´Ôºâ
start = time.time()
result2 = df.query('A > 0 and B < 0 and category == "X"')
t2 = time.time() - start

print(f"\\n‰º†ÁªüËøáÊª§ËÄóÊó∂: {t1:.3f}s")
print(f"queryËøáÊª§ËÄóÊó∂: {t2:.3f}s")
print(f"ÊÄßËÉΩÊèêÂçá: {t1/t2:.2f}ÂÄç")

# ========== eval È´òÁ∫ßÁî®Ê≥ï ==========
# Â§ö‰∏™ËµãÂÄº
df.eval('''
    D = A + B
    E = A * B
    F = A / (B + 1)
''', inplace=True)

# ‰ΩøÁî®ÂèòÈáè
threshold = 0.5
df.query('A > @threshold and B < @threshold')

# ========== query È´òÁ∫ßÁî®Ê≥ï ==========
# Â§çÊùÇÊù°‰ª∂
result = df.query('(A > 0 and B > 0) or (A < 0 and B < 0)')

# ‰ΩøÁî®ÂèòÈáè
min_val = -1
max_val = 1
result = df.query('@min_val < A < @max_val')

# Â≠óÁ¨¶‰∏≤ÂåπÈÖç
result = df.query('category in ["X", "Y"]')

# ========== Ê≥®ÊÑè‰∫ãÈ°π ==========
# 1. ÂàóÂêç‰∏çËÉΩÊúâÁ©∫Ê†ºÔºàÊàñÁî®ÂèçÂºïÂè∑Ôºâ
df_space = pd.DataFrame({'col_1': [1, 2], 'col_2': [3, 4]})
# Â¶ÇÊûúÂàóÂêçÊúâÁ©∫Ê†ºÔºåÈúÄË¶ÅÁî®ÂèçÂºïÂè∑
# ÈîôËØØÔºödf_space.query('col 1 > 1')
# Ê≠£Á°ÆÔºöresult = df_space.query('\`col 1\` > 1')

# 2. ‰∏çÊîØÊåÅÊâÄÊúâPandasÊìç‰Ωú
# queryÂè™ÊîØÊåÅÊØîËæÉ„ÄÅÈÄªËæëËøêÁÆóÔºå‰∏çÊîØÊåÅÂ§çÊùÇÂáΩÊï∞

# 3. Â∞èÊï∞ÊçÆÈõÜÂèØËÉΩÊõ¥ÊÖ¢ÔºàÊúâÈ¢ùÂ§ñËß£ÊûêÂºÄÈîÄÔºâ
small_df = df.head(100)
# Â∞èÊï∞ÊçÆÈõÜÁî®‰º†ÁªüÊñπÊ≥ïÊõ¥Â•Ω`
        },
        {
          emoji: 'üé®',
          title: 'style Ê†∑ÂºèÂåñËæìÂá∫',
          desc: 'DataFrameÁæéÂåñÔºåËÆ©Êä•ÂëäÊõ¥‰∏ì‰∏ö',
          detail: '**‰∏öÂä°Âú∫ÊôØ**ÔºöÊï∞ÊçÆÊä•Âëä„ÄÅÊºîÁ§∫ÊñáÁ®ø\\n**ËæìÂá∫**ÔºöÂ∏¶Ê†∑ÂºèÁöÑHTML„ÄÅExcel\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöËá™ÂÆö‰πâÊ†∑ÂºèÂáΩÊï∞',
          code: `import pandas as pd
import numpy as np

# ÂàõÂª∫ÈîÄÂîÆÊï∞ÊçÆ
df = pd.DataFrame({
    'region': ['ÂåóÂå∫', 'ÂçóÂå∫', '‰∏úÂå∫', 'Ë•øÂå∫', '‰∏≠Âå∫'],
    'Q1': [120, 150, 180, 90, 160],
    'Q2': [130, 140, 190, 95, 155],
    'Q3': [125, 160, 185, 100, 165],
    'Q4': [140, 155, 195, 105, 170]
})

# ========== Âü∫Á°ÄÊ†∑Âºè ==========
# È´ò‰∫ÆÊúÄÂ§ßÂÄº
styled1 = df.style.highlight_max(axis=0, color='#19bcc8')

# È´ò‰∫ÆÊúÄÂ∞èÂÄº
styled2 = df.style.highlight_min(axis=1, color='#ff6b6b')

# ========== Ê∏êÂèòËâ≤ ==========
# ÊåâÂàóÂ∫îÁî®Ê∏êÂèòËâ≤
styled3 = df.style.background_gradient(
    subset=['Q1', 'Q2', 'Q3', 'Q4'],
    cmap='Blues'
)

# ========== Êï∞ÊçÆÊù°ÔºàÁ±ª‰ººExcelÔºâ==========
styled4 = df.style.bar(
    subset=['Q1', 'Q2', 'Q3', 'Q4'],
    color='#19bcc8'
)

# ========== Ê†ºÂºèÂåñÊï∞Â≠ó ==========
styled5 = df.style.format({
    'Q1': '¬•{:,.0f}',
    'Q2': '¬•{:,.0f}',
    'Q3': '¬•{:,.0f}',
    'Q4': '¬•{:,.0f}'
})

# ========== Êù°‰ª∂Ê†ºÂºèÂåñ ==========
def highlight_low(val):
    color = '#ff6b6b' if val < 120 else ''
    return f'background-color: {color}'

styled6 = df.style.map(highlight_low, subset=['Q1', 'Q2', 'Q3', 'Q4'])

# ========== Ëá™ÂÆö‰πâÊ†∑ÂºèÂáΩÊï∞ ==========
def color_by_value(val):
    if val < 100:
        return 'background-color: #ff6b6b; color: white'
    elif val < 150:
        return 'background-color: #ffd93d'
    else:
        return 'background-color: #19bcc8; color: white'

styled7 = df.style.map(color_by_value, subset=['Q1', 'Q2', 'Q3', 'Q4'])

# ========== ÁªÑÂêàÂ§öÁßçÊ†∑Âºè ==========
styled_final = (df.style
    .background_gradient(subset=['Q1', 'Q2', 'Q3', 'Q4'], cmap='coolwarm')
    .highlight_max(axis=0, color='yellow')
    .format({
        'Q1': '¬•{:,.0f}',
        'Q2': '¬•{:,.0f}',
        'Q3': '¬•{:,.0f}',
        'Q4': '¬•{:,.0f}'
    })
    .set_caption('2024Âπ¥Â≠£Â∫¶ÈîÄÂîÆÊä•Âëä')
)

# ========== ÂØºÂá∫ ==========
# ÂØºÂá∫‰∏∫HTML
styled_final.to_html('report.html')

# ÂØºÂá∫‰∏∫ExcelÔºà‰øùÁïôÊ†∑ÂºèÔºâ
with pd.ExcelWriter('report.xlsx', engine='openpyxl') as writer:
    df.to_excel(writer, sheet_name='ÂéüÂßãÊï∞ÊçÆ', index=False)
    # Ê≥®ÊÑèÔºöExcelÂØºÂá∫‰∏çÂÆåÂÖ®ÊîØÊåÅÊâÄÊúâÊ†∑Âºè

print("\\n‚úÖ Ê†∑ÂºèÂåñÊä•ÂëäÂ∑≤ÁîüÊàê")`
        }
      ]
    },
    {
      id: 'string-processing',
      title: 'PART 17 Â≠óÁ¨¶‰∏≤Â§ÑÁêÜ‰∏ìÈ¢ò',
      subtitle: 'ÊñáÊú¨Êï∞ÊçÆÊ∏ÖÊ¥ó‰∏éÊèêÂèñ ‚Äî‚Äî strËÆøÈóÆÂô®ÂÖ®Ëß£Êûê',
      items: [
        {
          emoji: 'üî§',
          title: 'strËÆøÈóÆÂô®Âü∫Á°ÄÊìç‰Ωú ‚òÜ',
          desc: 'Â≠óÁ¨¶‰∏≤Â§ßÂ∞èÂÜô„ÄÅÂéªÁ©∫Ê†º„ÄÅÊõøÊç¢',
          detail: '**Ê†∏ÂøÉ**ÔºöSeries.str ÂèØ‰ª•Ë∞ÉÁî®ÊâÄÊúâÂ≠óÁ¨¶‰∏≤ÊñπÊ≥ï\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöNaNÂÄºÂ§ÑÁêÜ\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöÊ≠£ÂàôË°®ËææÂºè',
          code: `import pandas as pd
import numpy as np

# ÂàõÂª∫Êï∞ÊçÆ
df = pd.DataFrame({
    'name': ['  Âº†‰∏â  ', 'LI SI', 'Áéã‰∫î', None, 'zhao liu'],
    'email': ['zhang@qq.com', 'lisi@GMAIL.COM', 'ww@163.com', np.nan, 'zl@sina.com'],
    'phone': ['138-1234-5678', '139 8765 4321', '13512345678', '(010)12345678', '+86-136-9999-8888']
})

# ========== Â§ßÂ∞èÂÜôËΩ¨Êç¢ ==========
df['name_upper'] = df['name'].str.upper()  # ËΩ¨Â§ßÂÜô
df['name_lower'] = df['name'].str.lower()  # ËΩ¨Â∞èÂÜô
df['name_title'] = df['name'].str.title()  # È¶ñÂ≠óÊØçÂ§ßÂÜô
df['email_lower'] = df['email'].str.lower()  # ÈÇÆÁÆ±Áªü‰∏ÄÂ∞èÂÜô

print("Â§ßÂ∞èÂÜôËΩ¨Êç¢:")
print(df[['name', 'name_upper', 'name_lower', 'name_title']])

# ========== ÂéªÈô§Á©∫Ê†º ==========
df['name_strip'] = df['name'].str.strip()  # ÂéªÈô§‰∏§Á´ØÁ©∫Ê†º
df['name_lstrip'] = df['name'].str.lstrip()  # ÂéªÈô§Â∑¶‰æßÁ©∫Ê†º
df['name_rstrip'] = df['name'].str.rstrip()  # ÂéªÈô§Âè≥‰æßÁ©∫Ê†º

print("\\nÂéªÈô§Á©∫Ê†º:")
print(df[['name', 'name_strip']])

# ========== ÊõøÊç¢ ==========
df['phone_clean'] = df['phone'].str.replace('-', '').str.replace(' ', '').str.replace('(', '').str.replace(')', '').str.replace('+86', '')

print("\\nÁîµËØùÂè∑Á†ÅÊ∏ÖÊ¥ó:")
print(df[['phone', 'phone_clean']])

# ========== Â≠óÁ¨¶‰∏≤ÊãºÊé• ==========
df['full_info'] = df['name'].str.strip() + ' - ' + df['email']

# ========== Âà§Êñ≠ÂåÖÂê´ ==========
df['is_qq'] = df['email'].str.contains('qq', case=False, na=False)
df['is_mobile'] = df['phone'].str.contains('^1[3-9]\\d', regex=True, na=False)

print("\\nÂà§Êñ≠ÂåÖÂê´:")
print(df[['email', 'is_qq', 'phone', 'is_mobile']])

# ========== Âà§Êñ≠ÂºÄÂ§¥/ÁªìÂ∞æ ==========
df['starts_with_1'] = df['phone_clean'].str.startswith('1', na=False)
df['ends_with_com'] = df['email'].str.endswith('.com', na=False)

# ========== Â≠óÁ¨¶‰∏≤ÈïøÂ∫¶ ==========
df['name_len'] = df['name'].str.strip().str.len()
df['phone_len'] = df['phone_clean'].str.len()

print("\\nÂ≠óÁ¨¶‰∏≤ÈïøÂ∫¶:")
print(df[['name', 'name_len']])

# ========== Â≠óÁ¨¶‰∏≤ÂàáÁâá ==========
df['email_domain'] = df['email'].str.split('@').str[1]  # ÊèêÂèñÂüüÂêç
df['phone_prefix'] = df['phone_clean'].str[:3]  # Ââç3‰Ωç

print("\\nÂ≠óÁ¨¶‰∏≤ÂàáÁâá:")
print(df[['email', 'email_domain']])`
        },
        {
          emoji: 'üîç',
          title: 'Ê≠£ÂàôË°®ËææÂºèÂÆûÊàò ‚òÜ',
          desc: 'PythonÊ≠£ÂàôË°®ËææÂºèÂú®Êï∞ÊçÆÊ∏ÖÊ¥ó‰∏≠ÁöÑÂ∫îÁî®',
          detail: '**Ê†∏ÂøÉ**Ôºöstr.extract„ÄÅstr.findall„ÄÅstr.replace\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöËΩ¨‰πâÂ≠óÁ¨¶„ÄÅË¥™Â©™ÂåπÈÖç\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöÂëΩÂêçÊçïËé∑ÁªÑ',
          code: `import pandas as pd
import re

# ÂàõÂª∫ÊµãËØïÊï∞ÊçÆ
df = pd.DataFrame({
    'text': [
        'ËÅîÁ≥ªÁîµËØùÔºö138-1234-5678',
        'ÊàëÁöÑÈÇÆÁÆ±ÊòØzhang@qq.comÔºåÂ§áÁî®ÈÇÆÁÆ±li@163.com',
        'ËÆ¢ÂçïÂè∑ÔºöORDER20240101-12345',
        'ÈáëÈ¢ùÔºö¬•1,234.56ÂÖÉ',
        'Ë∫´‰ªΩËØÅÔºö110101199001011234'
    ]
})

# ========== ÊèêÂèñÁîµËØùÂè∑Á†Å ==========
df['phone'] = df['text'].str.extract(r'(1[3-9]\\d{1}-?\\d{4}-?\\d{4})')

# ========== ÊèêÂèñÈÇÆÁÆ± ==========
df['email'] = df['text'].str.extract(r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,})')

# ÊèêÂèñÊâÄÊúâÈÇÆÁÆ±ÔºàÂèØËÉΩÊúâÂ§ö‰∏™Ôºâ
df['all_emails'] = df['text'].str.findall(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}')

# ========== ÊèêÂèñÊï∞Â≠ó ==========
df['order_num'] = df['text'].str.extract(r'ORDER(\\d+-\\d+)')
df['amount'] = df['text'].str.extract(r'¬•([\\d,]+\\.\\d+)')

print("Ê≠£ÂàôÊèêÂèñÁªìÊûú:")
print(df[['text', 'phone', 'email', 'amount']])

# ========== ÊõøÊç¢ÔºàÊ≠£ÂàôÔºâ==========
# ÊõøÊç¢ÊâÄÊúâÊï∞Â≠ó‰∏∫*
df['masked'] = df['text'].str.replace(r'\\d', '*', regex=True)

# ÁßªÈô§ÊâÄÊúâÊ†áÁÇπÁ¨¶Âè∑
df['no_punct'] = df['text'].str.replace(r'[^\\w\\s]', '', regex=True)

print("\\nÊ≠£ÂàôÊõøÊç¢:")
print(df[['text', 'masked']])

# ========== È™åËØÅÊ†ºÂºè ==========
# È™åËØÅÈÇÆÁÆ±Ê†ºÂºè
email_pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'
emails = pd.Series(['zhang@qq.com', 'invalid-email', 'li@163.com', '@wrong.com'])
emails_valid = emails.str.match(email_pattern)

print("\\nÈÇÆÁÆ±È™åËØÅ:")
print(pd.DataFrame({'email': emails, 'valid': emails_valid}))

# ========== ÂëΩÂêçÊçïËé∑ÁªÑ ==========
order_df = pd.DataFrame({
    'order': ['ORDER20240101-12345', 'ORDER20240102-67890']
})

# ‰ΩøÁî®ÂëΩÂêçÊçïËé∑ÁªÑ
extracted = order_df['order'].str.extract(r'ORDER(?P<date>\\d+)-(?P<id>\\d+)')
print("\\nÂëΩÂêçÊçïËé∑ÁªÑ:")
print(extracted)

# ========== Â∏∏Áî®Ê≠£ÂàôÊ®°Âºè ==========
patterns = {
    'ÊâãÊú∫Âè∑': r'1[3-9]\\d{9}',
    'ÈÇÆÁÆ±': r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}',
    'Ë∫´‰ªΩËØÅ': r'\\d{17}[\\dXx]',
    'IPÂú∞ÂùÄ': r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}',
    'URL': r'https?://[^\\s]+',
    'Êó•ÊúüYYYY-MM-DD': r'\\d{4}-\\d{2}-\\d{2}',
    'ÈáëÈ¢ù': r'¬•?[\\d,]+\\.\\d{2}',
    '‰∏≠Êñá': r'[\\u4e00-\\u9fa5]+',
    'Ëã±ÊñáÂçïËØç': r'[a-zA-Z]+'
}

print("\\nÂ∏∏Áî®Ê≠£ÂàôÊ®°Âºè:")
for name, pattern in patterns.items():
    print(f"{name}: {pattern}")`
        },
        {
          emoji: 'üßπ',
          title: 'ÊñáÊú¨Ê∏ÖÊ¥óÂÆûÊàò',
          desc: 'ÂéªÈô§HTMLÊ†áÁ≠æ„ÄÅÁâπÊÆäÂ≠óÁ¨¶„ÄÅÁ©∫Ê†º',
          detail: '**‰∏öÂä°Âú∫ÊôØ**ÔºöÁà¨Ëô´Êï∞ÊçÆÊ∏ÖÊ¥ó„ÄÅÁî®Êà∑ËæìÂÖ•Ê∏ÖÊ¥ó\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöÁºñÁ†ÅÈóÆÈ¢ò„ÄÅÁâπÊÆäÂ≠óÁ¨¶\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöUnicodeËßÑËåÉÂåñ',
          code: `import pandas as pd
import re
import html

# ÂàõÂª∫ËÑèÊï∞ÊçÆ
df = pd.DataFrame({
    'text': [
        '  Hello  World  ',
        '<p>ËøôÊòØ<b>HTML</b>Ê†áÁ≠æ</p>',
        '‰ª∑Ê†ºÔºö¬•1,234.56ÂÖÉ',
        'ËÅîÁ≥ªÊàëÔºö138-1234-5678 Êàñ zhang@qq.com',
        'ÁâπÊÆäÂ≠óÁ¨¶Ôºö@#$%^&*()',
        '‰∏≠Êñá„ÄÅEnglish„ÄÅ123„ÄÅÁ¨¶Âè∑ÔºÅÔºü',
        '&lt;ËΩ¨‰πâÁ¨¶&gt;&nbsp;&amp;',
        '\\nÊç¢Ë°åÁ¨¶\\tÂà∂Ë°®Á¨¶\\rÂõûËΩ¶Á¨¶',
    ]
})

# ========== 1. ÂéªÈô§È¶ñÂ∞æÁ©∫Ê†º ==========
df['step1'] = df['text'].str.strip()

# ========== 2. ÂéªÈô§Â§ö‰ΩôÁ©∫Ê†ºÔºàÂ§ö‰∏™Á©∫Ê†ºÂèòÂçï‰∏™Ôºâ==========
df['step2'] = df['step1'].str.replace(r'\\s+', ' ', regex=True)

# ========== 3. ÂéªÈô§HTMLÊ†áÁ≠æ ==========
def remove_html_tags(text):
    if pd.isna(text):
        return text
    # Ëß£Á†ÅHTMLÂÆû‰Ωì
    text = html.unescape(text)
    # ÁßªÈô§HTMLÊ†áÁ≠æ
    text = re.sub(r'<[^>]+>', '', text)
    return text

df['step3'] = df['step2'].apply(remove_html_tags)

# ========== 4. ÂéªÈô§ÁâπÊÆäÂ≠óÁ¨¶ÔºàÂè™‰øùÁïô‰∏≠Ëã±Êñá„ÄÅÊï∞Â≠ó„ÄÅÂü∫Êú¨Á¨¶Âè∑Ôºâ==========
df['step4'] = df['step3'].str.replace(r'[^\\w\\sÔºå„ÄÇÔºÅÔºü„ÄÅÔºõÔºö""''ÔºàÔºâ]', '', regex=True)

# ========== 5. Áªü‰∏ÄÊ†áÁÇπÁ¨¶Âè∑Ôºà‰∏≠ÊñáÊ†áÁÇπËΩ¨Ëã±ÊñáÔºâ==========
punctuation_map = {
    'Ôºå': ',',
    '„ÄÇ': '.',
    'ÔºÅ': '!',
    'Ôºü': '?',
    'Ôºõ': ';',
    'Ôºö': ':',
    '"': '"',
    '"': '"',
    ''': "'",
    ''': "'",
    'Ôºà': '(',
    'Ôºâ': ')'
}

def normalize_punctuation(text):
    if pd.isna(text):
        return text
    for cn, en in punctuation_map.items():
        text = text.replace(cn, en)
    return text

df['step5'] = df['step4'].apply(normalize_punctuation)

# ========== 6. ÁßªÈô§Êç¢Ë°åÁ¨¶„ÄÅÂà∂Ë°®Á¨¶ ==========
df['step6'] = df['step5'].str.replace(r'[\\n\\t\\r]', ' ', regex=True)

# ========== 7. Áªü‰∏ÄÂ§ßÂ∞èÂÜôÔºàÂèØÈÄâÔºâ==========
df['step7'] = df['step6'].str.lower()

print("ÊñáÊú¨Ê∏ÖÊ¥óÊµÅÁ®ã:")
print(df[['text', 'step3', 'step6']])

# ========== ÂÆåÊï¥Ê∏ÖÊ¥óÂáΩÊï∞ ==========
def clean_text(text):
    if pd.isna(text):
        return text
    
    # 1. ÂéªÈô§È¶ñÂ∞æÁ©∫Ê†º
    text = text.strip()
    
    # 2. Ëß£Á†ÅHTMLÂÆû‰Ωì
    text = html.unescape(text)
    
    # 3. ÁßªÈô§HTMLÊ†áÁ≠æ
    text = re.sub(r'<[^>]+>', '', text)
    
    # 4. ÁßªÈô§Êç¢Ë°å„ÄÅÂà∂Ë°®„ÄÅÂõûËΩ¶
    text = re.sub(r'[\\n\\t\\r]', ' ', text)
    
    # 5. ÁßªÈô§Â§ö‰ΩôÁ©∫Ê†º
    text = re.sub(r'\\s+', ' ', text)
    
    # 6. ÁßªÈô§ÁâπÊÆäÂ≠óÁ¨¶ÔºàÂèØÈÄâÔºâ
    # text = re.sub(r'[^\\w\\s]', '', text)
    
    return text

df['cleaned'] = df['text'].apply(clean_text)
print("\\nÂÆåÊï¥Ê∏ÖÊ¥óÁªìÊûú:")
print(df[['text', 'cleaned']])`
        },
        {
          emoji: 'üìß',
          title: '‰ø°ÊÅØÊèêÂèñÔºàÁîµËØù„ÄÅÈÇÆÁÆ±„ÄÅË∫´‰ªΩËØÅÔºâ',
          desc: '‰ªéÊñáÊú¨‰∏≠ÊèêÂèñÂÖ≥ÈîÆ‰ø°ÊÅØ',
          detail: '**‰∏öÂä°Âú∫ÊôØ**ÔºöÁî®Êà∑‰ø°ÊÅØÊèêÂèñ„ÄÅÊï∞ÊçÆËÑ±Êïè\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöÊ≠£ÂàôÊÄßËÉΩ„ÄÅËæπÁïåÊÉÖÂÜµ\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöNERÂëΩÂêçÂÆû‰ΩìËØÜÂà´',
          code: `import pandas as pd
import re

# ÂàõÂª∫ÂåÖÂê´ÂêÑÁßç‰ø°ÊÅØÁöÑÊñáÊú¨
df = pd.DataFrame({
    'text': [
        'ÊàëÁöÑÊâãÊú∫ÊòØ13812345678ÔºåÈÇÆÁÆ±zhang@qq.com',
        'ËÅîÁ≥ªÊñπÂºèÔºö139-8765-4321 Êàñ 186 1234 5678',
        'Ë∫´‰ªΩËØÅÂè∑Ôºö11010119900101123X',
        'ÂÖ¨Âè∏ÁîµËØùÔºö010-12345678ÔºåÊâãÊú∫Ôºö+86-13912345678',
        'ÈÇÆÁÆ±Ôºöli.si@company.com.cnÔºåÂ§áÁî®Ôºöwangwu@163.com'
    ]
})

# ========== ÊèêÂèñÊâãÊú∫Âè∑ ==========
def extract_phone(text):
    if pd.isna(text):
        return None
    # ÂåπÈÖçÂêÑÁßçÊâãÊú∫Âè∑Ê†ºÂºè
    pattern = r'(?:\\+86[-\\s]?)?1[3-9]\\d[-\\s]?\\d{4}[-\\s]?\\d{4}'
    phones = re.findall(pattern, text)
    if phones:
        # Ê∏ÖÊ¥óÊ†ºÂºè
        return [re.sub(r'[-\\s+86]', '', p) for p in phones]
    return None

df['phones'] = df['text'].apply(extract_phone)

# ========== ÊèêÂèñÈÇÆÁÆ± ==========
def extract_email(text):
    if pd.isna(text):
        return None
    pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'
    emails = re.findall(pattern, text)
    return emails if emails else None

df['emails'] = df['text'].apply(extract_email)

# ========== ÊèêÂèñË∫´‰ªΩËØÅ ==========
def extract_id_card(text):
    if pd.isna(text):
        return None
    # 18‰ΩçË∫´‰ªΩËØÅ
    pattern = r'\\d{17}[\\dXx]'
    id_cards = re.findall(pattern, text)
    return id_cards if id_cards else None

df['id_cards'] = df['text'].apply(extract_id_card)

# ========== È™åËØÅË∫´‰ªΩËØÅ ==========
def validate_id_card(id_card):
    if not id_card or len(id_card) != 18:
        return False
    
    # Ê†°È™åÁ†ÅÊùÉÈáç
    weights = [7, 9, 10, 5, 8, 4, 2, 1, 6, 3, 7, 9, 10, 5, 8, 4, 2]
    check_codes = ['1', '0', 'X', '9', '8', '7', '6', '5', '4', '3', '2']
    
    try:
        # ËÆ°ÁÆóÊ†°È™åÁ†Å
        total = sum(int(id_card[i]) * weights[i] for i in range(17))
        check_code = check_codes[total % 11]
        
        return id_card[-1].upper() == check_code
    except:
        return False

# ========== È™åËØÅÈÇÆÁÆ± ==========
def validate_email(email):
    if not email:
        return False
    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'
    return bool(re.match(pattern, email))

# ========== È™åËØÅÊâãÊú∫Âè∑ ==========
def validate_phone(phone):
    if not phone:
        return False
    # ÂéªÈô§ÊâÄÊúâÈùûÊï∞Â≠óÂ≠óÁ¨¶
    phone_clean = re.sub(r'\\D', '', phone)
    # ‰∏≠ÂõΩÂ§ßÈôÜÊâãÊú∫Âè∑Ôºö11‰ΩçÔºå1ÂºÄÂ§¥
    return len(phone_clean) == 11 and phone_clean[0] == '1'

print("‰ø°ÊÅØÊèêÂèñÁªìÊûú:")
print(df[['text', 'phones', 'emails', 'id_cards']])

# ========== Êï∞ÊçÆËÑ±Êïè ==========
def mask_phone(phone):
    if not phone or len(phone) != 11:
        return phone
    return phone[:3] + '****' + phone[7:]

def mask_email(email):
    if not email or '@' not in email:
        return email
    parts = email.split('@')
    username = parts[0]
    if len(username) <= 2:
        masked = '*' * len(username)
    else:
        masked = username[0] + '*' * (len(username) - 2) + username[-1]
    return masked + '@' + parts[1]

def mask_id_card(id_card):
    if not id_card or len(id_card) != 18:
        return id_card
    return id_card[:6] + '********' + id_card[14:]

# Â∫îÁî®ËÑ±Êïè
masked_df = pd.DataFrame({
    'phone': ['13812345678', '13987654321'],
    'email': ['zhang@qq.com', 'li.si@company.com'],
    'id_card': ['11010119900101123X', '44030119850202456X']
})

masked_df['phone_masked'] = masked_df['phone'].apply(mask_phone)
masked_df['email_masked'] = masked_df['email'].apply(mask_email)
masked_df['id_card_masked'] = masked_df['id_card'].apply(mask_id_card)

print("\\nÊï∞ÊçÆËÑ±Êïè:")
print(masked_df)`
        },
        {
          emoji: 'üá®üá≥',
          title: '‰∏≠ÊñáÊñáÊú¨Â§ÑÁêÜÔºàjiebaÂàÜËØçÔºâ',
          desc: '‰∏≠ÊñáÂàÜËØç„ÄÅÂÖ≥ÈîÆËØçÊèêÂèñ',
          detail: '**Â∑•ÂÖ∑**ÔºöjiebaÔºàÁªìÂ∑¥ÂàÜËØçÔºâ\\n**‰∏öÂä°Âú∫ÊôØ**ÔºöËØÑËÆ∫ÂàÜÊûê„ÄÅÂÖ≥ÈîÆËØçÊèêÂèñ\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöËØçÊÄßÊ†áÊ≥®„ÄÅÂëΩÂêçÂÆû‰ΩìËØÜÂà´',
          code: `# ÂÆâË£Ö: pip install jieba
import pandas as pd
import jieba
import jieba.analyse
from collections import Counter

# ÂàõÂª∫‰∏≠ÊñáÊñáÊú¨Êï∞ÊçÆ
df = pd.DataFrame({
    'comment': [
        'Ëøô‰∏™‰∫ßÂìÅË¥®ÈáèÈùûÂ∏∏Â•ΩÔºåÂÄºÂæóË¥≠‰π∞ÔºÅ',
        'Áâ©ÊµÅÈÄüÂ∫¶Â§™ÊÖ¢‰∫ÜÔºåÁ≠â‰∫Ü‰∏Ä‰∏™ÊòüÊúüÊâçÂà∞',
        'ÂÆ¢ÊúçÊúçÂä°ÊÄÅÂ∫¶ÂæàÂ•ΩÔºåËß£Á≠îÂæàËÄêÂøÉ',
        '‰ª∑Ê†ºÊúâÁÇπË¥µÔºå‰ΩÜÊòØË¥®ÈáèÁ°ÆÂÆû‰∏çÈîô',
        'ÂåÖË£ÖÁ≤æÁæéÔºåÈÄÅÊúãÂèãÂæàÊúâÈù¢Â≠ê'
    ]
})

# ========== Âü∫Á°ÄÂàÜËØç ==========
df['words'] = df['comment'].apply(lambda x: jieba.lcut(x))

print("Âü∫Á°ÄÂàÜËØç:")
print(df[['comment', 'words']])

# ========== ÂéªÈô§ÂÅúÁî®ËØç ==========
# Ëá™ÂÆö‰πâÂÅúÁî®ËØçË°®
stopwords = set(['ÁöÑ', '‰∫Ü', 'Âæà', 'Êúâ', 'ÊòØ', 'Âú®', '‰∏™', '‰∏Ä'])

def remove_stopwords(words):
    return [w for w in words if w not in stopwords and len(w) > 1]

df['words_clean'] = df['words'].apply(remove_stopwords)

print("\\nÂéªÈô§ÂÅúÁî®ËØç:")
print(df[['comment', 'words_clean']])

# ========== ÂÖ≥ÈîÆËØçÊèêÂèñÔºàTF-IDFÔºâ==========
def extract_keywords_tfidf(text, topK=3):
    keywords = jieba.analyse.extract_tags(text, topK=topK, withWeight=True)
    return keywords

df['keywords_tfidf'] = df['comment'].apply(lambda x: extract_keywords_tfidf(x, topK=3))

print("\\nÂÖ≥ÈîÆËØçÊèêÂèñÔºàTF-IDFÔºâ:")
print(df[['comment', 'keywords_tfidf']])

# ========== ÂÖ≥ÈîÆËØçÊèêÂèñÔºàTextRankÔºâ==========
def extract_keywords_textrank(text, topK=3):
    keywords = jieba.analyse.textrank(text, topK=topK, withWeight=True)
    return keywords

df['keywords_textrank'] = df['comment'].apply(lambda x: extract_keywords_textrank(x, topK=3))

# ========== ËØçÈ¢ëÁªüËÆ° ==========
all_words = []
for words in df['words_clean']:
    all_words.extend(words)

word_counts = Counter(all_words)
top_words = word_counts.most_common(10)

print("\\nËØçÈ¢ëÁªüËÆ°Top 10:")
for word, count in top_words:
    print(f"{word}: {count}")

# ========== Ëá™ÂÆö‰πâËØçÂÖ∏ ==========
# Ê∑ªÂä†Ëá™ÂÆö‰πâËØçÊ±áÔºàÊèêÈ´òÂàÜËØçÂáÜÁ°ÆÊÄßÔºâ
jieba.add_word('ÂÆ¢ÊúçÊúçÂä°')
jieba.add_word('Áâ©ÊµÅÈÄüÂ∫¶')

df['words_custom'] = df['comment'].apply(lambda x: jieba.lcut(x))

print("\\nÊ∑ªÂä†Ëá™ÂÆö‰πâËØçÂÖ∏Âêé:")
print(df[['comment', 'words_custom']])

# ========== ÊÉÖÊÑüËØçÂÖ∏ÔºàÁÆÄÂçïÁâàÔºâ==========
positive_words = set(['Â•Ω', '‰∏çÈîô', 'Á≤æÁæé', 'ËÄêÂøÉ', 'ÂÄºÂæó'])
negative_words = set(['ÊÖ¢', 'Ë¥µ', 'Â∑Æ'])

def sentiment_score(words):
    pos_count = sum(1 for w in words if w in positive_words)
    neg_count = sum(1 for w in words if w in negative_words)
    return pos_count - neg_count

df['sentiment'] = df['words_clean'].apply(sentiment_score)
df['sentiment_label'] = df['sentiment'].apply(
    lambda x: 'Ê≠£Èù¢' if x > 0 else ('Ë¥üÈù¢' if x < 0 else '‰∏≠ÊÄß')
)

print("\\nÊÉÖÊÑüÂàÜÊûê:")
print(df[['comment', 'sentiment', 'sentiment_label']])

# ========== ËØç‰∫ëÊï∞ÊçÆÂáÜÂ§á ==========
# ÂáÜÂ§áËØç‰∫ëÊâÄÈúÄÁöÑËØçÈ¢ëÊï∞ÊçÆ
wordcloud_data = ' '.join(all_words)
print("\\nËØç‰∫ëÊï∞ÊçÆÔºàÂâç100Â≠óÁ¨¶Ôºâ:")
print(wordcloud_data[:100])`
        }
      ]
    },
    {
      id: 'time-series-advanced',
      title: 'PART 18 Êó∂Èó¥Â∫èÂàóÊ∑±Â∫¶ÂàÜÊûê',
      subtitle: 'Êó∂Èó¥Êï∞ÊçÆÂ§ÑÁêÜËøõÈò∂ ‚Äî‚Äî ‰ªéÂü∫Á°ÄÂà∞È´òÁ∫ßÂ∫îÁî®',
      items: [
        {
          emoji: 'üìÖ',
          title: 'Êó∂Èó¥Â∫èÂàóÂàÜËß£ ‚òÜ',
          desc: 'Ë∂ãÂäø„ÄÅÂ≠£ËäÇÊÄß„ÄÅÊÆãÂ∑Æ‰∏âË¶ÅÁ¥†ÂàÜÊûê',
          detail: '**Ê®°Âûã**ÔºöÂä†Ê≥ïÊ®°Âûã„ÄÅ‰πòÊ≥ïÊ®°Âûã\\n**‰∏öÂä°Â∫îÁî®**ÔºöÈîÄÂîÆÈ¢ÑÊµã„ÄÅÂºÇÂ∏∏Ê£ÄÊµã\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöSTLÂàÜËß£',
          code: `import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.seasonal import seasonal_decompose

# ÂàõÂª∫Êó∂Èó¥Â∫èÂàóÊï∞ÊçÆ
dates = pd.date_range('2022-01-01', periods=365, freq='D')
trend = np.linspace(100, 200, 365)
seasonal = 20 * np.sin(np.linspace(0, 4*np.pi, 365))
noise = np.random.randn(365) * 5
sales = trend + seasonal + noise

df = pd.DataFrame({
    'date': dates,
    'sales': sales
})
df.set_index('date', inplace=True)

# ========== Êó∂Èó¥Â∫èÂàóÂàÜËß£ ==========
# Âä†Ê≥ïÊ®°ÂûãÔºöY = T + S + RÔºàË∂ãÂäø+Â≠£ËäÇÊÄß+ÊÆãÂ∑ÆÔºâ
decomposition_add = seasonal_decompose(
    df['sales'], 
    model='additive', 
    period=30  # Â≠£ËäÇÂë®ÊúüÔºà30Â§©Ôºâ
)

# ‰πòÊ≥ïÊ®°ÂûãÔºöY = T * S * R
decomposition_mul = seasonal_decompose(
    df['sales'], 
    model='multiplicative', 
    period=30
)

# ========== ÂèØËßÜÂåñÂàÜËß£ÁªìÊûú ==========
fig, axes = plt.subplots(4, 1, figsize=(14, 10))

# ÂéüÂßãÊï∞ÊçÆ
df['sales'].plot(ax=axes[0], color='#19bcc8')
axes[0].set_title('ÂéüÂßãÈîÄÂîÆÊï∞ÊçÆ', fontsize=14, fontweight='bold')
axes[0].set_ylabel('ÈîÄÂîÆÈ¢ù')

# Ë∂ãÂäø
decomposition_add.trend.plot(ax=axes[1], color='#17a8b4')
axes[1].set_title('Ë∂ãÂäøÔºàTrendÔºâ', fontsize=14, fontweight='bold')
axes[1].set_ylabel('Ë∂ãÂäøÂÄº')

# Â≠£ËäÇÊÄß
decomposition_add.seasonal.plot(ax=axes[2], color='#1596a2')
axes[2].set_title('Â≠£ËäÇÊÄßÔºàSeasonalÔºâ', fontsize=14, fontweight='bold')
axes[2].set_ylabel('Â≠£ËäÇÊÄßÊ≥¢Âä®')

# ÊÆãÂ∑Æ
decomposition_add.resid.plot(ax=axes[3], color='#138490')
axes[3].set_title('ÊÆãÂ∑ÆÔºàResidualÔºâ', fontsize=14, fontweight='bold')
axes[3].set_ylabel('ÊÆãÂ∑Æ')

plt.tight_layout()
plt.savefig('time_series_decomposition.png', dpi=300)

# ========== ÊèêÂèñÂêÑÊàêÂàÜ ==========
trend_component = decomposition_add.trend
seasonal_component = decomposition_add.seasonal
residual_component = decomposition_add.resid

print("Ë∂ãÂäøÊàêÂàÜÁªüËÆ°:")
print(trend_component.describe())

print("\\nÂ≠£ËäÇÊÄßÊàêÂàÜÁªüËÆ°:")
print(seasonal_component.describe())

print("\\nÊÆãÂ∑ÆÊàêÂàÜÁªüËÆ°:")
print(residual_component.describe())

# ========== ÂºÇÂ∏∏Ê£ÄÊµãÔºàÂü∫‰∫éÊÆãÂ∑ÆÔºâ==========
# ÊÆãÂ∑ÆË∂ÖËøá3ÂÄçÊ†áÂáÜÂ∑ÆËßÜ‰∏∫ÂºÇÂ∏∏
std_resid = residual_component.std()
anomalies = residual_component[abs(residual_component) > 3 * std_resid]

print(f"\\nÊ£ÄÊµãÂà∞ {len(anomalies)} ‰∏™ÂºÇÂ∏∏ÁÇπ:")
print(anomalies)`
        },
        {
          emoji: 'üìä',
          title: 'ÊªöÂä®ÁªüËÆ°ÔºàRolling & ExpandingÔºâ‚òÜ',
          desc: 'ÁßªÂä®Âπ≥Âùá„ÄÅÁ¥ØËÆ°ÁªüËÆ°',
          detail: '**Ê†∏ÂøÉ**ÔºörollingÔºàÊªëÂä®Á™óÂè£Ôºâ„ÄÅexpandingÔºàÁ¥ØÁßØÁ™óÂè£Ôºâ\\n**‰∏öÂä°Â∫îÁî®**ÔºöÂπ≥ÊªëÊõ≤Á∫ø„ÄÅÁ¥ØËÆ°ÊåáÊ†á\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöÊåáÊï∞Âä†ÊùÉÁßªÂä®Âπ≥ÂùáÔºàEWMÔºâ',
          code: `import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# ÂàõÂª∫ËÇ°Á•®‰ª∑Ê†ºÊï∞ÊçÆ
dates = pd.date_range('2024-01-01', periods=100, freq='D')
price = 100 + np.cumsum(np.random.randn(100) * 2)
df = pd.DataFrame({
    'date': dates,
    'price': price
})
df.set_index('date', inplace=True)

# ========== ÊªöÂä®Á™óÂè£ÁªüËÆ°ÔºàrollingÔºâ==========
# 7Êó•ÁßªÂä®Âπ≥Âùá
df['MA_7'] = df['price'].rolling(window=7).mean()

# 30Êó•ÁßªÂä®Âπ≥Âùá
df['MA_30'] = df['price'].rolling(window=30).mean()

# ÊªöÂä®Ê†áÂáÜÂ∑ÆÔºàÊ≥¢Âä®ÁéáÔºâ
df['volatility'] = df['price'].rolling(window=7).std()

# ÊªöÂä®ÊúÄÂ§ßÂÄº„ÄÅÊúÄÂ∞èÂÄº
df['rolling_max'] = df['price'].rolling(window=7).max()
df['rolling_min'] = df['price'].rolling(window=7).min()

print("ÊªöÂä®ÁªüËÆ°:")
print(df[['price', 'MA_7', 'MA_30', 'volatility']].head(35))

# ========== Á¥ØËÆ°ÁªüËÆ°ÔºàexpandingÔºâ==========
# Á¥ØËÆ°ÂùáÂÄºÔºà‰ªéÂºÄÂßãÂà∞ÂΩìÂâçÔºâ
df['cumulative_mean'] = df['price'].expanding().mean()

# Á¥ØËÆ°ÊúÄÂ§ßÂÄº
df['cumulative_max'] = df['price'].expanding().max()

# Á¥ØËÆ°ÊúÄÂ∞èÂÄº
df['cumulative_min'] = df['price'].expanding().min()

print("\\nÁ¥ØËÆ°ÁªüËÆ°:")
print(df[['price', 'cumulative_mean', 'cumulative_max', 'cumulative_min']].head(10))

# ========== ÊåáÊï∞Âä†ÊùÉÁßªÂä®Âπ≥ÂùáÔºàEWMÔºâ==========
# Áõ∏ÊØîÁÆÄÂçïÁßªÂä®Âπ≥ÂùáÔºåEWMÂØπËøëÊúüÊï∞ÊçÆÊùÉÈáçÊõ¥Â§ß
df['EMA_12'] = df['price'].ewm(span=12).mean()
df['EMA_26'] = df['price'].ewm(span=26).mean()

# MACDÊåáÊ†áÔºàËÇ°Á•®ÊäÄÊúØÂàÜÊûêÂ∏∏Áî®Ôºâ
df['MACD'] = df['EMA_12'] - df['EMA_26']

print("\\nÊåáÊï∞Âä†ÊùÉÁßªÂä®Âπ≥Âùá:")
print(df[['price', 'EMA_12', 'EMA_26', 'MACD']].head(30))

# ========== ÂèØËßÜÂåñ ==========
fig, axes = plt.subplots(3, 1, figsize=(14, 10))

# Â≠êÂõæ1Ôºö‰ª∑Ê†º‰∏éÁßªÂä®Âπ≥ÂùáÁ∫ø
df['price'].plot(ax=axes[0], label='ÂéüÂßã‰ª∑Ê†º', color='#19bcc8', alpha=0.5)
df['MA_7'].plot(ax=axes[0], label='7Êó•ÂùáÁ∫ø', color='#17a8b4', linewidth=2)
df['MA_30'].plot(ax=axes[0], label='30Êó•ÂùáÁ∫ø', color='#1596a2', linewidth=2)
axes[0].set_title('‰ª∑Ê†º‰∏éÁßªÂä®Âπ≥ÂùáÁ∫ø', fontsize=14, fontweight='bold')
axes[0].legend()
axes[0].grid(alpha=0.3)

# Â≠êÂõæ2ÔºöÊ≥¢Âä®Áéá
df['volatility'].plot(ax=axes[1], color='#ff6b6b', linewidth=2)
axes[1].set_title('7Êó•ÊªöÂä®Ê≥¢Âä®Áéá', fontsize=14, fontweight='bold')
axes[1].grid(alpha=0.3)

# Â≠êÂõæ3ÔºöMACD
df['MACD'].plot(ax=axes[2], color='#138490', linewidth=2)
axes[2].axhline(y=0, color='gray', linestyle='--')
axes[2].set_title('MACDÊåáÊ†á', fontsize=14, fontweight='bold')
axes[2].grid(alpha=0.3)

plt.tight_layout()
plt.savefig('rolling_statistics.png', dpi=300)

# ========== È´òÁ∫ßÁî®Ê≥ïÔºöËá™ÂÆö‰πâÊªöÂä®ÂáΩÊï∞ ==========
def custom_range(x):
    return x.max() - x.min()

df['rolling_range'] = df['price'].rolling(window=7).apply(custom_range)

print("\\nËá™ÂÆö‰πâÊªöÂä®ÂáΩÊï∞Ôºà7Êó•‰ª∑Ê†ºÊûÅÂ∑ÆÔºâ:")
print(df[['price', 'rolling_range']].head(10))`
        },
        {
          emoji: '‚è∞',
          title: 'Êó∂Èó¥Á™óÂè£Êìç‰ΩúÈ´òÁ∫ßÊäÄÂ∑ß',
          desc: 'resample„ÄÅÊó∂Âå∫ËΩ¨Êç¢„ÄÅÂ∑•‰ΩúÊó•Â§ÑÁêÜ',
          detail: '**Ê†∏ÂøÉ**ÔºöÈáçÈááÊ†∑„ÄÅÊó∂Âå∫Â§ÑÁêÜ„ÄÅ‰∏öÂä°Êó•ÂéÜ\\n**‰∏öÂä°Â∫îÁî®**ÔºöÊï∞ÊçÆËÅöÂêà„ÄÅË∑®Êó∂Âå∫ÂàÜÊûê\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöËá™ÂÆö‰πâÈ¢ëÁéá„ÄÅÂÅèÁßªÈáè',
          code: `import pandas as pd
import numpy as np
from pandas.tseries.offsets import BDay, MonthEnd

# ÂàõÂª∫ÊØèÂ∞èÊó∂Êï∞ÊçÆ
dates = pd.date_range('2024-01-01', periods=24*7, freq='H')
df = pd.DataFrame({
    'timestamp': dates,
    'value': np.random.randint(10, 100, 24*7)
})
df.set_index('timestamp', inplace=True)

# ========== resample ÈáçÈááÊ†∑ ==========
# Â∞èÊó∂Êï∞ÊçÆ ‚Üí Â§©Êï∞ÊçÆ
daily = df.resample('D').agg({
    'value': ['sum', 'mean', 'max', 'min', 'count']
})
print("Â∞èÊó∂‚ÜíÂ§©ÔºàÈáçÈááÊ†∑Ôºâ:")
print(daily.head())

# Â∞èÊó∂Êï∞ÊçÆ ‚Üí Âë®Êï∞ÊçÆ
weekly = df.resample('W').sum()
print("\\nÂ∞èÊó∂‚ÜíÂë®:")
print(weekly.head())

# ÂêëÂâçÂ°´ÂÖÖÔºàffillÔºâÂíåÂêëÂêéÂ°´ÂÖÖÔºàbfillÔºâ
daily_ffill = df.resample('D').ffill()
daily_bfill = df.resample('D').bfill()

# ========== Ëá™ÂÆö‰πâËÅöÂêà ==========
def custom_agg(x):
    return {
        'ÊÄªÂíå': x.sum(),
        'ÂùáÂÄº': x.mean(),
        '‰∏≠‰ΩçÊï∞': x.median(),
        'Ê†áÂáÜÂ∑Æ': x.std()
    }

daily_custom = df.resample('D')['value'].apply(custom_agg).apply(pd.Series)
print("\\nËá™ÂÆö‰πâËÅöÂêà:")
print(daily_custom.head())

# ========== Êó∂Âå∫Â§ÑÁêÜ ==========
# Ê∑ªÂä†Êó∂Âå∫‰ø°ÊÅØ
df_tz = df.copy()
df_tz.index = df_tz.index.tz_localize('UTC')

# ËΩ¨Êç¢Êó∂Âå∫
df_beijing = df_tz.tz_convert('Asia/Shanghai')
df_newyork = df_tz.tz_convert('America/New_York')

print("\\nÊó∂Âå∫ËΩ¨Êç¢:")
print(f"UTCÊó∂Èó¥: {df_tz.index[0]}")
print(f"Âåó‰∫¨Êó∂Èó¥: {df_beijing.index[0]}")
print(f"Á∫ΩÁ∫¶Êó∂Èó¥: {df_newyork.index[0]}")

# ========== Â∑•‰ΩúÊó•Â§ÑÁêÜ ==========
# ÂàõÂª∫Â∑•‰ΩúÊó•Êó•ÊúüËåÉÂõ¥
business_days = pd.bdate_range('2024-01-01', '2024-12-31')
print(f"\\n2024Âπ¥Â∑•‰ΩúÊó•Êï∞Èáè: {len(business_days)}")

# Ëé∑Âèñ‰∏ã‰∏Ä‰∏™Â∑•‰ΩúÊó•
from datetime import datetime
today = pd.Timestamp('2024-01-06')  # Âë®ÂÖ≠
next_bday = today + BDay(1)
print(f"‰ªäÂ§©: {today.strftime('%Y-%m-%d %A')}")
print(f"‰∏ã‰∏™Â∑•‰ΩúÊó•: {next_bday.strftime('%Y-%m-%d %A')}")

# Ëé∑ÂèñÊúàÊú´Êó•Êúü
month_end = pd.Timestamp('2024-01-15') + MonthEnd(0)
print(f"\\n2024-01-15ÁöÑÊúàÊú´: {month_end}")

# ========== ‰∏≠ÂõΩËäÇÂÅáÊó•Â§ÑÁêÜÔºàÈúÄËá™ÂÆö‰πâÔºâ==========
# Ëá™ÂÆö‰πâËäÇÂÅáÊó•ÂàóË°®
holidays = pd.to_datetime([
    '2024-01-01',  # ÂÖÉÊó¶
    '2024-02-10', '2024-02-11', '2024-02-12',  # Êò•ËäÇ
    '2024-04-04', '2024-04-05', '2024-04-06',  # Ê∏ÖÊòé
    '2024-05-01', '2024-05-02', '2024-05-03',  # Âä≥Âä®ËäÇ
    '2024-10-01', '2024-10-02', '2024-10-03'   # ÂõΩÂ∫Ü
])

# ÂàõÂª∫Ëá™ÂÆö‰πâÂ∑•‰ΩúÊó•Êó•ÂéÜ
from pandas.tseries.holiday import AbstractHolidayCalendar, Holiday
class ChinaHolidayCalendar(AbstractHolidayCalendar):
    rules = [Holiday(name, year=2024, month=h.month, day=h.day) 
             for name, h in zip(['Holiday']*len(holidays), holidays)]

# ÁîüÊàêÂåÖÂê´ËäÇÂÅáÊó•ÁöÑÊó•ÊúüËåÉÂõ¥
china_bdays = pd.bdate_range('2024-01-01', '2024-12-31', 
                              freq='C', holidays=holidays)
print(f"\\n2024Âπ¥‰∏≠ÂõΩÂ∑•‰ΩúÊó•Êï∞ÈáèÔºàÂê´ËäÇÂÅáÊó•Ôºâ: {len(china_bdays)}")

# ========== Êó∂Èó¥ÂÅèÁßª ==========
base_date = pd.Timestamp('2024-01-15')
print(f"\\nÂü∫ÂáÜÊó•Êúü: {base_date}")
print(f"3Â§©Âêé: {base_date + pd.Timedelta(days=3)}")
print(f"2Âë®Âêé: {base_date + pd.Timedelta(weeks=2)}")
print(f"1‰∏™ÊúàÂêé: {base_date + pd.DateOffset(months=1)}")
print(f"3‰∏™Â∑•‰ΩúÊó•Âêé: {base_date + BDay(3)}")`
        },
        {
          emoji: 'üìà',
          title: 'ÂêåÊØî„ÄÅÁéØÊØîËÆ°ÁÆóÊ®°Êùø',
          desc: 'YoY„ÄÅMoM„ÄÅQoQÂ¢ûÈïøÁéáËÆ°ÁÆó',
          detail: '**‰∏öÂä°Âú∫ÊôØ**ÔºöÈîÄÂîÆÂàÜÊûê„ÄÅKPIÁõëÊéß\\n**ÂÖ¨Âºè**Ôºö(Êú¨Êúü-‰∏äÊúü)/‰∏äÊúü*100%\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöCAGRÂ§çÂêàÂ¢ûÈïøÁéá',
          code: `import pandas as pd
import numpy as np

# ÂàõÂª∫ÊúàÂ∫¶ÈîÄÂîÆÊï∞ÊçÆ
dates = pd.date_range('2022-01-01', periods=36, freq='MS')
sales = 1000 + np.cumsum(np.random.randn(36) * 50)
df = pd.DataFrame({
    'date': dates,
    'sales': sales
})
df['year'] = df['date'].dt.year
df['month'] = df['date'].dt.month
df['quarter'] = df['date'].dt.quarter

# ========== ÁéØÊØîÔºàMoM - Month over MonthÔºâ==========
# Êú¨ÊúàÁõ∏ÊØî‰∏äÊúàÁöÑÂ¢ûÈïøÁéá
df['sales_last_month'] = df['sales'].shift(1)
df['MoM'] = (df['sales'] - df['sales_last_month']) / df['sales_last_month'] * 100

# ========== ÂêåÊØîÔºàYoY - Year over YearÔºâ==========
# Êú¨ÊúàÁõ∏ÊØîÂéªÂπ¥ÂêåÊúüÁöÑÂ¢ûÈïøÁéá
df['sales_last_year'] = df['sales'].shift(12)
df['YoY'] = (df['sales'] - df['sales_last_year']) / df['sales_last_year'] * 100

# ========== Â≠£Â∫¶ÁéØÊØîÔºàQoQ - Quarter over QuarterÔºâ==========
# ÊåâÂ≠£Â∫¶ËÅöÂêà
quarterly = df.groupby(['year', 'quarter'])['sales'].sum().reset_index()
quarterly['sales_last_quarter'] = quarterly['sales'].shift(1)
quarterly['QoQ'] = (quarterly['sales'] - quarterly['sales_last_quarter']) / quarterly['sales_last_quarter'] * 100

print("ÁéØÊØî„ÄÅÂêåÊØîÂàÜÊûê:")
print(df[['date', 'sales', 'MoM', 'YoY']].tail(15))

print("\\nÂ≠£Â∫¶ÁéØÊØîÂàÜÊûê:")
print(quarterly)

# ========== ÊªöÂä®ÂêåÊØîÔºà12‰∏™ÊúàÁßªÂä®Âπ≥ÂùáÁöÑÂêåÊØîÔºâ==========
df['MA_12'] = df['sales'].rolling(window=12).mean()
df['MA_12_last_year'] = df['MA_12'].shift(12)
df['YoY_MA'] = (df['MA_12'] - df['MA_12_last_year']) / df['MA_12_last_year'] * 100

# ========== CAGRÔºàÂ§çÂêàÂπ¥ÂùáÂ¢ûÈïøÁéáÔºâ==========
def calculate_cagr(start_value, end_value, years):
    return (pow(end_value / start_value, 1 / years) - 1) * 100

# ËÆ°ÁÆó3Âπ¥CAGR
first_year_sales = df[df['year'] == 2022]['sales'].sum()
last_year_sales = df[df['year'] == 2024]['sales'].sum()
cagr_3y = calculate_cagr(first_year_sales, last_year_sales, 3)

print(f"\\n3Âπ¥CAGR: {cagr_3y:.2f}%")

# ========== ÂèØËßÜÂåñ ==========
import matplotlib.pyplot as plt

fig, axes = plt.subplots(2, 1, figsize=(14, 10))

# Â≠êÂõæ1ÔºöÈîÄÂîÆÈ¢ù‰∏éÂ¢ûÈïøÁéá
ax1 = axes[0]
ax2 = ax1.twinx()

ax1.plot(df['date'], df['sales'], color='#19bcc8', linewidth=2, label='ÈîÄÂîÆÈ¢ù')
ax2.plot(df['date'], df['YoY'], color='#ff6b6b', linewidth=2, label='ÂêåÊØîÂ¢ûÈïøÁéá', linestyle='--')
ax2.axhline(y=0, color='gray', linestyle='-', alpha=0.5)

ax1.set_xlabel('Êó•Êúü')
ax1.set_ylabel('ÈîÄÂîÆÈ¢ù', color='#19bcc8')
ax2.set_ylabel('ÂêåÊØîÂ¢ûÈïøÁéá(%)', color='#ff6b6b')
ax1.set_title('ÈîÄÂîÆÈ¢ù‰∏éÂêåÊØîÂ¢ûÈïøÁéá', fontsize=14, fontweight='bold')
ax1.legend(loc='upper left')
ax2.legend(loc='upper right')
ax1.grid(alpha=0.3)

# Â≠êÂõæ2ÔºöÁéØÊØîvsÂêåÊØî
axes[1].plot(df['date'], df['MoM'], color='#17a8b4', linewidth=2, label='ÁéØÊØî(MoM)')
axes[1].plot(df['date'], df['YoY'], color='#ff6b6b', linewidth=2, label='ÂêåÊØî(YoY)')
axes[1].axhline(y=0, color='gray', linestyle='-', alpha=0.5)
axes[1].set_xlabel('Êó•Êúü')
axes[1].set_ylabel('Â¢ûÈïøÁéá(%)')
axes[1].set_title('ÁéØÊØîvsÂêåÊØîÂ¢ûÈïøÁéáÂØπÊØî', fontsize=14, fontweight='bold')
axes[1].legend()
axes[1].grid(alpha=0.3)

plt.tight_layout()
plt.savefig('yoy_mom_analysis.png', dpi=300)

# ========== ‰∏öÂä°Â∫îÁî®ÔºöËØÜÂà´ÂºÇÂ∏∏Â¢ûÈïø ==========
# YoYÂ¢ûÈïøÁéáË∂ÖËøá¬±30%ËßÜ‰∏∫ÂºÇÂ∏∏
anomaly_growth = df[(abs(df['YoY']) > 30)][['date', 'sales', 'YoY']]
print("\\nÂºÇÂ∏∏Â¢ûÈïøÊúà‰ªΩ:")
print(anomaly_growth)`
        },
        {
          emoji: 'üîÑ',
          title: 'Áî®Êà∑ÁïôÂ≠òÂàÜÊûêÔºàCohort AnalysisÔºâ',
          desc: 'ÈòüÂàóÂàÜÊûêÔºåËÆ°ÁÆóÁî®Êà∑ÁïôÂ≠òÁéá',
          detail: '**‰∏öÂä°‰ª∑ÂÄº**ÔºöË°°Èáè‰∫ßÂìÅÁ≤òÊÄß„ÄÅÁî®Êà∑ÁîüÂëΩÂë®Êúü\\n**Ê†∏ÂøÉÊåáÊ†á**ÔºöÊ¨°Êó•ÁïôÂ≠ò„ÄÅ7Êó•ÁïôÂ≠ò„ÄÅ30Êó•ÁïôÂ≠ò\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöÁïôÂ≠òÊõ≤Á∫ø„ÄÅÁî®Êà∑ÂàÜÁæ§',
          code: `import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# ÂàõÂª∫Áî®Êà∑Ë°å‰∏∫Êï∞ÊçÆ
np.random.seed(42)
user_ids = range(1, 1001)
dates = pd.date_range('2024-01-01', periods=90, freq='D')

# ÁîüÊàêÁî®Êà∑Ê¥ªË∑ÉËÆ∞ÂΩï
records = []
for user_id in user_ids:
    # Áî®Êà∑È¶ñÊ¨°ÁôªÂΩïÊó•Êúü
    first_login = np.random.choice(dates[:30])
    records.append({
        'user_id': user_id,
        'date': first_login,
        'is_new_user': 1
    })
    
    # ÂêéÁª≠Ê¥ªË∑ÉÔºàÁïôÂ≠òÁéáÈÄêÊ∏ê‰∏ãÈôçÔºâ
    current_date = first_login
    retention_prob = 0.8
    for i in range(60):
        if np.random.rand() < retention_prob:
            current_date += pd.Timedelta(days=1)
            if current_date in dates:
                records.append({
                    'user_id': user_id,
                    'date': current_date,
                    'is_new_user': 0
                })
        retention_prob *= 0.98  # ÁïôÂ≠òÁéáÈÄíÂáè

df = pd.DataFrame(records)

# ========== Á°ÆÂÆöÁî®Êà∑È¶ñÊ¨°Ê¥ªË∑ÉÊó•ÊúüÔºàÈòüÂàóÔºâ==========
user_cohort = df.groupby('user_id')['date'].min().reset_index()
user_cohort.columns = ['user_id', 'cohort_date']
user_cohort['cohort'] = user_cohort['cohort_date'].dt.to_period('D')

# ÂêàÂπ∂ÈòüÂàó‰ø°ÊÅØ
df = df.merge(user_cohort, on='user_id')

# ========== ËÆ°ÁÆóÁî®Êà∑Ê¥ªË∑ÉÂ§©Êï∞ÔºàÁõ∏ÂØπ‰∫éÈ¶ñÊ¨°Ê¥ªË∑ÉÔºâ==========
df['days_since_first'] = (df['date'] - df['cohort_date']).dt.days

# ========== ÊûÑÂª∫ÁïôÂ≠òÁü©Èòµ ==========
retention_matrix = df.groupby(['cohort', 'days_since_first'])['user_id'].nunique().reset_index()
retention_matrix.columns = ['cohort', 'days', 'active_users']

# Ëé∑ÂèñÊØè‰∏™ÈòüÂàóÁöÑÂàùÂßãÁî®Êà∑Êï∞
cohort_sizes = user_cohort.groupby('cohort')['user_id'].nunique()

# ËÆ°ÁÆóÁïôÂ≠òÁéá
retention_matrix = retention_matrix.set_index(['cohort', 'days'])['active_users'].unstack()
retention_rate = retention_matrix.divide(cohort_sizes, axis=0) * 100

print("ÁïôÂ≠òÁéáÁü©ÈòµÔºà%Ôºâ:")
print(retention_rate.iloc[:10, :8])  # ÊòæÁ§∫Ââç10‰∏™ÈòüÂàóÔºåÂâç8Â§©

# ========== ÂÖ≥ÈîÆÊåáÊ†áÔºöÊ¨°Êó•„ÄÅ7Êó•„ÄÅ30Êó•ÁïôÂ≠ò ==========
if 1 in retention_rate.columns:
    day1_retention = retention_rate[1].mean()
    print(f"\\nÂπ≥ÂùáÊ¨°Êó•ÁïôÂ≠òÁéá: {day1_retention:.2f}%")

if 7 in retention_rate.columns:
    day7_retention = retention_rate[7].mean()
    print(f"Âπ≥Âùá7Êó•ÁïôÂ≠òÁéá: {day7_retention:.2f}%")

if 30 in retention_rate.columns:
    day30_retention = retention_rate[30].mean()
    print(f"Âπ≥Âùá30Êó•ÁïôÂ≠òÁéá: {day30_retention:.2f}%")

# ========== ÂèØËßÜÂåñÔºöÁïôÂ≠òÁÉ≠ÂäõÂõæ ==========
plt.figure(figsize=(14, 8))
sns.heatmap(
    retention_rate.iloc[:, :15],  # ÊòæÁ§∫Ââç15Â§©
    annot=True,
    fmt='.1f',
    cmap='YlGnBu',
    cbar_kws={'label': 'ÁïôÂ≠òÁéá(%)'}
)
plt.title('Áî®Êà∑ÁïôÂ≠òÁéáÁÉ≠ÂäõÂõæ', fontsize=16, fontweight='bold')
plt.xlabel('Ë∑ùÈ¶ñÊ¨°Ê¥ªË∑ÉÂ§©Êï∞')
plt.ylabel('Áî®Êà∑ÈòüÂàóÔºàÈ¶ñÊ¨°Ê¥ªË∑ÉÊó•ÊúüÔºâ')
plt.tight_layout()
plt.savefig('cohort_retention_heatmap.png', dpi=300)

# ========== ÂèØËßÜÂåñÔºöÁïôÂ≠òÊõ≤Á∫ø ==========
plt.figure(figsize=(14, 6))
for cohort in retention_rate.index[:5]:  # Â±ïÁ§∫Ââç5‰∏™ÈòüÂàó
    plt.plot(retention_rate.columns[:15], 
             retention_rate.loc[cohort, :15], 
             marker='o', 
             label=str(cohort))

plt.xlabel('Ë∑ùÈ¶ñÊ¨°Ê¥ªË∑ÉÂ§©Êï∞')
plt.ylabel('ÁïôÂ≠òÁéá(%)')
plt.title('Áî®Êà∑ÁïôÂ≠òÊõ≤Á∫øÂØπÊØî', fontsize=16, fontweight='bold')
plt.legend(title='Áî®Êà∑ÈòüÂàó')
plt.grid(alpha=0.3)
plt.tight_layout()
plt.savefig('retention_curves.png', dpi=300)

print("\\n‚úÖ ÁïôÂ≠òÂàÜÊûêÂÆåÊàê")`
        }
      ]
    },
    {
      id: 'project-case',
      title: 'PART 19 ÂÆåÊï¥È°πÁõÆÂÆûÊàò',
      subtitle: '‰ªéÊï∞ÊçÆËé∑ÂèñÂà∞Êä•ÂëäËæìÂá∫ ‚Äî‚Äî ÁîµÂïÜÁî®Êà∑Ë°å‰∏∫ÂàÜÊûêÂÆåÊï¥Ê°à‰æã',
      items: [
        {
          emoji: 'üéØ',
          title: 'È°πÁõÆËÉåÊôØ‰∏éÁõÆÊ†á',
          desc: 'ÊüêÁîµÂïÜÂπ≥Âè∞ÊÉ≥‰∫ÜËß£Áî®Êà∑Ë¥≠‰π∞Ë°å‰∏∫Ôºå‰ºòÂåñËøêËê•Á≠ñÁï•',
          detail: '**‰∏öÂä°ÁõÆÊ†á**ÔºöÊèêÂçáÁî®Êà∑ËΩ¨ÂåñÁéáÂíåÂ§çË¥≠Áéá\\n**Êï∞ÊçÆÊù•Ê∫ê**ÔºöÁî®Êà∑Ë°å‰∏∫Êó•Âøó„ÄÅËÆ¢ÂçïÊï∞ÊçÆ„ÄÅÁî®Êà∑‰ø°ÊÅØ\\n**ÂàÜÊûêÂë®Êúü**ÔºöÊúÄËøë3‰∏™ÊúàÊï∞ÊçÆ',
          code: `"""
È°πÁõÆÔºöÁîµÂïÜÁî®Êà∑Ë°å‰∏∫ÂàÜÊûê
‰∏öÂä°ÁõÆÊ†áÔºö
1. ‰∫ÜËß£Áî®Êà∑Ë¥≠‰π∞Ë∑ØÂæÑÂíåËΩ¨ÂåñÊºèÊñó
2. ËØÜÂà´È´ò‰ª∑ÂÄºÁî®Êà∑Áæ§‰ΩìÔºàRFMÊ®°ÂûãÔºâ
3. ÂàÜÊûêÁî®Êà∑ÁïôÂ≠òÂíåÊµÅÂ§±ÊÉÖÂÜµ
4. Êèê‰æõËøêËê•‰ºòÂåñÂª∫ËÆÆ

Êï∞ÊçÆÈõÜËØ¥ÊòéÔºö
- user_behavior.csv: Áî®Êà∑Ë°å‰∏∫Êó•ÂøóÔºàÊµèËßà„ÄÅÊî∂Ëóè„ÄÅÂä†Ë¥≠„ÄÅË¥≠‰π∞Ôºâ
- orders.csv: ËÆ¢ÂçïÊï∞ÊçÆ
- users.csv: Áî®Êà∑Âü∫Êú¨‰ø°ÊÅØ

ÂàÜÊûêÊ°ÜÊû∂Ôºö
1. Êï∞ÊçÆËé∑Âèñ‰∏éÊ∏ÖÊ¥ó
2. Êé¢Á¥¢ÊÄßÊï∞ÊçÆÂàÜÊûêÔºàEDAÔºâ
3. Áî®Êà∑Ë°å‰∏∫Ë∑ØÂæÑÂàÜÊûê
4. RFMÂÆ¢Êà∑‰ª∑ÂÄºÂàÜÊûê
5. ÁïôÂ≠òÂàÜÊûê
6. ÂèØËßÜÂåñDashboard
7. ÁªìËÆ∫‰∏éÂª∫ËÆÆ
"""`
        },
        {
          emoji: 'üì•',
          title: 'Êï∞ÊçÆËé∑Âèñ‰∏éÊ∏ÖÊ¥ó',
          desc: 'Âä†ËΩΩÊï∞ÊçÆ„ÄÅÂ§ÑÁêÜÁº∫Â§±ÂÄº„ÄÅÊï∞ÊçÆÁ±ªÂûãËΩ¨Êç¢',
          detail: '**ÈáçÁÇπ**ÔºöÊï∞ÊçÆË¥®ÈáèÊ£ÄÊü•„ÄÅÂºÇÂ∏∏ÂÄºÂ§ÑÁêÜ\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöÊó•ÊúüÊ†ºÂºè„ÄÅÈáçÂ§çÊï∞ÊçÆ\\n**ËæìÂá∫**ÔºöÂπ≤ÂáÄÁöÑÂèØÂàÜÊûêÊï∞ÊçÆÈõÜ',
          code: `import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

# 1. Âä†ËΩΩÊï∞ÊçÆ
behavior = pd.read_csv('user_behavior.csv')
orders = pd.read_csv('orders.csv')
users = pd.read_csv('users.csv')

# 2. Êï∞ÊçÆÊ¶ÇËßà
print("Ë°å‰∏∫Êï∞ÊçÆ:", behavior.shape)
print("ËÆ¢ÂçïÊï∞ÊçÆ:", orders.shape)
print("Áî®Êà∑Êï∞ÊçÆ:", users.shape)

behavior.info()
behavior.head()

# 3. Êï∞ÊçÆÊ∏ÖÊ¥ó
# 3.1 Â§ÑÁêÜÁº∫Â§±ÂÄº
print("Áº∫Â§±ÂÄºÁªüËÆ°:\\n", behavior.isnull().sum())
behavior = behavior.dropna(subset=['user_id', 'item_id'])

# 3.2 Êï∞ÊçÆÁ±ªÂûãËΩ¨Êç¢
behavior['timestamp'] = pd.to_datetime(behavior['timestamp'])
orders['order_date'] = pd.to_datetime(orders['order_date'])

# 3.3 Âà†Èô§ÈáçÂ§çÂÄº
behavior = behavior.drop_duplicates()
orders = orders.drop_duplicates(subset=['order_id'])

# 3.4 ÂºÇÂ∏∏ÂÄºÂ§ÑÁêÜ
# Âà†Èô§ÂºÇÂ∏∏ÈáëÈ¢ùËÆ¢Âçï
Q1 = orders['amount'].quantile(0.25)
Q3 = orders['amount'].quantile(0.75)
IQR = Q3 - Q1
orders = orders[(orders['amount'] >= Q1 - 1.5*IQR) & 
                (orders['amount'] <= Q3 + 1.5*IQR)]

# 3.5 Ê∑ªÂä†Êó∂Èó¥ÁâπÂæÅ
behavior['date'] = behavior['timestamp'].dt.date
behavior['hour'] = behavior['timestamp'].dt.hour
behavior['dayofweek'] = behavior['timestamp'].dt.dayofweek

# 4. Êï∞ÊçÆÂêàÂπ∂
df = pd.merge(behavior, users, on='user_id', how='left')

print("\\nÊ∏ÖÊ¥óÂêéÊï∞ÊçÆ:", df.shape)
print("Êï∞ÊçÆÊó∂Èó¥ËåÉÂõ¥:", df['timestamp'].min(), "Ëá≥", df['timestamp'].max())`
        },
        {
          emoji: 'üîç',
          title: 'Êé¢Á¥¢ÊÄßÊï∞ÊçÆÂàÜÊûêÔºàEDAÔºâ',
          desc: 'Áî®Êà∑Ë°å‰∏∫ÂàÜÂ∏É„ÄÅËΩ¨ÂåñÊºèÊñó„ÄÅÊó∂Èó¥Ë∂ãÂäø',
          detail: '**ÈáçÁÇπ**ÔºöÂèëÁé∞Êï∞ÊçÆËßÑÂæãÂíåÂºÇÂ∏∏\\n**ÂèØËßÜÂåñ**ÔºöÊü±Áä∂Âõæ„ÄÅÊäòÁ∫øÂõæ„ÄÅÊºèÊñóÂõæ\\n**ËæìÂá∫**ÔºöEDAÊä•ÂëäÂíåÂÖ≥ÈîÆÂèëÁé∞',
          code: `# 1. Áî®Êà∑Ë°å‰∏∫ÂàÜÂ∏É
behavior_dist = behavior['behavior_type'].value_counts()
print("Áî®Êà∑Ë°å‰∏∫ÂàÜÂ∏É:\\n", behavior_dist)

plt.figure(figsize=(10, 6))
behavior_dist.plot(kind='bar', color='#19bcc8')
plt.title('Áî®Êà∑Ë°å‰∏∫Á±ªÂûãÂàÜÂ∏É', fontsize=16)
plt.ylabel('Ê¨°Êï∞')
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig('behavior_distribution.png', dpi=300)

# 2. ËΩ¨ÂåñÊºèÊñóÂàÜÊûê
funnel = behavior.groupby('behavior_type')['user_id'].nunique()
funnel_ordered = funnel[['ÊµèËßà', 'Êî∂Ëóè', 'Âä†Ë¥≠', 'Ë¥≠‰π∞']]
conversion_rate = (funnel_ordered / funnel_ordered['ÊµèËßà'] * 100).round(2)

print("\\nËΩ¨ÂåñÊºèÊñó:")
print(funnel_ordered)
print("\\nËΩ¨ÂåñÁéá:")
print(conversion_rate)

# 3. Êó•Ê¥ªË∑ÉÁî®Êà∑Ë∂ãÂäø
daily_users = behavior.groupby('date')['user_id'].nunique()
plt.figure(figsize=(12, 6))
daily_users.plot(color='#19bcc8', linewidth=2)
plt.title('Êó•Ê¥ªË∑ÉÁî®Êà∑Ë∂ãÂäø', fontsize=16)
plt.ylabel('Ê¥ªË∑ÉÁî®Êà∑Êï∞')
plt.grid(alpha=0.3)
plt.tight_layout()
plt.savefig('daily_active_users.png', dpi=300)

# 4. Êó∂ÊÆµÂàÜÂ∏É
hourly_behavior = behavior.groupby('hour').size()
plt.figure(figsize=(12, 6))
hourly_behavior.plot(kind='bar', color='#19bcc8')
plt.title('Áî®Êà∑Ë°å‰∏∫Êó∂ÊÆµÂàÜÂ∏É', fontsize=16)
plt.xlabel('Â∞èÊó∂')
plt.ylabel('Ë°å‰∏∫Ê¨°Êï∞')
plt.tight_layout()
plt.savefig('hourly_distribution.png', dpi=300)

# 5. Ë¥≠‰π∞ÈáëÈ¢ùÂàÜÂ∏É
plt.figure(figsize=(10, 6))
orders['amount'].hist(bins=50, color='#19bcc8', alpha=0.7)
plt.title('ËÆ¢ÂçïÈáëÈ¢ùÂàÜÂ∏É', fontsize=16)
plt.xlabel('ÈáëÈ¢ùÔºàÂÖÉÔºâ')
plt.ylabel('ËÆ¢ÂçïÊï∞')
plt.tight_layout()
plt.savefig('amount_distribution.png', dpi=300)

# 6. ÂÖ≥ÈîÆÂèëÁé∞
print("\\nÂÖ≥ÈîÆÂèëÁé∞:")
print(f"1. ÊÄªÁî®Êà∑Êï∞: {behavior['user_id'].nunique():,}")
print(f"2. ÊÄªËÆ¢ÂçïÊï∞: {orders.shape[0]:,}")
print(f"3. Âπ≥ÂùáËÆ¢ÂçïÈáëÈ¢ù: ¬•{orders['amount'].mean():.2f}")
print(f"4. ÊµèËßàÂà∞Ë¥≠‰π∞ËΩ¨ÂåñÁéá: {conversion_rate['Ë¥≠‰π∞']:.2f}%")`
        },
        {
          emoji: 'üë•',
          title: 'RFMÂÆ¢Êà∑‰ª∑ÂÄºÂàÜÊûê',
          desc: 'ËØÜÂà´È´ò‰ª∑ÂÄºÁî®Êà∑ÔºåËøõË°åÁ≤æÂáÜËê•ÈîÄ',
          detail: '**RFMÊ®°Âûã**ÔºöRecencyÔºàÊúÄËøëË¥≠‰π∞Ôºâ„ÄÅFrequencyÔºàË¥≠‰π∞È¢ëÊ¨°Ôºâ„ÄÅMonetaryÔºàË¥≠‰π∞ÈáëÈ¢ùÔºâ\\n**ËæìÂá∫**ÔºöÂÆ¢Êà∑ÂàÜÁæ§ÁªìÊûú\\n**Â∫îÁî®**ÔºöÁ≤æÂáÜËê•ÈîÄ„ÄÅÂÆ¢Êà∑ÂÖ≥Á≥ªÁÆ°ÁêÜ',
          code: `# RFMÂàÜÊûê
analysis_date = orders['order_date'].max()

rfm = orders.groupby('user_id').agg({
    'order_date': lambda x: (analysis_date - x.max()).days,  # Recency
    'order_id': 'count',  # Frequency
    'amount': 'sum'  # Monetary
}).rename(columns={
    'order_date': 'Recency',
    'order_id': 'Frequency',
    'amount': 'Monetary'
})

# ËÆ°ÁÆóRFMÂàÜÊï∞Ôºà1-5ÂàÜÔºâ
rfm['R_Score'] = pd.qcut(rfm['Recency'], 5, labels=[5,4,3,2,1])
rfm['F_Score'] = pd.qcut(rfm['Frequency'].rank(method='first'), 5, labels=[1,2,3,4,5])
rfm['M_Score'] = pd.qcut(rfm['Monetary'].rank(method='first'), 5, labels=[1,2,3,4,5])

# RFMÊÄªÂàÜ
rfm['RFM_Score'] = rfm['R_Score'].astype(str) + rfm['F_Score'].astype(str) + rfm['M_Score'].astype(str)

# ÂÆ¢Êà∑ÂàÜÁæ§
def rfm_segment(row):
    if row['R_Score'] >= 4 and row['F_Score'] >= 4 and row['M_Score'] >= 4:
        return 'ÈáçË¶Å‰ª∑ÂÄºÂÆ¢Êà∑'
    elif row['R_Score'] >= 4 and row['F_Score'] < 4:
        return 'ÈáçË¶ÅÂèëÂ±ïÂÆ¢Êà∑'
    elif row['R_Score'] < 4 and row['F_Score'] >= 4:
        return 'ÈáçË¶Å‰øùÊåÅÂÆ¢Êà∑'
    elif row['R_Score'] >= 3:
        return '‰∏ÄËà¨ÂÆ¢Êà∑'
    else:
        return 'ÊµÅÂ§±È£éÈô©ÂÆ¢Êà∑'

rfm['ÂÆ¢Êà∑Áæ§‰Ωì'] = rfm.apply(rfm_segment, axis=1)

# ÂÆ¢Êà∑ÂàÜÁæ§ÁªüËÆ°
segment_summary = rfm.groupby('ÂÆ¢Êà∑Áæ§‰Ωì').agg({
    'Recency': 'mean',
    'Frequency': 'mean',
    'Monetary': 'sum'
}).round(2)

print("\\nRFMÂÆ¢Êà∑ÂàÜÁæ§ÁªìÊûú:")
print(rfm['ÂÆ¢Êà∑Áæ§‰Ωì'].value_counts())
print("\\nÂêÑÁæ§‰ΩìÁâπÂæÅ:")
print(segment_summary)

# ÂèØËßÜÂåñ
plt.figure(figsize=(10, 6))
rfm['ÂÆ¢Êà∑Áæ§‰Ωì'].value_counts().plot(kind='bar', color='#19bcc8')
plt.title('ÂÆ¢Êà∑Áæ§‰ΩìÂàÜÂ∏É', fontsize=16)
plt.ylabel('ÂÆ¢Êà∑Êï∞Èáè')
plt.xticks(rotation=45)
plt.tight_layout()
plt.savefig('rfm_segments.png', dpi=300)

# ÂØºÂá∫RFMÁªìÊûú
rfm.reset_index().to_excel('rfm_analysis.xlsx', index=False)`
        },
        {
          emoji: 'üìà',
          title: 'ÂèØËßÜÂåñDashboard',
          desc: 'Áî®PlotlyÂàõÂª∫‰∫§‰∫íÂºèÊï∞ÊçÆÁúãÊùø',
          detail: '**ÈáçÁÇπ**Ôºö‰∫§‰∫íÂºèÂõæË°®„ÄÅÂ§öÁª¥Â∫¶Â±ïÁ§∫\\n**Â∑•ÂÖ∑**ÔºöPlotly„ÄÅMatplotlib\\n**ËæìÂá∫**ÔºöHTMLÊ†ºÂºèDashboard',
          code: `import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.express as px

# 1. ÂàõÂª∫Â≠êÂõæÂ∏ÉÂ±ÄÔºà2x2Ôºâ
fig = make_subplots(
    rows=2, cols=2,
    subplot_titles=('Áî®Êà∑Ë°å‰∏∫ÊºèÊñó', 'Êó•Ê¥ªË∑ÉÁî®Êà∑Ë∂ãÂäø', 'RFMÂÆ¢Êà∑ÂàÜÁæ§', 'Êó∂ÊÆµË°å‰∏∫ÁÉ≠ÂäõÂõæ'),
    specs=[[{"type": "funnel"}, {"type": "scatter"}],
           [{"type": "bar"}, {"type": "heatmap"}]]
)

# 2. ËΩ¨ÂåñÊºèÊñóÂõæ
funnel_data = behavior.groupby('behavior_type')['user_id'].nunique()
fig.add_trace(
    go.Funnel(
        y=['ÊµèËßà', 'Êî∂Ëóè', 'Âä†Ë¥≠', 'Ë¥≠‰π∞'],
        x=[funnel_data.get('ÊµèËßà', 0), funnel_data.get('Êî∂Ëóè', 0), 
           funnel_data.get('Âä†Ë¥≠', 0), funnel_data.get('Ë¥≠‰π∞', 0)],
        textinfo="value+percent previous",
        marker=dict(color=['#19bcc8', '#17a8b4', '#1596a2', '#138490'])
    ),
    row=1, col=1
)

# 3. Êó•Ê¥ªË∑ÉË∂ãÂäøÂõæ
daily_users = behavior.groupby('date')['user_id'].nunique()
fig.add_trace(
    go.Scatter(
        x=daily_users.index,
        y=daily_users.values,
        mode='lines+markers',
        line=dict(color='#19bcc8', width=2),
        fill='tozeroy',
        fillcolor='rgba(25, 188, 200, 0.2)'
    ),
    row=1, col=2
)

# 4. RFMÂÆ¢Êà∑ÂàÜÁæ§Êü±Áä∂Âõæ
segment_counts = rfm['ÂÆ¢Êà∑Áæ§‰Ωì'].value_counts()
fig.add_trace(
    go.Bar(
        x=segment_counts.index,
        y=segment_counts.values,
        marker_color='#19bcc8',
        text=segment_counts.values,
        textposition='auto'
    ),
    row=2, col=1
)

# 5. Êó∂ÊÆµË°å‰∏∫ÁÉ≠ÂäõÂõæ
hourly_dow = behavior.groupby(['dayofweek', 'hour']).size().unstack(fill_value=0)
fig.add_trace(
    go.Heatmap(
        z=hourly_dow.values,
        x=list(range(24)),
        y=['Âë®‰∏Ä', 'Âë®‰∫å', 'Âë®‰∏â', 'Âë®Âõõ', 'Âë®‰∫î', 'Âë®ÂÖ≠', 'Âë®Êó•'],
        colorscale='Teal',
        showscale=True
    ),
    row=2, col=2
)

# Êõ¥Êñ∞Â∏ÉÂ±Ä
fig.update_layout(
    title_text="ÁîµÂïÜÁî®Êà∑Ë°å‰∏∫ÂàÜÊûê Dashboard",
    title_font_size=24,
    showlegend=False,
    height=900,
    width=1400
)

# ‰øùÂ≠ò‰∏∫HTML
fig.write_html('dashboard.html')
print("\\n‚úÖ ‰∫§‰∫íÂºèDashboardÂ∑≤ÁîüÊàê: dashboard.html")

# È¢ùÂ§ñÔºöÂçïÁã¨ÁöÑÈ´òÁ∫ßÂõæË°®
# 6. RFM 3DÊï£ÁÇπÂõæ
fig_3d = px.scatter_3d(
    rfm.reset_index(), 
    x='Recency', 
    y='Frequency', 
    z='Monetary',
    color='ÂÆ¢Êà∑Áæ§‰Ωì',
    size='Monetary',
    hover_data=['user_id'],
    title='RFM 3DÂÆ¢Êà∑ÂàÜÁæ§ÂèØËßÜÂåñ',
    color_discrete_sequence=px.colors.qualitative.Set2
)
fig_3d.write_html('rfm_3d.html')

print("‚úÖ RFM 3DÂèØËßÜÂåñÂ∑≤ÁîüÊàê: rfm_3d.html")`
        },
        {
          emoji: 'üìä',
          title: 'ÁîüÊàêÂàÜÊûêÊä•Âëä',
          desc: 'Êï¥ÂêàÊâÄÊúâÂàÜÊûêÁªìÊûúÔºåËæìÂá∫ExcelÊä•Âëä',
          detail: '**ËæìÂá∫**ÔºöÂåÖÂê´Â§ö‰∏™sheetÁöÑExcelÊä•Âëä\\n**ÂÜÖÂÆπ**ÔºöÊï∞ÊçÆÊ¶ÇËßà„ÄÅËΩ¨ÂåñÂàÜÊûê„ÄÅRFMÂàÜÁæ§„ÄÅËøêËê•Âª∫ËÆÆ\\n**Ê†ºÂºè**Ôºö‰∏ì‰∏ö„ÄÅÊòìËØª„ÄÅÂèØÊâßË°å',
          code: `# ÁîüÊàêÁªºÂêàÂàÜÊûêÊä•Âëä
with pd.ExcelWriter('ÁîµÂïÜÁî®Êà∑Ë°å‰∏∫ÂàÜÊûêÊä•Âëä.xlsx', engine='openpyxl') as writer:
    # Sheet1: Êï∞ÊçÆÊ¶ÇËßà
    summary = pd.DataFrame({
        'ÊåáÊ†á': ['ÊÄªÁî®Êà∑Êï∞', 'ÊÄªËÆ¢ÂçïÊï∞', 'ÊÄªGMV', 'Âπ≥ÂùáËÆ¢ÂçïÈáëÈ¢ù', 'ÊµèËßà-Ë¥≠‰π∞ËΩ¨ÂåñÁéá'],
        'Êï∞ÂÄº': [
            f"{behavior['user_id'].nunique():,}",
            f"{orders.shape[0]:,}",
            f"¬•{orders['amount'].sum():,.2f}",
            f"¬•{orders['amount'].mean():.2f}",
            f"{conversion_rate['Ë¥≠‰π∞']:.2f}%"
        ]
    })
    summary.to_excel(writer, sheet_name='Êï∞ÊçÆÊ¶ÇËßà', index=False)
    
    # Sheet2: Ë°å‰∏∫ÂàÜÂ∏É
    behavior_dist.to_excel(writer, sheet_name='Ë°å‰∏∫ÂàÜÂ∏É')
    
    # Sheet3: RFMÂàÜÁæ§
    rfm.reset_index().to_excel(writer, sheet_name='RFMÂàÜÊûê', index=False)
    
    # Sheet4: ÂÆ¢Êà∑ÂàÜÁæ§ÁªüËÆ°
    segment_summary.to_excel(writer, sheet_name='ÂÆ¢Êà∑ÂàÜÁæ§ÁªüËÆ°')
    
    # Sheet5: ËøêËê•Âª∫ËÆÆ
    suggestions = pd.DataFrame({
        'ÂÆ¢Êà∑Áæ§‰Ωì': ['ÈáçË¶Å‰ª∑ÂÄºÂÆ¢Êà∑', 'ÈáçË¶ÅÂèëÂ±ïÂÆ¢Êà∑', 'ÈáçË¶Å‰øùÊåÅÂÆ¢Êà∑', '‰∏ÄËà¨ÂÆ¢Êà∑', 'ÊµÅÂ§±È£éÈô©ÂÆ¢Êà∑'],
        'ËøêËê•Á≠ñÁï•': [
            'VIPÊúçÂä°„ÄÅ‰∏ìÂ±û‰ºòÊÉ†„ÄÅ‰ºòÂÖà‰ΩìÈ™åÊñ∞ÂìÅ',
            'Â¢ûÂä†‰∫íÂä®„ÄÅÊèêÂçáË¥≠‰π∞È¢ëÊ¨°„ÄÅ‰ºöÂëòÊùÉÁõäÂê∏Âºï',
            'Áª¥Êä§ÂÖ≥Á≥ª„ÄÅÂÆöÊúüÂÖ≥ÊÄÄ„ÄÅÈò≤Ê≠¢ÊµÅÂ§±',
            '‰øÉÈîÄÊ¥ªÂä®„ÄÅÊèêÂçáÂèÇ‰∏éÂ∫¶',
            'Âè¨ÂõûÊ¥ªÂä®„ÄÅÂ§ßÈ¢ù‰ºòÊÉ†Âà∏„ÄÅ‰∫ÜËß£ÊµÅÂ§±ÂéüÂõ†'
        ]
    })
    suggestions.to_excel(writer, sheet_name='ËøêËê•Âª∫ËÆÆ', index=False)

print("\\n‚úÖ ÂàÜÊûêÊä•ÂëäÂ∑≤ÁîüÊàê: ÁîµÂïÜÁî®Êà∑Ë°å‰∏∫ÂàÜÊûêÊä•Âëä.xlsx")
print("\\nüìä Êä•ÂëäÂåÖÂê´5‰∏™sheet:")
print("   1. Êï∞ÊçÆÊ¶ÇËßà")
print("   2. Ë°å‰∏∫ÂàÜÂ∏É")
print("   3. RFMÂàÜÊûê")
print("   4. ÂÆ¢Êà∑ÂàÜÁæ§ÁªüËÆ°")
print("   5. ËøêËê•Âª∫ËÆÆ")

# È°πÁõÆÊÄªÁªì
print("\\n" + "="*50)
print("È°πÁõÆÂÆåÊàêÊÄªÁªì")
print("="*50)
print("‚úì Êï∞ÊçÆÊ∏ÖÊ¥óÂÆåÊàê")
print("‚úì Êé¢Á¥¢ÊÄßÂàÜÊûêÂÆåÊàê")
print("‚úì RFMÂÆ¢Êà∑ÂàÜÁæ§ÂÆåÊàê")
print("‚úì ÂèØËßÜÂåñÂõæË°®ÁîüÊàêÂÆåÊàê")
print("‚úì ExcelÊä•ÂëäÂØºÂá∫ÂÆåÊàê")
print("\\n‰∏ã‰∏ÄÊ≠•ÔºöÂ∞ÜÂàÜÊûêÁªìÊûúÂ∫îÁî®Âà∞ÂÆûÈôÖËøêËê•‰∏≠ÔºÅ")`
        }
      ]
    },
    {
      id: 'project-sales',
      title: 'PART 17 ÈîÄÂîÆÈ¢ùÈ¢ÑÊµãÂÆûÊàò',
      subtitle: 'Êó∂Èó¥Â∫èÂàóÈ¢ÑÊµã ‚Äî‚Äî Áî®PythonÈ¢ÑÊµãÊú™Êù•ÈîÄÂîÆË∂ãÂäø',
      items: [
        {
          emoji: 'üìã',
          title: 'È°πÁõÆËÉåÊôØ‰∏éÊï∞ÊçÆÂáÜÂ§á',
          desc: 'ÊüêÈõ∂ÂîÆ‰ºÅ‰∏öÈúÄË¶ÅÈ¢ÑÊµãÊú™Êù•3‰∏™ÊúàÁöÑÈîÄÂîÆÈ¢ùÔºå‰ºòÂåñÂ∫ìÂ≠òÂíåËê•ÈîÄËÆ°Âàí',
          detail: '**‰∏öÂä°ÁõÆÊ†á**ÔºöÈ¢ÑÊµãÊú™Êù•ÈîÄÂîÆÈ¢ùÔºåÈôç‰ΩéÂ∫ìÂ≠òÊàêÊú¨\\n**Êï∞ÊçÆ**ÔºöÂéÜÂè≤ÈîÄÂîÆÊï∞ÊçÆÔºà2Âπ¥Ôºâ\\n**ÊñπÊ≥ï**ÔºöARIMA„ÄÅProphet„ÄÅXGBoost',
          code: `"""
È°πÁõÆÔºöÈîÄÂîÆÈ¢ùÈ¢ÑÊµã
‰∏öÂä°Âú∫ÊôØÔºöÈõ∂ÂîÆ‰ºÅ‰∏öÊúàÂ∫¶ÈîÄÂîÆÈ¢ÑÊµã
Êï∞ÊçÆÔºö2022-01 Ëá≥ 2024-12 ÁöÑÊúàÂ∫¶ÈîÄÂîÆÊï∞ÊçÆ
ÁõÆÊ†áÔºöÈ¢ÑÊµã2025Âπ¥1-3ÊúàÈîÄÂîÆÈ¢ù

ÊäÄÊúØÊ†àÔºö
- PandasÔºöÊï∞ÊçÆÂ§ÑÁêÜ
- StatsmodelsÔºöARIMAÊ®°Âûã
- ProphetÔºöFacebookÊó∂Èó¥Â∫èÂàóÈ¢ÑÊµã
- XGBoostÔºöÊú∫Âô®Â≠¶‰π†È¢ÑÊµã
- Matplotlib/PlotlyÔºöÂèØËßÜÂåñ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# 1. Âä†ËΩΩÊï∞ÊçÆ
df = pd.read_csv('sales_data.csv', parse_dates=['date'])
df = df.sort_values('date').reset_index(drop=True)

print("Êï∞ÊçÆÂΩ¢Áä∂:", df.shape)
print("\\nÊï∞ÊçÆÈ¢ÑËßà:")
print(df.head())
print("\\nÊï∞ÊçÆÁªüËÆ°:")
print(df.describe())

# 2. ÂèØËßÜÂåñÂéÜÂè≤Ë∂ãÂäø
plt.figure(figsize=(14, 6))
plt.plot(df['date'], df['sales'], marker='o', linewidth=2, color='#19bcc8')
plt.title('ÂéÜÂè≤ÈîÄÂîÆÈ¢ùË∂ãÂäøÔºà2022-2024Ôºâ', fontsize=16, fontweight='bold')
plt.xlabel('Êó•Êúü')
plt.ylabel('ÈîÄÂîÆÈ¢ùÔºà‰∏áÂÖÉÔºâ')
plt.grid(alpha=0.3)
plt.tight_layout()
plt.savefig('sales_trend.png', dpi=300)
plt.show()

# 3. Êï∞ÊçÆÂàÜËß£ÔºàË∂ãÂäø„ÄÅÂ≠£ËäÇÊÄß„ÄÅÊÆãÂ∑ÆÔºâ
from statsmodels.tsa.seasonal import seasonal_decompose

decomposition = seasonal_decompose(df.set_index('date')['sales'], 
                                   model='multiplicative', period=12)

fig, axes = plt.subplots(4, 1, figsize=(14, 10))
df.set_index('date')['sales'].plot(ax=axes[0], color='#19bcc8')
axes[0].set_title('ÂéüÂßãÊï∞ÊçÆ')
decomposition.trend.plot(ax=axes[1], color='#17a8b4')
axes[1].set_title('Ë∂ãÂäø')
decomposition.seasonal.plot(ax=axes[2], color='#1596a2')
axes[2].set_title('Â≠£ËäÇÊÄß')
decomposition.resid.plot(ax=axes[3], color='#138490')
axes[3].set_title('ÊÆãÂ∑Æ')
plt.tight_layout()
plt.savefig('decomposition.png', dpi=300)

print("\\n‚úÖ Êï∞ÊçÆÊé¢Á¥¢ÂÆåÊàê")`
        },
        {
          emoji: 'üìà',
          title: 'ÊñπÊ≥ï1ÔºöARIMAÊ®°Âûã',
          desc: 'ÁªèÂÖ∏Êó∂Èó¥Â∫èÂàóÈ¢ÑÊµãÊ®°Âûã',
          detail: '**‰ºòÁÇπ**ÔºöÁªüËÆ°Â≠¶ÂéüÁêÜÔºåÂèØËß£ÈáäÊÄßÂº∫\\n**ÈÄÇÁî®**ÔºöÊúâÊòéÊòæË∂ãÂäøÂíåÂ≠£ËäÇÊÄßÁöÑÊï∞ÊçÆ\\n**ÂèÇÊï∞**ÔºöpÔºàËá™ÂõûÂΩíÔºâ„ÄÅdÔºàÂ∑ÆÂàÜÔºâ„ÄÅqÔºàÁßªÂä®Âπ≥ÂùáÔºâ',
          code: `from statsmodels.tsa.arima.model import ARIMA
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from sklearn.metrics import mean_absolute_error, mean_squared_error

# 1. ÂàíÂàÜËÆ≠ÁªÉÈõÜÂíåÊµãËØïÈõÜ
train_size = int(len(df) * 0.8)
train = df[:train_size]
test = df[train_size:]

print(f"ËÆ≠ÁªÉÈõÜ: {train.shape[0]} ‰∏™Êúà")
print(f"ÊµãËØïÈõÜ: {test.shape[0]} ‰∏™Êúà")

# 2. Á°ÆÂÆöARIMAÂèÇÊï∞Ôºàp, d, qÔºâ
# ÊñπÊ≥ï1ÔºöËá™Âä®ÊêúÁ¥¢ÊúÄ‰ºòÂèÇÊï∞
import itertools

p = d = q = range(0, 3)
pdq = list(itertools.product(p, d, q))
seasonal_pdq = [(x[0], x[1], x[2], 12) for x in pdq]

best_aic = np.inf
best_params = None

for param in pdq:
    for param_seasonal in seasonal_pdq:
        try:
            model = ARIMA(train['sales'], order=param, 
                         seasonal_order=param_seasonal)
            results = model.fit()
            if results.aic < best_aic:
                best_aic = results.aic
                best_params = (param, param_seasonal)
        except:
            continue

print(f"\\nÊúÄ‰ºòÂèÇÊï∞: {best_params}")
print(f"ÊúÄ‰ºòAIC: {best_aic:.2f}")

# 3. ËÆ≠ÁªÉÊúÄ‰ºòÊ®°Âûã
model = ARIMA(train['sales'], 
              order=best_params[0], 
              seasonal_order=best_params[1])
fitted_model = model.fit()

print("\\nÊ®°ÂûãÊëòË¶Å:")
print(fitted_model.summary())

# 4. È¢ÑÊµã
forecast_steps = len(test)
forecast = fitted_model.forecast(steps=forecast_steps)

# 5. ËØÑ‰º∞
mae = mean_absolute_error(test['sales'], forecast)
rmse = np.sqrt(mean_squared_error(test['sales'], forecast))
mape = np.mean(np.abs((test['sales'] - forecast) / test['sales'])) * 100

print(f"\\nARIMAÊ®°ÂûãËØÑ‰º∞:")
print(f"MAE: {mae:.2f}")
print(f"RMSE: {rmse:.2f}")
print(f"MAPE: {mape:.2f}%")

# 6. ÂèØËßÜÂåñÈ¢ÑÊµãÁªìÊûú
plt.figure(figsize=(14, 6))
plt.plot(train['date'], train['sales'], label='ËÆ≠ÁªÉÊï∞ÊçÆ', color='#19bcc8')
plt.plot(test['date'], test['sales'], label='ÁúüÂÆûÂÄº', color='#17a8b4', marker='o')
plt.plot(test['date'], forecast, label='ARIMAÈ¢ÑÊµã', color='#ff6b6b', marker='s')
plt.title('ARIMAÈîÄÂîÆÈ¢ùÈ¢ÑÊµã', fontsize=16, fontweight='bold')
plt.xlabel('Êó•Êúü')
plt.ylabel('ÈîÄÂîÆÈ¢ùÔºà‰∏áÂÖÉÔºâ')
plt.legend()
plt.grid(alpha=0.3)
plt.tight_layout()
plt.savefig('arima_forecast.png', dpi=300)

# 7. È¢ÑÊµãÊú™Êù•3‰∏™Êúà
future_forecast = fitted_model.forecast(steps=3)
print("\\nÊú™Êù•3‰∏™ÊúàÈ¢ÑÊµãÔºàARIMAÔºâ:")
for i, value in enumerate(future_forecast, 1):
    print(f"2025-{i:02d}: {value:.2f} ‰∏áÂÖÉ")`
        },
        {
          emoji: 'üîÆ',
          title: 'ÊñπÊ≥ï2ÔºöProphetÊ®°Âûã',
          desc: 'FacebookÂºÄÊ∫êÁöÑÊó∂Èó¥Â∫èÂàóÈ¢ÑÊµãÂ∑•ÂÖ∑',
          detail: '**‰ºòÁÇπ**ÔºöËá™Âä®Â§ÑÁêÜËäÇÂÅáÊó•„ÄÅË∂ãÂäøÂèòÂåñ„ÄÅÂºÇÂ∏∏ÂÄº\\n**ÈÄÇÁî®**Ôºö‰∏öÂä°Êï∞ÊçÆÔºåÊúâËäÇÂÅáÊó•ÊïàÂ∫î\\n**ÁâπÁÇπ**ÔºöÁÆÄÂçïÊòìÁî®ÔºåÊó†ÈúÄË∞ÉÂèÇ',
          code: `# ÂÆâË£Ö: pip install prophet
from prophet import Prophet

# 1. ÂáÜÂ§áProphetÊ†ºÂºèÊï∞ÊçÆ
prophet_df = df[['date', 'sales']].copy()
prophet_df.columns = ['ds', 'y']

# ÂàíÂàÜËÆ≠ÁªÉÈõÜÂíåÊµãËØïÈõÜ
prophet_train = prophet_df[:train_size]
prophet_test = prophet_df[train_size:]

# 2. ËÆ≠ÁªÉÊ®°Âûã
model = Prophet(
    yearly_seasonality=True,
    weekly_seasonality=False,
    daily_seasonality=False,
    seasonality_mode='multiplicative'
)

# Ê∑ªÂä†‰∏≠ÂõΩËäÇÂÅáÊó•ÔºàÂèØÈÄâÔºâ
model.add_country_holidays(country_name='CN')

model.fit(prophet_train)

# 3. È¢ÑÊµã
future = model.make_future_dataframe(periods=len(prophet_test), freq='MS')
forecast = model.predict(future)

# 4. ËØÑ‰º∞
prophet_pred = forecast.iloc[train_size:]['yhat'].values
mae_prophet = mean_absolute_error(prophet_test['y'], prophet_pred)
rmse_prophet = np.sqrt(mean_squared_error(prophet_test['y'], prophet_pred))
mape_prophet = np.mean(np.abs((prophet_test['y'] - prophet_pred) / prophet_test['y'])) * 100

print(f"ProphetÊ®°ÂûãËØÑ‰º∞:")
print(f"MAE: {mae_prophet:.2f}")
print(f"RMSE: {rmse_prophet:.2f}")
print(f"MAPE: {mape_prophet:.2f}%")

# 5. ÂèØËßÜÂåñ
fig1 = model.plot(forecast)
plt.title('ProphetÈîÄÂîÆÈ¢ùÈ¢ÑÊµã', fontsize=16, fontweight='bold')
plt.tight_layout()
plt.savefig('prophet_forecast.png', dpi=300)

# 6. ÁªÑ‰ª∂ÂàÜËß£
fig2 = model.plot_components(forecast)
plt.tight_layout()
plt.savefig('prophet_components.png', dpi=300)

# 7. È¢ÑÊµãÊú™Êù•3‰∏™Êúà
future_periods = model.make_future_dataframe(periods=len(prophet_test)+3, freq='MS')
future_forecast = model.predict(future_periods)
future_3_months = future_forecast.tail(3)[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]

print("\\nÊú™Êù•3‰∏™ÊúàÈ¢ÑÊµãÔºàProphetÔºâ:")
for idx, row in future_3_months.iterrows():
    print(f"{row['ds'].strftime('%Y-%m')}: {row['yhat']:.2f} ‰∏áÂÖÉ "
          f"(Âå∫Èó¥: {row['yhat_lower']:.2f} - {row['yhat_upper']:.2f})")`
        },
        {
          emoji: 'ü§ñ',
          title: 'ÊñπÊ≥ï3ÔºöXGBoostÊú∫Âô®Â≠¶‰π†',
          desc: 'Â∞ÜÊó∂Èó¥Â∫èÂàóËΩ¨Êç¢‰∏∫ÁõëÁù£Â≠¶‰π†ÈóÆÈ¢ò',
          detail: '**‰ºòÁÇπ**ÔºöÂèØÂä†ÂÖ•Â§ñÈÉ®ÁâπÂæÅÔºà‰øÉÈîÄ„ÄÅËäÇÂÅáÊó•Á≠âÔºâ\\n**ÈÄÇÁî®**ÔºöÊúâÂ§öÁßçÂΩ±ÂìçÂõ†Á¥†ÁöÑ‰∏öÂä°Âú∫ÊôØ\\n**ÁâπÁÇπ**ÔºöÈ´òÁ≤æÂ∫¶ÔºåÂèØÂ§ÑÁêÜÈùûÁ∫øÊÄßÂÖ≥Á≥ª',
          code: `import xgboost as xgb
from sklearn.metrics import mean_absolute_error, mean_squared_error

# 1. ÁâπÂæÅÂ∑•Á®ã
def create_features(df):
    df = df.copy()
    df['year'] = df['date'].dt.year
    df['month'] = df['date'].dt.month
    df['quarter'] = df['date'].dt.quarter
    df['dayofyear'] = df['date'].dt.dayofyear
    
    # ÊªûÂêéÁâπÂæÅÔºà‰∏ä‰∏™Êúà„ÄÅ‰∏ä2‰∏™Êúà„ÄÅÂéªÂπ¥ÂêåÊúüÔºâ
    df['lag_1'] = df['sales'].shift(1)
    df['lag_2'] = df['sales'].shift(2)
    df['lag_12'] = df['sales'].shift(12)
    
    # ÊªöÂä®ÁªüËÆ°ÁâπÂæÅ
    df['rolling_mean_3'] = df['sales'].shift(1).rolling(window=3).mean()
    df['rolling_std_3'] = df['sales'].shift(1).rolling(window=3).std()
    df['rolling_mean_6'] = df['sales'].shift(1).rolling(window=6).mean()
    
    return df

df_features = create_features(df)
df_features = df_features.dropna()

# 2. ÂàíÂàÜÊï∞ÊçÆÈõÜ
feature_cols = ['year', 'month', 'quarter', 'dayofyear', 
                'lag_1', 'lag_2', 'lag_12', 
                'rolling_mean_3', 'rolling_std_3', 'rolling_mean_6']

train_size = int(len(df_features) * 0.8)
X_train = df_features[:train_size][feature_cols]
y_train = df_features[:train_size]['sales']
X_test = df_features[train_size:][feature_cols]
y_test = df_features[train_size:]['sales']

# 3. ËÆ≠ÁªÉXGBoostÊ®°Âûã
model = xgb.XGBRegressor(
    n_estimators=1000,
    learning_rate=0.01,
    max_depth=5,
    min_child_weight=1,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42
)

model.fit(X_train, y_train, 
          eval_set=[(X_test, y_test)],
          early_stopping_rounds=50,
          verbose=False)

# 4. È¢ÑÊµãÂíåËØÑ‰º∞
y_pred = model.predict(X_test)

mae_xgb = mean_absolute_error(y_test, y_pred)
rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred))
mape_xgb = np.mean(np.abs((y_test - y_pred) / y_test)) * 100

print(f"XGBoostÊ®°ÂûãËØÑ‰º∞:")
print(f"MAE: {mae_xgb:.2f}")
print(f"RMSE: {rmse_xgb:.2f}")
print(f"MAPE: {mape_xgb:.2f}%")

# 5. ÁâπÂæÅÈáçË¶ÅÊÄß
import matplotlib.pyplot as plt
xgb.plot_importance(model, max_num_features=10)
plt.title('ÁâπÂæÅÈáçË¶ÅÊÄß', fontsize=14, fontweight='bold')
plt.tight_layout()
plt.savefig('feature_importance.png', dpi=300)

# 6. ÂèØËßÜÂåñÁªìÊûú
plt.figure(figsize=(14, 6))
plt.plot(df_features[train_size:]['date'], y_test, 
         label='ÁúüÂÆûÂÄº', color='#19bcc8', marker='o')
plt.plot(df_features[train_size:]['date'], y_pred, 
         label='XGBoostÈ¢ÑÊµã', color='#ff6b6b', marker='s')
plt.title('XGBoostÈîÄÂîÆÈ¢ùÈ¢ÑÊµã', fontsize=16, fontweight='bold')
plt.xlabel('Êó•Êúü')
plt.ylabel('ÈîÄÂîÆÈ¢ùÔºà‰∏áÂÖÉÔºâ')
plt.legend()
plt.grid(alpha=0.3)
plt.tight_layout()
plt.savefig('xgboost_forecast.png', dpi=300)

print("\\n‚úÖ ‰∏âÁßçÊ®°ÂûãÂØπÊØî:")
print(f"ARIMA  - MAPE: {mape:.2f}%")
print(f"Prophet - MAPE: {mape_prophet:.2f}%")
print(f"XGBoost - MAPE: {mape_xgb:.2f}%")`
        },
        {
          emoji: 'üìä',
          title: 'Ê®°ÂûãÂØπÊØî‰∏é‰∏öÂä°Âª∫ËÆÆ',
          desc: 'ÁªºÂêàÂØπÊØî‰∏âÁßçÊñπÊ≥ïÔºåËæìÂá∫ÊúÄÁªàÈ¢ÑÊµãÊä•Âëä',
          detail: '**ËæìÂá∫**ÔºöExcelÊä•Âëä + ÂèØËßÜÂåñDashboard\\n**Âª∫ËÆÆ**ÔºöÊ†πÊçÆMAPEÈÄâÊã©ÊúÄ‰ºòÊ®°Âûã\\n**Â∫îÁî®**ÔºöÂ∫ìÂ≠òËÆ°Âàí„ÄÅËê•ÈîÄÈ¢ÑÁÆóÂàÜÈÖç',
          code: `# 1. Ê®°ÂûãÂØπÊØîÊ±áÊÄª
comparison = pd.DataFrame({
    'Ê®°Âûã': ['ARIMA', 'Prophet', 'XGBoost'],
    'MAE': [mae, mae_prophet, mae_xgb],
    'RMSE': [rmse, rmse_prophet, rmse_xgb],
    'MAPE(%)': [mape, mape_prophet, mape_xgb],
    '‰ºòÁÇπ': [
        'ÁªüËÆ°Â≠¶ÂéüÁêÜÔºåÂèØËß£ÈáäÊÄßÂº∫',
        'Ëá™Âä®Â§ÑÁêÜËäÇÂÅáÊó•ÂíåÂºÇÂ∏∏ÂÄº',
        'ÂèØËûçÂêàÂ§öÁßçÁâπÂæÅÔºåÁ≤æÂ∫¶È´ò'
    ],
    'Áº∫ÁÇπ': [
        'ÈúÄË¶ÅË∞ÉÂèÇÔºåÂØπÂºÇÂ∏∏ÂÄºÊïèÊÑü',
        'ÈúÄË¶ÅËæÉÈïøÂéÜÂè≤Êï∞ÊçÆ',
        'ÈªëÁõíÊ®°ÂûãÔºåÂèØËß£ÈáäÊÄßÂº±'
    ]
})

print("\\nÊ®°ÂûãÁªºÂêàÂØπÊØî:")
print(comparison.to_string(index=False))

# 2. ÈÄâÊã©ÊúÄ‰ºòÊ®°Âûã
best_model_idx = comparison['MAPE(%)'].idxmin()
best_model_name = comparison.loc[best_model_idx, 'Ê®°Âûã']
print(f"\\nüèÜ ÊúÄ‰ºòÊ®°Âûã: {best_model_name} (MAPE: {comparison.loc[best_model_idx, 'MAPE(%)']:.2f}%)")

# 3. ÁîüÊàêÈ¢ÑÊµãÊä•Âëä
with pd.ExcelWriter('ÈîÄÂîÆÈ¢ùÈ¢ÑÊµãÊä•Âëä.xlsx', engine='openpyxl') as writer:
    # Sheet1: Ê®°ÂûãÂØπÊØî
    comparison.to_excel(writer, sheet_name='Ê®°ÂûãÂØπÊØî', index=False)
    
    # Sheet2: ÂéÜÂè≤Êï∞ÊçÆ
    df.to_excel(writer, sheet_name='ÂéÜÂè≤Êï∞ÊçÆ', index=False)
    
    # Sheet3: Êú™Êù•È¢ÑÊµãÔºà‰ΩøÁî®ÊúÄ‰ºòÊ®°ÂûãÁöÑÁªìÊûúÔºâ
    # ËøôÈáåÂÅáËÆæ‰ΩøÁî®ProphetÁöÑÁªìÊûú
    future_3_months.to_excel(writer, sheet_name='Êú™Êù•È¢ÑÊµã', index=False)
    
    # Sheet4: ‰∏öÂä°Âª∫ËÆÆ
    suggestions = pd.DataFrame({
        'Êúà‰ªΩ': ['2025-01', '2025-02', '2025-03'],
        'È¢ÑÊµãÈîÄÂîÆÈ¢ù': future_3_months['yhat'].values,
        'Âª∫ËÆÆÂ∫ìÂ≠ò': future_3_months['yhat'].values * 1.2,  # È¢ÑÁïô20%ÁºìÂÜ≤
        'Ëê•ÈîÄÈ¢ÑÁÆó': future_3_months['yhat'].values * 0.15,  # 15%Áî®‰∫éËê•ÈîÄ
        'Â§áÊ≥®': [
            'Êò•ËäÇÊúàÔºåÂä†Â§ß‰øÉÈîÄÂäõÂ∫¶',
            'Ê∑°Â≠£ÔºåÊéßÂà∂Â∫ìÂ≠ò',
            'ÂºÄÂßãÂ§áË¥ßQ2Êó∫Â≠£'
        ]
    })
    suggestions.to_excel(writer, sheet_name='‰∏öÂä°Âª∫ËÆÆ', index=False)

print("\\n‚úÖ È¢ÑÊµãÊä•ÂëäÂ∑≤ÁîüÊàê: ÈîÄÂîÆÈ¢ùÈ¢ÑÊµãÊä•Âëä.xlsx")

# 4. ÂàõÂª∫ÂèØËßÜÂåñDashboard
import plotly.graph_objects as go
from plotly.subplots import make_subplots

fig = make_subplots(
    rows=2, cols=2,
    subplot_titles=('ÂéÜÂè≤Ë∂ãÂäø‰∏éÈ¢ÑÊµã', 'Ê®°ÂûãÂØπÊØî', 'Â≠£ËäÇÊÄßÂàÜËß£', 'ÁΩÆ‰ø°Âå∫Èó¥'),
    specs=[[{"colspan": 2}, None],
           [{"type": "bar"}, {"type": "scatter"}]]
)

# Â≠êÂõæ1: ÂéÜÂè≤Ë∂ãÂäø‰∏éÈ¢ÑÊµã
fig.add_trace(go.Scatter(x=df['date'], y=df['sales'], 
                         mode='lines', name='ÂéÜÂè≤Êï∞ÊçÆ',
                         line=dict(color='#19bcc8', width=2)),
              row=1, col=1)

# Â≠êÂõæ2: Ê®°ÂûãÂØπÊØî
fig.add_trace(go.Bar(x=comparison['Ê®°Âûã'], y=comparison['MAPE(%)'],
                     marker_color='#19bcc8', name='MAPE'),
              row=2, col=1)

fig.update_layout(height=800, showlegend=True, 
                  title_text="ÈîÄÂîÆÈ¢ùÈ¢ÑÊµãÂàÜÊûêDashboard")
fig.write_html('sales_forecast_dashboard.html')

print("‚úÖ DashboardÂ∑≤ÁîüÊàê: sales_forecast_dashboard.html")
print("\\n" + "="*60)
print("È°πÁõÆÂÆåÊàêÔºÅÂèØÁî®‰∫é:")
print("  1. Â∫ìÂ≠òËÆ°Âàí‰ºòÂåñ")
print("  2. Ëê•ÈîÄÈ¢ÑÁÆóÂàÜÈÖç")
print("  3. ‰æõÂ∫îÈìæÁÆ°ÁêÜ")
print("  4. Ë¥¢Âä°È¢ÑÁÆóÁºñÂà∂")
print("="*60)`
        }
      ]
    },
    {
      id: 'project-churn',
      title: 'PART 18 Áî®Êà∑ÊµÅÂ§±È¢ÑË≠¶ÂÆûÊàò',
      subtitle: 'Êú∫Âô®Â≠¶‰π†ÂàÜÁ±ª ‚Äî‚Äî ÊèêÂâçËØÜÂà´ÊµÅÂ§±Áî®Êà∑Âπ∂ÊåΩÂõû',
      items: [
        {
          emoji: 'üéØ',
          title: 'È°πÁõÆËÉåÊôØ‰∏éÊï∞ÊçÆÁêÜËß£',
          desc: 'Áîµ‰ø°ÂÖ¨Âè∏ÊÉ≥ÊèêÂâçËØÜÂà´ÂèØËÉΩÊµÅÂ§±ÁöÑÁî®Êà∑ÔºåËøõË°åÁ≤æÂáÜÊåΩÁïô',
          detail: '**‰∏öÂä°‰ª∑ÂÄº**ÔºöÊåΩÁïô‰∏Ä‰∏™ËÄÅÂÆ¢Êà∑ÁöÑÊàêÊú¨ < Ëé∑Âèñ‰∏Ä‰∏™Êñ∞ÂÆ¢Êà∑\\n**Êï∞ÊçÆ**ÔºöÁî®Êà∑Â±ûÊÄß„ÄÅ‰ΩøÁî®Ë°å‰∏∫„ÄÅÊ∂àË¥πËÆ∞ÂΩï\\n**ÁõÆÊ†á**ÔºöÈ¢ÑÊµãÊú™Êù•1‰∏™ÊúàÂÜÖÊµÅÂ§±Ê¶ÇÁéá',
          code: `"""
È°πÁõÆÔºöÁî®Êà∑ÊµÅÂ§±È¢ÑË≠¶Á≥ªÁªü
‰∏öÂä°Âú∫ÊôØÔºöÁîµ‰ø°Ë°å‰∏öÂÆ¢Êà∑ÊµÅÂ§±È¢ÑÊµã
Êï∞ÊçÆÔºö7000+Áî®Êà∑ÁöÑ20+‰∏™ÁâπÂæÅ
ÁõÆÊ†áÔºöÈ¢ÑÊµãÊµÅÂ§±Ê¶ÇÁéáÔºåÂÆûÁé∞Á≤æÂáÜÊåΩÁïô

Êï∞ÊçÆÂ≠óÊÆµÔºö
- Áî®Êà∑Â±ûÊÄßÔºöÊÄßÂà´„ÄÅÂπ¥ÈæÑ„ÄÅÊòØÂê¶ËÄÅÂπ¥‰∫∫„ÄÅÊòØÂê¶ÊúâÈÖçÂÅ∂„ÄÅÊòØÂê¶ÊúâÂÆ∂Â±û
- Ë¥¶Êà∑‰ø°ÊÅØÔºöÂêàÁ∫¶Á±ªÂûã„ÄÅ‰ªòÊ¨æÊñπÂºè„ÄÅÊòØÂê¶Êó†Á∫∏ÂåñË¥¶Âçï„ÄÅÊúàË¥π„ÄÅÊÄªË¥πÁî®
- ÊúçÂä°‰ΩøÁî®ÔºöÊòØÂê¶‰ΩøÁî®ÁîµËØù„ÄÅÂ§öÁ∫øË∑Ø„ÄÅÁΩëÁªú„ÄÅÂú®Á∫øÂÆâÂÖ®„ÄÅÂú®Á∫øÂ§á‰ªΩ„ÄÅËÆæÂ§á‰øùÊä§„ÄÅÊäÄÊúØÊîØÊåÅ„ÄÅÊµÅÂ™í‰ΩìÁîµËßÜ„ÄÅÊµÅÂ™í‰ΩìÁîµÂΩ±
- Ê†áÁ≠æÔºöChurnÔºà0=Êú™ÊµÅÂ§±Ôºå1=Â∑≤ÊµÅÂ§±Ôºâ

ÊäÄÊúØÊ†àÔºö
- Pandas/NumPyÔºöÊï∞ÊçÆÂ§ÑÁêÜ
- Scikit-learnÔºöÊú∫Âô®Â≠¶‰π†
- XGBoost/LightGBMÔºöÈõÜÊàêÂ≠¶‰π†
- SHAPÔºöÊ®°ÂûãËß£Èáä
- Imbalanced-learnÔºöÂ§ÑÁêÜÊ†∑Êú¨‰∏çÂπ≥Ë°°
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
import warnings
warnings.filterwarnings('ignore')

# 1. Âä†ËΩΩÊï∞ÊçÆ
df = pd.read_csv('telecom_churn.csv')

print("Êï∞ÊçÆÂΩ¢Áä∂:", df.shape)
print("\\nÊï∞ÊçÆÈ¢ÑËßà:")
print(df.head())
print("\\nÊï∞ÊçÆ‰ø°ÊÅØ:")
print(df.info())

# 2. Êü•ÁúãÊµÅÂ§±Áéá
churn_rate = df['Churn'].value_counts(normalize=True)
print("\\nÊµÅÂ§±Áéá:")
print(churn_rate)
print(f"\\nÊµÅÂ§±Áî®Êà∑ÊØî‰æã: {churn_rate[1]*100:.2f}%")

# 3. ÂèØËßÜÂåñÊµÅÂ§±ÂàÜÂ∏É
fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# ÊµÅÂ§±Áî®Êà∑Êï∞Èáè
df['Churn'].value_counts().plot(kind='bar', ax=axes[0], color=['#19bcc8', '#ff6b6b'])
axes[0].set_title('ÊµÅÂ§±Áî®Êà∑ÂàÜÂ∏É', fontsize=14, fontweight='bold')
axes[0].set_xticklabels(['Êú™ÊµÅÂ§±', 'Â∑≤ÊµÅÂ§±'], rotation=0)
axes[0].set_ylabel('Áî®Êà∑Êï∞')

# ÊúàË¥π‰∏éÊµÅÂ§±ÂÖ≥Á≥ª
sns.boxplot(data=df, x='Churn', y='MonthlyCharges', ax=axes[1])
axes[1].set_title('ÊúàË¥π‰∏éÊµÅÂ§±ÂÖ≥Á≥ª', fontsize=14, fontweight='bold')
axes[1].set_xticklabels(['Êú™ÊµÅÂ§±', 'Â∑≤ÊµÅÂ§±'])

plt.tight_layout()
plt.savefig('churn_overview.png', dpi=300)

print("\\n‚úÖ Êï∞ÊçÆÂä†ËΩΩÂÆåÊàê")`
        },
        {
          emoji: 'üîß',
          title: 'Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ‰∏éÁâπÂæÅÂ∑•Á®ã',
          desc: 'Â§ÑÁêÜÁº∫Â§±ÂÄº„ÄÅÁºñÁ†Å„ÄÅÁâπÂæÅË°çÁîü',
          detail: '**ÈáçÁÇπ**ÔºöÁ±ªÂà´ÂèòÈáèÁºñÁ†Å„ÄÅÁâπÂæÅÁº©Êîæ„ÄÅÊ†∑Êú¨‰∏çÂπ≥Ë°°Â§ÑÁêÜ\\n**ÊäÄÂ∑ß**Ôºö‰ªé‰∏öÂä°ËßíÂ∫¶Ë°çÁîüÊñ∞ÁâπÂæÅ\\n**ËæìÂá∫**ÔºöÂèØÁî®‰∫éÂª∫Ê®°ÁöÑÁâπÂæÅÁü©Èòµ',
          code: `# 1. Â§ÑÁêÜÁº∫Â§±ÂÄº
print("Áº∫Â§±ÂÄºÁªüËÆ°:")
print(df.isnull().sum())

# TotalChargesÊúâÁº∫Â§±ÂÄºÔºåËΩ¨Êç¢‰∏∫Êï∞ÂÄºÁ±ªÂûã
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
df['TotalCharges'].fillna(df['TotalCharges'].median(), inplace=True)

# 2. ÁâπÂæÅÂ∑•Á®ã
# 2.1 Âú®ÁΩëÊó∂ÈïøÔºàÁî®ÊÄªË¥πÁî®/ÊúàË¥π‰º∞ÁÆóÔºâ
df['tenure_months'] = (df['TotalCharges'] / df['MonthlyCharges']).fillna(0)

# 2.2 ÊúàÂùáÊ∂àË¥πÂ¢ûÈïøÁéá
df['avg_monthly_growth'] = df['TotalCharges'] / (df['tenure_months'] + 1)

# 2.3 ÊúçÂä°‰ΩøÁî®Êï∞Èáè
service_cols = ['PhoneService', 'MultipleLines', 'InternetService', 
                'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 
                'TechSupport', 'StreamingTV', 'StreamingMovies']
df['total_services'] = (df[service_cols] != 'No').sum(axis=1)

# 2.4 ÊòØÂê¶È´ò‰ª∑ÂÄºÂÆ¢Êà∑
df['is_high_value'] = (df['MonthlyCharges'] > df['MonthlyCharges'].median()).astype(int)

# 2.5 ÂêàÁ∫¶È£éÈô©ÔºàÊúà‰ªòÂêàÁ∫¶È£éÈô©È´òÔºâ
df['contract_risk'] = (df['Contract'] == 'Month-to-month').astype(int)

print("\\nÊñ∞Â¢ûÁâπÂæÅ:")
print(df[['tenure_months', 'avg_monthly_growth', 'total_services', 
          'is_high_value', 'contract_risk']].head())

# 3. ÁºñÁ†ÅÁ±ªÂà´ÂèòÈáè
# 3.1 ‰∫åÂàÜÁ±ªÂèòÈáèÔºàYes/NoÔºâ
binary_cols = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 
               'PhoneService', 'PaperlessBilling']
for col in binary_cols:
    if col in df.columns:
        df[col] = df[col].map({'Yes': 1, 'No': 0, 'Male': 1, 'Female': 0})

# 3.2 Â§öÂàÜÁ±ªÂèòÈáèÔºàOne-HotÁºñÁ†ÅÔºâ
categorical_cols = ['MultipleLines', 'InternetService', 'OnlineSecurity', 
                   'OnlineBackup', 'DeviceProtection', 'TechSupport', 
                   'StreamingTV', 'StreamingMovies', 'Contract', 
                   'PaymentMethod']
df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)

# 3.3 ÁõÆÊ†áÂèòÈáè
df_encoded['Churn'] = df_encoded['Churn'].map({'Yes': 1, 'No': 0})

# 4. Âà†Èô§‰∏çÈúÄË¶ÅÁöÑÂàó
drop_cols = ['customerID']
df_encoded = df_encoded.drop(columns=[col for col in drop_cols if col in df_encoded.columns])

print("\\nÁºñÁ†ÅÂêéÁâπÂæÅÊï∞Èáè:", df_encoded.shape[1])
print("ÁâπÂæÅÂàóË°®:")
print(df_encoded.columns.tolist())

# 5. ÂàíÂàÜÁâπÂæÅÂíåÊ†áÁ≠æ
X = df_encoded.drop('Churn', axis=1)
y = df_encoded['Churn']

# 6. ÂàíÂàÜËÆ≠ÁªÉÈõÜÂíåÊµãËØïÈõÜ
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\\nËÆ≠ÁªÉÈõÜ: {X_train.shape}")
print(f"ÊµãËØïÈõÜ: {X_test.shape}")
print(f"ËÆ≠ÁªÉÈõÜÊµÅÂ§±Áéá: {y_train.mean()*100:.2f}%")
print(f"ÊµãËØïÈõÜÊµÅÂ§±Áéá: {y_test.mean()*100:.2f}%")

# 7. ÁâπÂæÅÁº©Êîæ
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("\\n‚úÖ Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÂÆåÊàê")`
        },
        {
          emoji: 'ü§ñ',
          title: 'Ê®°ÂûãËÆ≠ÁªÉ‰∏éÂØπÊØî',
          desc: 'ÈÄªËæëÂõûÂΩí„ÄÅÈöèÊú∫Ê£ÆÊûó„ÄÅXGBoost„ÄÅLightGBM',
          detail: '**ÂØπÊØî**Ôºö4ÁßçÁÆóÊ≥ïÊÄßËÉΩÂØπÊØî\\n**ÊåáÊ†á**ÔºöÂáÜÁ°ÆÁéá„ÄÅÂè¨ÂõûÁéá„ÄÅF1„ÄÅAUC\\n**ÈáçÁÇπ**ÔºöÂè¨ÂõûÁéáÔºà‰∏çÊºèÊéâÊµÅÂ§±Áî®Êà∑Ôºâ',
          code: `from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Â§ÑÁêÜÊ†∑Êú¨‰∏çÂπ≥Ë°°
from imblearn.over_sampling import SMOTE

smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)

print(f"SMOTEÂêéËÆ≠ÁªÉÈõÜ: {X_train_balanced.shape}")
print(f"ÊµÅÂ§±Áî®Êà∑ÊØî‰æã: {y_train_balanced.mean()*100:.2f}%")

# ÂÆö‰πâÊ®°Âûã
models = {
    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'XGBoost': XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='logloss'),
    'LightGBM': LGBMClassifier(n_estimators=100, random_state=42, verbose=-1)
}

# ËÆ≠ÁªÉÂíåËØÑ‰º∞
results = []

for name, model in models.items():
    print(f"\\n{'='*60}")
    print(f"ËÆ≠ÁªÉ {name}...")
    
    # ËÆ≠ÁªÉ
    model.fit(X_train_balanced, y_train_balanced)
    
    # È¢ÑÊµã
    y_pred = model.predict(X_test_scaled)
    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]
    
    # ËØÑ‰º∞
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    auc = roc_auc_score(y_test, y_pred_proba)
    
    results.append({
        'Ê®°Âûã': name,
        'ÂáÜÁ°ÆÁéá': f'{accuracy:.4f}',
        'Á≤æÁ°ÆÁéá': f'{precision:.4f}',
        'Âè¨ÂõûÁéá': f'{recall:.4f}',
        'F1ÂàÜÊï∞': f'{f1:.4f}',
        'AUC': f'{auc:.4f}'
    })
    
    print(f"ÂáÜÁ°ÆÁéá: {accuracy:.4f}")
    print(f"Á≤æÁ°ÆÁéá: {precision:.4f}")
    print(f"Âè¨ÂõûÁéá: {recall:.4f}")
    print(f"F1ÂàÜÊï∞: {f1:.4f}")
    print(f"AUC: {auc:.4f}")

# Ê®°ÂûãÂØπÊØîË°®
results_df = pd.DataFrame(results)
print("\\n" + "="*60)
print("Ê®°ÂûãÊÄßËÉΩÂØπÊØî:")
print("="*60)
print(results_df.to_string(index=False))

# ÈÄâÊã©ÊúÄ‰ºòÊ®°ÂûãÔºàËøôÈáåÈÄâÊã©AUCÊúÄÈ´òÁöÑÔºâ
best_model_name = results_df.loc[results_df['AUC'].astype(float).idxmax(), 'Ê®°Âûã']
print(f"\\nüèÜ ÊúÄ‰ºòÊ®°Âûã: {best_model_name}")

# ‰øùÂ≠òÊúÄ‰ºòÊ®°ÂûãÔºàÂÅáËÆæÊòØLightGBMÔºâ
best_model = models['LightGBM']
import joblib
joblib.dump(best_model, 'churn_model.pkl')
joblib.dump(scaler, 'scaler.pkl')
print("\\n‚úÖ Ê®°ÂûãÂ∑≤‰øùÂ≠ò: churn_model.pkl")`
        },
        {
          emoji: 'üìä',
          title: 'Ê®°ÂûãËß£Èáä‰∏é‰∏öÂä°Ê¥ûÂØü',
          desc: '‰ΩøÁî®SHAPËß£ÈáäÊ®°ÂûãÔºåËØÜÂà´ÊµÅÂ§±ÂÖ≥ÈîÆÂõ†Á¥†',
          detail: '**Â∑•ÂÖ∑**ÔºöSHAPÔºàSHapley Additive exPlanationsÔºâ\\n**ËæìÂá∫**ÔºöÁâπÂæÅÈáçË¶ÅÊÄß„ÄÅÂçï‰∏™Áî®Êà∑ÊµÅÂ§±ÂéüÂõ†\\n**‰ª∑ÂÄº**ÔºöÊåáÂØºÊåΩÁïôÁ≠ñÁï•',
          code: `import shap
import matplotlib.pyplot as plt

# 1. ËÆ°ÁÆóSHAPÂÄº
explainer = shap.TreeExplainer(best_model)
shap_values = explainer.shap_values(X_test_scaled)

# 2. ÁâπÂæÅÈáçË¶ÅÊÄßÔºàÂÖ®Â±ÄÔºâ
plt.figure(figsize=(10, 8))
shap.summary_plot(shap_values, X_test, plot_type="bar", show=False)
plt.title('ÁâπÂæÅÈáçË¶ÅÊÄßÊéíÂêçÔºàSHAPÔºâ', fontsize=16, fontweight='bold')
plt.tight_layout()
plt.savefig('shap_feature_importance.png', dpi=300)

# 3. SHAP Summary PlotÔºàÊòæÁ§∫ÁâπÂæÅÂÄºÂΩ±ÂìçÔºâ
plt.figure(figsize=(10, 8))
shap.summary_plot(shap_values, X_test, show=False)
plt.title('ÁâπÂæÅÂÄºÂØπÊµÅÂ§±È¢ÑÊµãÁöÑÂΩ±Âìç', fontsize=16, fontweight='bold')
plt.tight_layout()
plt.savefig('shap_summary.png', dpi=300)

# 4. Âçï‰∏™Áî®Êà∑Ëß£ÈáäÔºàÈÄâÊã©Á¨¨‰∏Ä‰∏™ÊµÅÂ§±Áî®Êà∑Ôºâ
churn_user_idx = y_test[y_test == 1].index[0]
churn_user_idx_in_test = list(y_test.index).index(churn_user_idx)

shap.force_plot(
    explainer.expected_value, 
    shap_values[churn_user_idx_in_test], 
    X_test.iloc[churn_user_idx_in_test],
    matplotlib=True,
    show=False
)
plt.title(f'Áî®Êà∑ {churn_user_idx} ÊµÅÂ§±ÂéüÂõ†Ëß£Èáä', fontsize=14, fontweight='bold')
plt.tight_layout()
plt.savefig('shap_user_explanation.png', dpi=300, bbox_inches='tight')

print("\\n‚úÖ SHAPÂàÜÊûêÂÆåÊàê")

# 5. ‰∏öÂä°Ê¥ûÂØüÊÄªÁªì
print("\\n" + "="*60)
print("ÂÖ≥ÈîÆÊµÅÂ§±Âõ†Á¥†ÂàÜÊûêÔºàÂü∫‰∫éSHAPÔºâ:")
print("="*60)

# Ëé∑ÂèñÁâπÂæÅÈáçË¶ÅÊÄßÊéíÂêç
feature_importance = pd.DataFrame({
    'feature': X_test.columns,
    'importance': np.abs(shap_values).mean(axis=0)
}).sort_values('importance', ascending=False)

print("\\nTop 10 ÊµÅÂ§±ÂΩ±ÂìçÂõ†Á¥†:")
print(feature_importance.head(10).to_string(index=False))

print("\\nüí° ‰∏öÂä°Âª∫ËÆÆ:")
print("1. ÂêàÁ∫¶Á±ªÂûãÔºöÊúà‰ªòÁî®Êà∑ÊµÅÂ§±È£éÈô©È´ò ‚Üí Êé®ËçêÂπ¥‰ªò‰ºòÊÉ†")
print("2. Âú®ÁΩëÊó∂ÈïøÔºöÊñ∞Áî®Êà∑ÊµÅÂ§±Â§ö ‚Üí Âä†Âº∫Êñ∞Áî®Êà∑ÂÖ≥ÊÄÄ")
print("3. ÊúàË¥πÔºöÈ´òÊúàË¥πÁî®Êà∑ÊòìÊµÅÂ§± ‚Üí Êèê‰æõÈò∂Ê¢Ø‰ºòÊÉ†")
print("4. ÊäÄÊúØÊîØÊåÅÔºöÊú™‰ΩøÁî®ËÄÖÊòìÊµÅÂ§± ‚Üí ‰∏ªÂä®Êèê‰æõÊäÄÊúØÊîØÊåÅ")
print("5. ‰ªòÊ¨æÊñπÂºèÔºöÁîµÂ≠êÊîØÁ•®Áî®Êà∑ÊòìÊµÅÂ§± ‚Üí Êé®ËçêËá™Âä®Êâ£Ê¨æ")`
        },
        {
          emoji: 'üéØ',
          title: 'ÊµÅÂ§±È¢ÑË≠¶Á≥ªÁªü‰∏éÊåΩÁïôÁ≠ñÁï•',
          desc: 'ÊûÑÂª∫ÂÆûÊó∂È¢ÑË≠¶Á≥ªÁªüÔºåËæìÂá∫ÊåΩÁïôÂêçÂçï',
          detail: '**ËæìÂá∫**ÔºöÈ´òÈ£éÈô©Áî®Êà∑ÂêçÂçï + ‰∏™ÊÄßÂåñÊåΩÁïôÁ≠ñÁï•\\n**Â∫îÁî®**ÔºöÂÆ¢Êúç‰∏≠ÂøÉ„ÄÅËê•ÈîÄÈÉ®Èó®\\n**ROI**ÔºöÊåΩÁïôÊàêÊú¨ < ÂÆ¢Êà∑ÁîüÂëΩÂë®Êúü‰ª∑ÂÄº',
          code: `# 1. ÂØπÊâÄÊúâÁî®Êà∑ËøõË°åÊµÅÂ§±Ê¶ÇÁéáÈ¢ÑÊµã
all_users_scaled = scaler.transform(X)
churn_proba = best_model.predict_proba(all_users_scaled)[:, 1]

# Ê∑ªÂä†ÊµÅÂ§±Ê¶ÇÁéáÂà∞ÂéüÊï∞ÊçÆ
df['churn_probability'] = churn_proba
df['churn_risk_level'] = pd.cut(churn_proba, 
                                 bins=[0, 0.3, 0.6, 1.0],
                                 labels=['‰ΩéÈ£éÈô©', '‰∏≠È£éÈô©', 'È´òÈ£éÈô©'])

# 2. È´òÈ£éÈô©Áî®Êà∑ÂêçÂçï
high_risk_users = df[df['churn_risk_level'] == 'È´òÈ£éÈô©'].copy()
high_risk_users = high_risk_users.sort_values('churn_probability', ascending=False)

print(f"\\nÈ´òÈ£éÈô©Áî®Êà∑Êï∞Èáè: {len(high_risk_users)}")
print(f"Âç†ÊØî: {len(high_risk_users)/len(df)*100:.2f}%")

# 3. ÊåΩÁïôÁ≠ñÁï•Âª∫ËÆÆÔºàÂü∫‰∫éÁî®Êà∑ÁâπÂæÅÔºâ
def recommend_retention_strategy(row):
    strategies = []
    
    if row.get('Contract') == 'Month-to-month':
        strategies.append('üìå ÂêàÁ∫¶‰ºòÊÉ†ÔºöÂçáÁ∫ßËá≥Âπ¥‰ªò‰∫´8Êäò‰ºòÊÉ†')
    
    if row.get('MonthlyCharges', 0) > df['MonthlyCharges'].median():
        strategies.append('üí∞ ‰ª∑Ê†º‰ºòÊÉ†ÔºöVIP‰∏ìÂ±ûÊäòÊâ£ÔºåÊúàË¥πÂáèÂÖç20%')
    
    if row.get('TechSupport') == 'No':
        strategies.append('üõ†Ô∏è ÊäÄÊúØÊîØÊåÅÔºöÂÖçË¥πËµ†ÈÄÅ3‰∏™ÊúàÊäÄÊúØÊîØÊåÅÊúçÂä°')
    
    if row.get('tenure_months', 0) < 12:
        strategies.append('üéÅ Êñ∞Áî®Êà∑ÂÖ≥ÊÄÄÔºöËµ†ÈÄÅËØùË¥π/ÊµÅÈáèÂåÖ')
    
    if row.get('PaymentMethod') == 'Electronic check':
        strategies.append('üè¶ ‰ªòÊ¨æ‰ºòÊÉ†ÔºöÊîπÁî®Ëá™Âä®Êâ£Ê¨æ‰∫´ÊØèÊúà5ÂÖÉ‰ºòÊÉ†')
    
    return ' | '.join(strategies) if strategies else '‚úÖ Â∏∏ËßÑÂÖ≥ÊÄÄ'

high_risk_users['retention_strategy'] = high_risk_users.apply(
    recommend_retention_strategy, axis=1
)

# 4. ËæìÂá∫ÊåΩÁïôÂêçÂçï
retention_list = high_risk_users[[
    'customerID', 'churn_probability', 'churn_risk_level',
    'MonthlyCharges', 'TotalCharges', 'Contract', 
    'tenure_months', 'retention_strategy'
]].copy()

retention_list.columns = [
    'Áî®Êà∑ID', 'ÊµÅÂ§±Ê¶ÇÁéá', 'È£éÈô©Á≠âÁ∫ß', 'ÊúàË¥π', 'ÊÄªË¥πÁî®', 
    'ÂêàÁ∫¶Á±ªÂûã', 'Âú®ÁΩëÊúàÊï∞', 'ÊåΩÁïôÁ≠ñÁï•'
]

print("\\nTop 10 È´òÈ£éÈô©Áî®Êà∑:")
print(retention_list.head(10).to_string(index=False))

# 5. ÂØºÂá∫ExcelÊä•Âëä
with pd.ExcelWriter('Áî®Êà∑ÊµÅÂ§±È¢ÑË≠¶Êä•Âëä.xlsx', engine='openpyxl') as writer:
    # Sheet1: Ê®°ÂûãÊÄßËÉΩ
    results_df.to_excel(writer, sheet_name='Ê®°ÂûãÊÄßËÉΩ', index=False)
    
    # Sheet2: È´òÈ£éÈô©Áî®Êà∑ÂêçÂçï
    retention_list.to_excel(writer, sheet_name='È´òÈ£éÈô©Áî®Êà∑', index=False)
    
    # Sheet3: ÁâπÂæÅÈáçË¶ÅÊÄß
    feature_importance.to_excel(writer, sheet_name='ÂÖ≥ÈîÆÂõ†Á¥†', index=False)
    
    # Sheet4: È£éÈô©ÂàÜÂ∏É
    risk_summary = df['churn_risk_level'].value_counts().reset_index()
    risk_summary.columns = ['È£éÈô©Á≠âÁ∫ß', 'Áî®Êà∑Êï∞']
    risk_summary.to_excel(writer, sheet_name='È£éÈô©ÂàÜÂ∏É', index=False)

print("\\n‚úÖ È¢ÑË≠¶Êä•ÂëäÂ∑≤ÁîüÊàê: Áî®Êà∑ÊµÅÂ§±È¢ÑË≠¶Êä•Âëä.xlsx")

# 6. ROIËÆ°ÁÆó
print("\\n" + "="*60)
print("ÊåΩÁïôROIÂàÜÊûê:")
print("="*60)
avg_clv = df['TotalCharges'].mean()  # ÂÆ¢Êà∑ÁîüÂëΩÂë®Êúü‰ª∑ÂÄº
retention_cost = 100  # ÂÅáËÆæÊåΩÁïôÊàêÊú¨100ÂÖÉ/‰∫∫
expected_retention_rate = 0.3  # ÂÅáËÆæÊåΩÁïôÊàêÂäüÁéá30%

total_high_risk = len(high_risk_users)
expected_saved = total_high_risk * expected_retention_rate
total_cost = total_high_risk * retention_cost
total_value = expected_saved * avg_clv
roi = (total_value - total_cost) / total_cost * 100

print(f"È´òÈ£éÈô©Áî®Êà∑Êï∞: {total_high_risk}")
print(f"È¢ÑËÆ°ÊåΩÁïôÊàêÂäü: {expected_saved:.0f} ‰∫∫")
print(f"ÊåΩÁïôÊÄªÊàêÊú¨: ¬•{total_cost:,.0f}")
print(f"È¢ÑËÆ°ÊåΩÂõû‰ª∑ÂÄº: ¬•{total_value:,.0f}")
print(f"ROI: {roi:.2f}%")
print("="*60)

print("\\n‚úÖ È°πÁõÆÂÆåÊàêÔºÅÂèØÁî®‰∫é:")
print("  1. ÂÆ¢Êúç‰∏≠ÂøÉ‰∏ªÂä®Â§ñÂëºÊåΩÁïô")
print("  2. Á≤æÂáÜËê•ÈîÄÊ¥ªÂä®Êé®ÈÄÅ")
print("  3. ‰∫ßÂìÅ‰ºòÂåñÂíåÊúçÂä°ÊîπËøõ")
print("  4. ÂÆ¢Êà∑ÁîüÂëΩÂë®ÊúüÁÆ°ÁêÜ")`
        }
      ]
    },
    {
      id: 'learning-path',
      title: 'PART 19 Â≠¶‰π†Ë∑ØÂæÑ',
      subtitle: '‰ªéÂÖ•Èó®Âà∞Á≤æÈÄöÁöÑÂÆåÊï¥Ë∑ØÁ∫øÂõæ',
      items: [
        {
          emoji: 'üó∫Ô∏è',
          title: 'PythonÊï∞ÊçÆÂàÜÊûêÂ≠¶‰π†Ë∑ØÂæÑ',
          desc: '30Â§©‰ªéÈõ∂Âà∞Êï∞ÊçÆÂàÜÊûêÂ∏à',
          detail: '**ÂÖ∏Âûã‰∏öÂä°Âú∫ÊôØ**ÔºöÁ≥ªÁªüÂåñÂ≠¶‰π†ËßÑÂàí\\n**ÊòìË∏©ÂùëÁÇπ**ÔºöË¥™Â§öÂöº‰∏çÁÉÇ„ÄÅÊ≤°ÊúâÂÆûÊàò\\n**ÂèØÁªßÁª≠Ê∑±Êåñ**ÔºöKaggleÂÆûÊàò„ÄÅÈ°πÁõÆÂÆûË∑µ',
          code: `# Á¨¨1Âë®ÔºöPythonÂü∫Á°ÄÔºàÊØèÂ§©2Â∞èÊó∂Ôºâ
# Day 1-2: PythonÁéØÂ¢É„ÄÅÂü∫Á°ÄËØ≠Ê≥ï„ÄÅÊï∞ÊçÆÁªìÊûÑ
# Day 3-4: ÂáΩÊï∞„ÄÅÂæ™ÁéØ„ÄÅÊñá‰ª∂Êìç‰Ωú
# Day 5-7: ÁªºÂêàÁªÉ‰π†„ÄÅÂ∞èÈ°πÁõÆ

# Á¨¨2Âë®ÔºöNumPy & PandasÔºàÊØèÂ§©2Â∞èÊó∂Ôºâ
# Day 8-9: NumPyÊï∞ÁªÑ„ÄÅÂêëÈáèÂåñËøêÁÆó
# Day 10-12: PandasËØªÂèñ„ÄÅÁ≠õÈÄâ„ÄÅÊ∏ÖÊ¥ó
# Day 13-14: GroupBy„ÄÅMerge„ÄÅÊó∂Èó¥Â∫èÂàó

# Á¨¨3Âë®ÔºöÊï∞ÊçÆÂèØËßÜÂåñÔºàÊØèÂ§©2Â∞èÊó∂Ôºâ
# Day 15-16: MatplotlibÂü∫Á°ÄÂõæË°®
# Day 17-18: SeabornÈ´òÁ∫ßÂèØËßÜÂåñ
# Day 19-21: ÂÆûÊàòÈ°πÁõÆÔºöÈîÄÂîÆÊï∞ÊçÆÂàÜÊûêÁúãÊùø

# Á¨¨4Âë®ÔºöÁªºÂêàÂÆûÊàòÔºàÊØèÂ§©3Â∞èÊó∂Ôºâ
# Day 22-23: ÂÆåÊï¥Êï∞ÊçÆÂàÜÊûêÈ°πÁõÆ
# Day 24-25: Ëá™Âä®ÂåñÊä•Ë°®ËÑöÊú¨
# Day 26-27: SQLÈõÜÊàê„ÄÅÊï∞ÊçÆÂ∫ìÊìç‰Ωú
# Day 28-30: ‰∏™‰∫∫È°πÁõÆ„ÄÅÁÆÄÂéÜÈ°πÁõÆ

# Êé®ËçêÂ≠¶‰π†ËµÑÊ∫ê
# 1. ÂÆòÊñπÊñáÊ°£Ôºöpandas.pydata.org
# 2. ËßÜÈ¢ëÊïôÁ®ãÔºöBÁ´ô„ÄÅYouTube
# 3. ÂÆûÊàòÂπ≥Âè∞ÔºöKaggle„ÄÅÂ§©Ê±†
# 4. ‰π¶Á±çÔºö„ÄäÂà©Áî®PythonËøõË°åÊï∞ÊçÆÂàÜÊûê„Äã

# ËøõÈò∂ÊñπÂêë
# 1. Êï∞ÊçÆÂèØËßÜÂåñÔºöPlotly„ÄÅDash
# 2. Êú∫Âô®Â≠¶‰π†ÔºöScikit-learn
# 3. Â§ßÊï∞ÊçÆÔºöPySpark„ÄÅDask
# 4. Ëá™Âä®ÂåñÔºöAirflow„ÄÅLuigi`
        }
      ]
    }
  ]

  return (
    <div className={isDark ? 'bg-gray-900 min-h-screen' : 'bg-gray-50 min-h-screen'}>
      <style jsx global>{`
        .python-code-block {
          background-color: #2b2b2b !important;
        }
        .python-code-block code {
          color: #a9b7c6 !important;
          background-color: transparent !important;
        }
      `}</style>
      <Navigation />

      {/* Èù¢ÂåÖÂ±ëÂØºËà™ */}
      <div className={isDark ? 'bg-gray-800 border-gray-700 border-b sticky top-0 z-10' : 'bg-white border-gray-200 border-b sticky top-0 z-10'}>
        <div className="max-w-[1600px] mx-auto px-4 sm:px-6 lg:px-8">
          <div className="flex items-center space-x-2 h-16">
            <Link href="/" className="flex items-center space-x-2 text-blue-600 hover:text-blue-700 transition-colors">
                <Home size={20} />
                <span className="font-medium">‰∏ªÈ°µ</span>
              </Link>
            <span className={isDark ? 'text-gray-600' : 'text-gray-400'}>/</span>
            <span className={isDark ? 'text-gray-100 font-medium' : 'text-gray-900 font-medium'}>PythonÊï∞ÊçÆÂàÜÊûê</span>
          </div>
        </div>
      </div>

      <div className="max-w-[1600px] mx-auto px-4 sm:px-6 lg:px-8 py-12">
        <div className="flex gap-8">
          
          <aside className="hidden lg:block w-72 flex-shrink-0">
            <div className={isDark ? 'sticky top-24 bg-gray-800/95 border-gray-700 backdrop-blur-sm rounded-2xl border-2 p-5 shadow-lg max-h-[calc(100vh-120px)] overflow-y-auto' : 'sticky top-24 bg-white/95 border-gray-200 backdrop-blur-sm rounded-2xl border-2 p-5 shadow-lg max-h-[calc(100vh-120px)] overflow-y-auto'}>
              <h3 className="text-xl font-extrabold mb-6 flex items-center gap-2">
                {getLucideIcon('üìñ', 'w-6 h-6 text-[#19bcc8]')}
                <span className={isDark ? 'text-gray-100' : 'text-gray-800'}>ÁõÆÂΩïÂØºËà™</span>
              </h3>
              <nav className="space-y-1.5">
                {navItems.map((item) => {
                  const isActive = activeSection === item.id
                  
                  return (
                    <a
                      key={item.id}
                      href={'#' + item.id}
                      className={
                        'flex items-center gap-3 px-4 py-2.5 rounded-xl transition-all duration-200 border-2 ' +
                        (isActive
                          ? 'border-[#19bcc8] bg-[#19bcc8]/10 shadow-md'
                          : (isDark ? 'border-transparent hover:bg-gray-700/50 hover:border-[#19bcc8]/30' : 'border-transparent hover:bg-[#19bcc8]/5 hover:border-[#19bcc8]/30')
                        )
                      }
                    >
                      {getLucideIcon(item.icon, 'w-5 h-5 text-[#19bcc8]')}
                      <span className={'text-sm font-medium ' + (isActive ? 'text-[#19bcc8]' : (isDark ? 'text-gray-200' : 'text-gray-700'))}>
                        {item.label}
                      </span>
                    </a>
                  )
                })}
              </nav>
            </div>
          </aside>

          <main className="flex-1 min-w-0">
            {/* È°µÈù¢Ê†áÈ¢ò */}
            <div className="text-center mb-20">
              <div className="flex items-center justify-center mb-6">
                <div className="p-3 rounded-full bg-gradient-to-r from-green-500 to-teal-600">
                  {getLucideIcon('üêç', 'h-8 w-8 text-white')}
                </div>
              </div>
              <h1 className={'text-4xl font-bold mb-6 ' + (isDark ? 'text-gray-100' : 'text-gray-900')}>
                Python Êï∞ÊçÆÂàÜÊûêÂÆåÊï¥Áü•ËØÜ‰ΩìÁ≥ª
              </h1>
              <p className={'text-lg max-w-3xl mx-auto ' + (isDark ? 'text-gray-400' : 'text-gray-600')}>
                ‰ªéÁéØÂ¢ÉÊê≠Âª∫Âà∞È´òÁ∫ßÂ∫îÁî®Ôºå‰ªéÁêÜËÆ∫Ê°ÜÊû∂Âà∞ÂÆûÊàòËêΩÂú∞ÔºåÊéåÊè°Êï∞ÊçÆÂàÜÊûêÂ∏àÂøÖÂ§áÁöÑ‰∏öÂä°Áü•ËØÜ
              </p>
            </div>

            <section id="intro" className="mb-16 scroll-mt-24">
              <div className={'rounded-xl p-10 shadow-sm border ' + (isDark ? 'bg-gray-800 border-gray-700' : 'bg-white border-gray-200')}>
                <h2 className={'text-3xl font-bold mb-8 ' + (isDark ? 'text-gray-100' : 'text-gray-900')}>
                  {getLucideIcon('üìä', 'inline w-6 h-6 text-[#19bcc8]')} Áü•ËØÜ‰ΩìÁ≥ªÊû∂ÊûÑ
                </h2>

                <div className="mt-8 grid grid-cols-3 gap-4">
                  {[
                    { label: '140+ Python‰ª£Á†Å', value: 'ÂÆûÊàò‰ª£Á†Å' },
                    { label: '1500+ Ë°å‰ª£Á†Å', value: 'Ê∑±Â∫¶ËÆ≤Ëß£' },
                    { label: '90% Âú∫ÊôØË¶ÜÁõñ', value: 'Êï∞ÊçÆÂàÜÊûê' }
                  ].map((item, idx) => (
                    <div key={idx} className={'rounded-lg p-4 border ' + (isDark ? 'bg-[#19bcc8]/10 border-[#19bcc8]/30' : 'bg-[#19bcc8]/5 border-[#19bcc8]/20')}>
                      <div className={'text-sm mb-1 ' + (isDark ? 'text-gray-400' : 'text-gray-600')}>{item.label}</div>
                      <div className={'text-lg font-bold ' + (isDark ? 'text-gray-100' : 'text-[#19bcc8]')}>{item.value}</div>
                  </div>
                ))}
            </div>
          </div>

              {/* ‰ΩìÁ≥ªÁâπÁÇπ */}
              <div className={'mt-12 rounded-xl p-6 shadow-sm border ' + (isDark ? 'bg-gray-800 border-gray-700' : 'bg-white border-gray-200')}>
                <h3 className={'text-xl font-bold mb-6 flex items-center gap-2 ' + (isDark ? 'text-gray-100' : 'text-gray-900')}>
                  {getLucideIcon('‚≠ê', 'w-6 h-6 text-[#19bcc8]')}
                  <span>Êú¨‰ΩìÁ≥ªÁâπÁÇπ</span>
                </h3>
                <div className="grid grid-cols-2 gap-4">
                  {[
                    { icon: 'üéØ', title: 'ËÅöÁÑ¶Êï∞ÊçÆÂàÜÊûê', desc: 'Âè™ËÆ≤Êï∞ÊçÆÂàÜÊûêÂøÖÂ§áÔºåË∑≥ËøáWebÂºÄÂèë„ÄÅÁà¨Ëô´Á≠âÊó†ÂÖ≥ÂÜÖÂÆπ' },
                    { icon: 'üìä', title: 'ÂõõÂ§ßÊ†∏ÂøÉÂ∫ì', desc: 'NumPy„ÄÅPandas„ÄÅMatplotlib„ÄÅSeabornÊ∑±Â∫¶ËÆ≤Ëß£' },
                    { icon: 'üíº', title: '‰∏öÂä°ÂØºÂêë', desc: 'ÊâÄÊúâÊ°à‰æãÊù•Ëá™ÁúüÂÆû‰∏öÂä°Âú∫ÊôØÔºàÈîÄÂîÆ„ÄÅÁî®Êà∑„ÄÅËøêËê•Ôºâ' },
                    { icon: 'üîß', title: 'Âç≥Â≠¶Âç≥Áî®', desc: 'ÊØè‰∏™Áü•ËØÜÁÇπÈÖç‰ª£Á†ÅÊ®°ÊùøÔºåÂ§çÂà∂Âç≥ÂèØ‰∏äÊâã' }
                  ].map((item, idx) => (
                    <div key={idx} className={'p-4 rounded-lg border transition-all duration-300 ' + (isDark ? 'bg-gray-700/30 border-gray-600 hover:border-[#19bcc8]' : 'bg-gray-50 border-gray-200 hover:border-[#19bcc8]')}>
                      <div className="flex items-start gap-3">
                        {getLucideIcon(item.icon, 'w-6 h-6 text-[#19bcc8] flex-shrink-0')}
                        <div>
                          <h4 className={'font-bold mb-1 ' + (isDark ? 'text-gray-100' : 'text-gray-900')}>{item.title}</h4>
                          <p className={'text-sm ' + (isDark ? 'text-gray-400' : 'text-gray-600')}>{item.desc}</p>
                        </div>
                      </div>
                    </div>
                    ))}
                  </div>
                </div>
            </section>

            {/* PARTÂÜÖÂÆπ */}
            <div className="space-y-24">
              {parts.map((part, partIdx) => (
                <section key={part.id} id={part.id} className="scroll-mt-24">
                  <div className={'rounded-xl p-6 shadow-sm border mb-10 ' + (isDark ? 'bg-gray-800 border-gray-700' : 'bg-white border-gray-200')}>
                    <div className="flex items-center gap-4 mb-3">
                      <div className="w-1 h-12 bg-[#19bcc8] rounded-full"></div>
                      <h2 className={'text-3xl font-extrabold ' + (isDark ? 'text-gray-100' : 'text-gray-900')}>{part.title}</h2>
                    </div>
                    <p className={'text-base ml-5 ' + (isDark ? 'text-gray-400' : 'text-gray-600')}>{part.subtitle}</p>
                  </div>

                  <div className="space-y-6">
                    {part.items.map((item, itemIdx) => (
                      <div key={itemIdx} className={'rounded-xl border p-5 transition-all duration-300 shadow-sm hover:shadow-md ' + (isDark ? 'bg-gray-800 border-gray-700 hover:border-[#19bcc8]' : 'bg-white border-gray-200 hover:border-[#19bcc8]')}>
                        <div className="flex items-start gap-4">
                          {getLucideIcon(item.emoji, 'w-6 h-6 text-[#19bcc8] flex-shrink-0 mt-1')}
                          <div className="flex-1 min-w-0">
                            <h3 className={'text-lg font-bold mb-2 flex items-center gap-2 ' + (isDark ? 'text-gray-100' : 'text-gray-900')}>
                              {item.title}
                            </h3>
                            <p className={'mb-3 text-sm ' + (isDark ? 'text-gray-300' : 'text-gray-700')}>
                              {item.desc}
                            </p>
                            {item.detail && (
                              <div className={'p-4 rounded-lg border-l-2 border-[#19bcc8] mb-4 ' + (isDark ? 'bg-gray-900/50' : 'bg-gray-50')}>
                                {item.detail.split('\\n').map((part, i) => (
                                  <p key={i} className={'text-sm mb-2 last:mb-0 ' + (isDark ? 'text-gray-400' : 'text-gray-600')}>
                                    {part.startsWith('**') ? (
                                      <>
                                        <span className="font-bold text-[#19bcc8]">{part.split('**')[1]}</span>
                                        {part.split('**')[2]}
                                      </>
                                    ) : (
                                      part
                                    )}
                                  </p>
              ))}
            </div>
                            )}
                            {item.code && (
                              <pre 
                                className="p-4 rounded-lg border overflow-x-auto font-mono text-sm"
                                style={{
                                  backgroundColor: '#e8f5f3',
                                  borderColor: '#19bcc8',
                                  color: '#000'
                                }}
                              >
                                <code>
                                  {item.code.split('\n').map((line, idx, arr) => {
                                    const isComment = line.trim().startsWith('#');
                                    const prevLine = idx > 0 ? arr[idx - 1].trim() : '';
                                    // Â¶ÇÊûúÂΩìÂâçË°åÊòØÊ≥®ÈáäÔºå‰∏îÂâç‰∏ÄË°å‰∏çÊòØÁ©∫Ë°å‰πü‰∏çÊòØÊ≥®ÈáäÔºåÂàôÊ∑ªÂä†Á©∫Ë°å
                                    const needsSpace = isComment && prevLine.length > 0 && !prevLine.startsWith('#');
                                    
                                    return (
                                      <div key={idx}>
                                        {needsSpace && <div>&nbsp;</div>}
                                        <div style={{ color: isComment ? '#888' : '#000' }}>
                                          {line || '\u00A0'}
          </div>
        </div>
                                    );
                                  })}
                                </code>
                              </pre>
                            )}
      </div>
    </div>
      </div>
                    ))}
    </div>

                  {/* ÂàÜÈöîÁ∫ø */}
                  {partIdx < parts.length - 1 && (
                    <div className="flex items-center justify-center my-16">
                      <div className={'w-2 h-2 rounded-full mx-2 ' + (isDark ? 'bg-[#19bcc8]' : 'bg-[#19bcc8]')}></div>
                      <div className={'w-2 h-2 rounded-full mx-2 ' + (isDark ? 'bg-[#19bcc8]' : 'bg-[#19bcc8]')}></div>
                      <div className={'w-2 h-2 rounded-full mx-2 ' + (isDark ? 'bg-[#19bcc8]' : 'bg-[#19bcc8]')}></div>
                    </div>
                  )}
                </section>
              ))}
            </div>

            {/* È°µËÑöÊÄªÁªì */}
            <div className={'rounded-xl p-8 mt-20 shadow-sm border ' + (isDark ? 'bg-gray-800 border-gray-700' : 'bg-white border-gray-200')}>
              <div className="flex items-center gap-3 mb-4">
                <div className="w-1 h-8 bg-[#19bcc8] rounded-full"></div>
                <h3 className={'text-2xl font-bold ' + (isDark ? 'text-gray-100' : 'text-gray-900')}>
                  ÊÅ≠ÂñúÔºÅ‰Ω†Â∑≤ÊéåÊè°PythonÊï∞ÊçÆÂàÜÊûêÂÆåÊï¥Áü•ËØÜ‰ΩìÁ≥ª
                </h3>
              </div>
              <p className={'mb-6 ml-4 ' + (isDark ? 'text-gray-300' : 'text-gray-700')}>
                ‰ªéÁéØÂ¢ÉÊê≠Âª∫Âà∞È´òÁ∫ßÂ∫îÁî®Ôºå14‰∏™Ê®°ÂùóÂæ™Â∫èÊ∏êËøõÔºå140+‰ª£Á†ÅÊ®°ÊùøÂä©‰Ω†Âø´ÈÄü‰∏äÊâãÊï∞ÊçÆÂàÜÊûêÂ∑•‰Ωú„ÄÇ
              </p>
              <div className="grid grid-cols-3 gap-4">
                <div className={'p-4 rounded-lg border ' + (isDark ? 'bg-gray-700/30 border-gray-600' : 'bg-gray-50 border-gray-200')}>
                  <div className={'text-3xl font-black mb-2 text-[#19bcc8]'}>14</div>
                  <div className={'text-sm ' + (isDark ? 'text-gray-400' : 'text-gray-600')}>Ê†∏ÂøÉÊ®°Âùó</div>
                </div>
                <div className={'p-4 rounded-lg border ' + (isDark ? 'bg-gray-700/30 border-gray-600' : 'bg-gray-50 border-gray-200')}>
                  <div className={'text-3xl font-black mb-2 text-[#19bcc8]'}>140+</div>
                  <div className={'text-sm ' + (isDark ? 'text-gray-400' : 'text-gray-600')}>‰ª£Á†ÅÁ§∫‰æã</div>
                </div>
                <div className={'p-4 rounded-lg border ' + (isDark ? 'bg-gray-700/30 border-gray-600' : 'bg-gray-50 border-gray-200')}>
                  <div className={'text-3xl font-black mb-2 text-[#19bcc8]'}>90%</div>
                  <div className={'text-sm ' + (isDark ? 'text-gray-400' : 'text-gray-600')}>Âú∫ÊôØË¶ÜÁõñ</div>
                </div>
              </div>
            </div>
          </main>
        </div>

        {showBackToTop && (
          <button
            onClick={scrollToTop}
            className={
              'fixed bottom-8 right-8 p-4 rounded-full shadow-lg transition-all duration-300 hover:scale-110 z-50 bg-[#19bcc8] hover:bg-[#17a8b4] text-white'
            }
            aria-label="ËøîÂõûÈ°∂ÈÉ®"
          >
            <ArrowUp className="w-6 h-6" />
          </button>
        )}
      </div>

      {/* ‰ª£Á†ÅÂùóÊ†∑Âºè - ÁÆÄÂçïÂå∫ÂàÜÊ≥®Èáä */}
      <style jsx global>{`
        pre code {
          display: block;
          white-space: pre;
          line-height: 1.6;
        }
        
        /* Ê≥®ÈáäË°åÁî®ÁÅ∞Ëâ≤ */
        pre code::before {
          content: '';
        }
      `}</style>
    </div>
  )
}
