"""
ä¸ºSQLç»ƒä¹ é¢˜ç›®ç”ŸæˆçœŸå®çš„CSVæ•°æ®é›†
æ¯ä¸ªé¢˜ç›®å¯¹åº”ä¸€ä¸ªæˆ–å¤šä¸ªCSVæ–‡ä»¶
"""
import csv
import os
from datetime import datetime, timedelta
import random

os.makedirs('public/sql-datasets', exist_ok=True)

print("=" * 70)
print("æ­£åœ¨ç”ŸæˆSQLç»ƒä¹ é¢˜æ•°æ®é›†...")
print("=" * 70)

# ==========================================
# é¢˜ç›®1ï¼šè®¡ç®—æ¯ä¸ªç”¨æˆ·æœ€è¿‘ä¸€æ¬¡è®¢å•é‡‘é¢
# ==========================================
print("\n[1/10] ç”Ÿæˆè®¢å•æ•°æ®é›† (orders.csv)...")

random.seed(42)
orders_data = []
base_date = datetime(2024, 1, 1)

# ç”Ÿæˆ100ä¸ªç”¨æˆ·çš„è®¢å•æ•°æ®
for user_id in range(101, 151):  # 50ä¸ªç”¨æˆ·
    num_orders = random.randint(2, 8)  # æ¯äºº2-8ç¬”è®¢å•
    for i in range(num_orders):
        order_date = base_date + timedelta(days=random.randint(0, 90))
        orders_data.append({
            'order_id': len(orders_data) + 1,
            'user_id': user_id,
            'amount': round(random.uniform(30, 300), 2),
            'created_at': order_date.strftime('%Y-%m-%d %H:%M:%S')
        })

# æ’åº
orders_data.sort(key=lambda x: x['order_id'])

with open('public/sql-datasets/orders.csv', 'w', newline='', encoding='utf-8-sig') as f:
    writer = csv.DictWriter(f, fieldnames=['order_id', 'user_id', 'amount', 'created_at'])
    writer.writeheader()
    writer.writerows(orders_data)

print(f"âœ“ orders.csv ({len(orders_data)} è¡Œ)")

# ==========================================
# é¢˜ç›®2ï¼šè®¡ç®—7æ—¥ç§»åŠ¨å¹³å‡é”€å”®é¢
# ==========================================
print("\n[2/10] ç”Ÿæˆæ—¥é”€å”®æ•°æ®é›† (daily_sales.csv)...")

daily_sales_data = []
start_date = datetime(2024, 1, 1)

# ç”Ÿæˆ3ä¸ªäº§å“çš„60å¤©é”€å”®æ•°æ®
for product_id in [1, 2, 3]:
    base_amount = random.uniform(80, 150)
    for day in range(60):
        sale_date = start_date + timedelta(days=day)
        # æ·»åŠ è¶‹åŠ¿å’Œå™ªå£°
        trend = day * 0.5
        noise = random.gauss(0, 10)
        amount = round(base_amount + trend + noise, 2)
        
        daily_sales_data.append({
            'product_id': product_id,
            'sale_date': sale_date.strftime('%Y-%m-%d'),
            'amount': amount
        })

with open('public/sql-datasets/daily_sales.csv', 'w', newline='', encoding='utf-8-sig') as f:
    writer = csv.DictWriter(f, fieldnames=['product_id', 'sale_date', 'amount'])
    writer.writeheader()
    writer.writerows(daily_sales_data)

print(f"âœ“ daily_sales.csv ({len(daily_sales_data)} è¡Œ)")

# ==========================================
# é¢˜ç›®3ï¼šåŒæ¯”å¢é•¿ç‡è®¡ç®—
# ==========================================
print("\n[3/10] ç”Ÿæˆæœˆåº¦é”€å”®æ•°æ®é›† (monthly_sales.csv)...")

monthly_sales_data = []
months = []
for year in [2023, 2024]:
    for month in range(1, 13):
        months.append((year, month))

for product_id in ['P001', 'P002', 'P003']:
    base_amount = random.uniform(50000, 100000)
    for year, month in months:
        # 2024å¹´æ¯”2023å¹´å¢é•¿10-30%
        growth_factor = 1.0 if year == 2023 else random.uniform(1.1, 1.3)
        seasonal_factor = 1 + 0.2 * abs(6 - month) / 6  # å¹´ä¸­æœ€é«˜
        amount = round(base_amount * growth_factor * seasonal_factor + random.gauss(0, 5000), 2)
        
        monthly_sales_data.append({
            'product_id': product_id,
            'year': year,
            'month': month,
            'amount': amount
        })

with open('public/sql-datasets/monthly_sales.csv', 'w', newline='', encoding='utf-8-sig') as f:
    writer = csv.DictWriter(f, fieldnames=['product_id', 'year', 'month', 'amount'])
    writer.writeheader()
    writer.writerows(monthly_sales_data)

print(f"âœ“ monthly_sales.csv ({len(monthly_sales_data)} è¡Œ)")

# ==========================================
# é¢˜ç›®4ï¼šç”¨æˆ·ç´¯è®¡æ¶ˆè´¹é‡‘é¢
# ==========================================
print("\n[4/10] ç”Ÿæˆäº¤æ˜“æ˜ç»†æ•°æ®é›† (transactions.csv)...")

transactions_data = []
transaction_date = datetime(2024, 1, 1)

for user_id in range(1001, 1051):  # 50ä¸ªç”¨æˆ·
    num_trans = random.randint(5, 15)
    for i in range(num_trans):
        transaction_date += timedelta(hours=random.randint(1, 48))
        transactions_data.append({
            'transaction_id': len(transactions_data) + 1,
            'user_id': user_id,
            'amount': round(random.uniform(20, 200), 2),
            'transaction_date': transaction_date.strftime('%Y-%m-%d %H:%M:%S')
        })

with open('public/sql-datasets/transactions.csv', 'w', newline='', encoding='utf-8-sig') as f:
    writer = csv.DictWriter(f, fieldnames=['transaction_id', 'user_id', 'amount', 'transaction_date'])
    writer.writeheader()
    writer.writerows(transactions_data)

print(f"âœ“ transactions.csv ({len(transactions_data)} è¡Œ)")

# ==========================================
# é¢˜ç›®5ï¼šè¿ç»­ç™»å½•å¤©æ•°
# ==========================================
print("\n[5/10] ç”Ÿæˆç”¨æˆ·ç™»å½•è®°å½•æ•°æ®é›† (user_logins.csv)...")

user_logins_data = []
login_date = datetime(2024, 1, 1)

for user_id in range(2001, 2031):  # 30ä¸ªç”¨æˆ·
    # ç”Ÿæˆè¿ç»­ç™»å½•åºåˆ—
    current_date = login_date + timedelta(days=random.randint(0, 10))
    
    # éšæœºç”Ÿæˆ2-4æ®µè¿ç»­ç™»å½•
    for segment in range(random.randint(2, 4)):
        consecutive_days = random.randint(3, 10)
        for day in range(consecutive_days):
            user_logins_data.append({
                'user_id': user_id,
                'login_date': current_date.strftime('%Y-%m-%d')
            })
            current_date += timedelta(days=1)
        
        # é—´éš”å‡ å¤©
        current_date += timedelta(days=random.randint(2, 7))

with open('public/sql-datasets/user_logins.csv', 'w', newline='', encoding='utf-8-sig') as f:
    writer = csv.DictWriter(f, fieldnames=['user_id', 'login_date'])
    writer.writeheader()
    writer.writerows(user_logins_data)

print(f"âœ“ user_logins.csv ({len(user_logins_data)} è¡Œ)")

# ==========================================
# é¢˜ç›®6ï¼šå•†å“é”€å”®æ’å
# ==========================================
print("\n[6/10] ç”Ÿæˆå•†å“é”€å”®æ•°æ®é›† (product_sales.csv)...")

product_sales_data = []
categories = ['ç”µå­äº§å“', 'æœè£…é‹å¸½', 'é£Ÿå“é¥®æ–™', 'å®¶å±…å®¶è£…']
product_names = {
    'ç”µå­äº§å“': ['æ‰‹æœº', 'è€³æœº', 'å……ç”µå®', 'æ•°æ®çº¿'],
    'æœè£…é‹å¸½': ['Tæ¤', 'ç‰›ä»”è£¤', 'è¿åŠ¨é‹', 'èƒŒåŒ…'],
    'é£Ÿå“é¥®æ–™': ['å’–å•¡', 'èŒ¶å¶', 'åšæœ', 'å·§å…‹åŠ›'],
    'å®¶å±…å®¶è£…': ['å°ç¯', 'æŠ±æ•', 'æ”¶çº³ç›’', 'æŒ‚é’Ÿ']
}

product_id = 1
for category in categories:
    for product_name in product_names[category]:
        sales = random.randint(100, 1000)
        product_sales_data.append({
            'product_id': product_id,
            'product_name': product_name,
            'category': category,
            'sales': sales
        })
        product_id += 1

with open('public/sql-datasets/product_sales.csv', 'w', newline='', encoding='utf-8-sig') as f:
    writer = csv.DictWriter(f, fieldnames=['product_id', 'product_name', 'category', 'sales'])
    writer.writeheader()
    writer.writerows(product_sales_data)

print(f"âœ“ product_sales.csv ({len(product_sales_data)} è¡Œ)")

# ==========================================
# é¢˜ç›®7ï¼šå‘˜å·¥å·¥èµ„æ•°æ®
# ==========================================
print("\n[7/10] ç”Ÿæˆå‘˜å·¥æ•°æ®é›† (employees.csv)...")

employees_data = []
departments = ['æŠ€æœ¯éƒ¨', 'å¸‚åœºéƒ¨', 'è¿è¥éƒ¨', 'è´¢åŠ¡éƒ¨', 'äººåŠ›èµ„æºéƒ¨']
positions = ['ç»ç†', 'ä¸»ç®¡', 'ä¸“å‘˜', 'åŠ©ç†']

employee_id = 1001
for dept in departments:
    dept_size = random.randint(8, 15)
    for i in range(dept_size):
        position = random.choice(positions)
        base_salary = {
            'ç»ç†': random.randint(20000, 30000),
            'ä¸»ç®¡': random.randint(15000, 20000),
            'ä¸“å‘˜': random.randint(8000, 15000),
            'åŠ©ç†': random.randint(5000, 8000)
        }[position]
        
        employees_data.append({
            'employee_id': employee_id,
            'name': f'å‘˜å·¥{employee_id}',
            'department': dept,
            'position': position,
            'salary': base_salary
        })
        employee_id += 1

with open('public/sql-datasets/employees.csv', 'w', newline='', encoding='utf-8-sig') as f:
    writer = csv.DictWriter(f, fieldnames=['employee_id', 'name', 'department', 'position', 'salary'])
    writer.writeheader()
    writer.writerows(employees_data)

print(f"âœ“ employees.csv ({len(employees_data)} è¡Œ)")

# ==========================================
# é¢˜ç›®8ï¼šå­¦ç”Ÿæˆç»©æ•°æ®
# ==========================================
print("\n[8/10] ç”Ÿæˆå­¦ç”Ÿæˆç»©æ•°æ®é›† (student_scores.csv)...")

student_scores_data = []
subjects = ['æ•°å­¦', 'è¯­æ–‡', 'è‹±è¯­', 'ç‰©ç†', 'åŒ–å­¦']

for student_id in range(10001, 10101):  # 100ä¸ªå­¦ç”Ÿ
    for subject in subjects:
        score = random.randint(60, 100)
        student_scores_data.append({
            'student_id': student_id,
            'student_name': f'å­¦ç”Ÿ{student_id}',
            'subject': subject,
            'score': score
        })

with open('public/sql-datasets/student_scores.csv', 'w', newline='', encoding='utf-8-sig') as f:
    writer = csv.DictWriter(f, fieldnames=['student_id', 'student_name', 'subject', 'score'])
    writer.writeheader()
    writer.writerows(student_scores_data)

print(f"âœ“ student_scores.csv ({len(student_scores_data)} è¡Œ)")

# ==========================================
# é¢˜ç›®9ï¼šé¡µé¢è®¿é—®æ—¥å¿—
# ==========================================
print("\n[9/10] ç”Ÿæˆé¡µé¢è®¿é—®æ•°æ®é›† (page_views.csv)...")

page_views_data = []
pages = ['/home', '/product', '/cart', '/checkout', '/about']
visit_time = datetime(2024, 1, 1)

for session_id in range(5001, 5201):  # 200ä¸ªä¼šè¯
    user_id = random.randint(1, 100)
    num_pages = random.randint(2, 8)
    
    for i in range(num_pages):
        page = pages[min(i, len(pages)-1)]  # æŒ‰æ¼æ–—é¡ºåº
        visit_time += timedelta(seconds=random.randint(10, 180))
        
        page_views_data.append({
            'session_id': session_id,
            'user_id': user_id,
            'page_url': page,
            'visit_time': visit_time.strftime('%Y-%m-%d %H:%M:%S')
        })

with open('public/sql-datasets/page_views.csv', 'w', newline='', encoding='utf-8-sig') as f:
    writer = csv.DictWriter(f, fieldnames=['session_id', 'user_id', 'page_url', 'visit_time'])
    writer.writeheader()
    writer.writerows(page_views_data)

print(f"âœ“ page_views.csv ({len(page_views_data)} è¡Œ)")

# ==========================================
# é¢˜ç›®10ï¼šåº“å­˜å˜åŠ¨è®°å½•
# ==========================================
print("\n[10/10] ç”Ÿæˆåº“å­˜å˜åŠ¨æ•°æ®é›† (inventory_changes.csv)...")

inventory_changes_data = []
change_date = datetime(2024, 1, 1)

for product_id in range(3001, 3021):  # 20ä¸ªå•†å“
    # åˆå§‹åº“å­˜
    current_stock = random.randint(100, 500)
    
    # ç”Ÿæˆ30å¤©çš„å˜åŠ¨è®°å½•
    for day in range(30):
        change_date_str = (change_date + timedelta(days=day)).strftime('%Y-%m-%d')
        
        # å…¥åº“
        if random.random() < 0.3:
            change_qty = random.randint(50, 200)
            current_stock += change_qty
            inventory_changes_data.append({
                'change_id': len(inventory_changes_data) + 1,
                'product_id': product_id,
                'change_type': 'å…¥åº“',
                'change_quantity': change_qty,
                'change_date': change_date_str,
                'stock_after': current_stock
            })
        
        # å‡ºåº“
        if random.random() < 0.6:
            change_qty = random.randint(10, 50)
            current_stock -= change_qty
            inventory_changes_data.append({
                'change_id': len(inventory_changes_data) + 1,
                'product_id': product_id,
                'change_type': 'å‡ºåº“',
                'change_quantity': change_qty,
                'change_date': change_date_str,
                'stock_after': current_stock
            })

with open('public/sql-datasets/inventory_changes.csv', 'w', newline='', encoding='utf-8-sig') as f:
    writer = csv.DictWriter(f, fieldnames=['change_id', 'product_id', 'change_type', 
                                           'change_quantity', 'change_date', 'stock_after'])
    writer.writeheader()
    writer.writerows(inventory_changes_data)

print(f"âœ“ inventory_changes.csv ({len(inventory_changes_data)} è¡Œ)")

# ==========================================
# ç»Ÿè®¡æ‘˜è¦
# ==========================================
print("\n" + "=" * 70)
print("âœ… SQLæ•°æ®é›†ç”Ÿæˆå®Œæˆï¼")
print("=" * 70)

datasets = [
    ('orders.csv', len(orders_data), 'ç”¨æˆ·è®¢å•'),
    ('daily_sales.csv', len(daily_sales_data), 'æ—¥é”€å”®é¢'),
    ('monthly_sales.csv', len(monthly_sales_data), 'æœˆåº¦é”€å”®'),
    ('transactions.csv', len(transactions_data), 'äº¤æ˜“æ˜ç»†'),
    ('user_logins.csv', len(user_logins_data), 'ç™»å½•è®°å½•'),
    ('product_sales.csv', len(product_sales_data), 'å•†å“é”€å”®'),
    ('employees.csv', len(employees_data), 'å‘˜å·¥ä¿¡æ¯'),
    ('student_scores.csv', len(student_scores_data), 'å­¦ç”Ÿæˆç»©'),
    ('page_views.csv', len(page_views_data), 'é¡µé¢è®¿é—®'),
    ('inventory_changes.csv', len(inventory_changes_data), 'åº“å­˜å˜åŠ¨')
]

print("\nğŸ“Š æ•°æ®é›†æ¸…å•ï¼š\n")
for filename, rows, desc in datasets:
    print(f"  {filename:30s} {rows:>5} è¡Œ  - {desc}")

total_rows = sum(rows for _, rows, _ in datasets)
print(f"\næ€»è®¡: 10ä¸ªæ•°æ®é›†ï¼Œ{total_rows:,} è¡Œæ•°æ®")
print("\nğŸ“ ä¿å­˜ä½ç½®: public/sql-datasets/")
print("=" * 70)


